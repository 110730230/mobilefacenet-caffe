I0423 22:44:01.740130 21205 caffe.cpp:204] Using GPUs 0, 1, 2, 3
I0423 22:44:01.783622 21205 caffe.cpp:209] GPU 0: Tesla V100-DGXS-16GB
I0423 22:44:01.784543 21205 caffe.cpp:209] GPU 1: Tesla V100-DGXS-16GB
I0423 22:44:01.785441 21205 caffe.cpp:209] GPU 2: Tesla V100-DGXS-16GB
I0423 22:44:01.786327 21205 caffe.cpp:209] GPU 3: Tesla V100-DGXS-16GB
I0423 22:44:02.433653 21205 solver.cpp:45] Initializing solver from parameters: 
base_lr: 0.1
display: 100
max_iter: 36000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 4e-05
snapshot: 4000
snapshot_prefix: "result/model"
solver_mode: GPU
device_id: 0
net: "model1.prototxt"
train_state {
  level: 0
  stage: ""
}
stepvalue: 16000
stepvalue: 24000
stepvalue: 28000
stepvalue: 32000
I0423 22:44:02.433784 21205 solver.cpp:102] Creating training net from net file: model1.prototxt
I0423 22:44:02.435055 21205 upgrade_proto.cpp:79] Attempting to upgrade batch norm layers using deprecated params: model1.prototxt
I0423 22:44:02.435070 21205 upgrade_proto.cpp:82] Successfully upgraded batch norm layers using deprecated params.
I0423 22:44:02.436460 21205 net.cpp:51] Initializing net from parameters: 
name: "MobileFaceNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.0078125
    mirror: true
    mean_value: 127.5
  }
  data_param {
    source: "/raid/face_dataset/CASIA-Webface_lmdb/"
    batch_size: 128
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1/bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv1/scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "PReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_dw"
  type: "Convolution"
  bottom: "conv1"
  top: "conv1_dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1_dw/bn"
  type: "BatchNorm"
  bottom: "conv1_dw"
  top: "conv1_dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv1_dw/scale"
  type: "Scale"
  bottom: "conv1_dw"
  top: "conv1_dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_dw"
  type: "PReLU"
  bottom: "conv1_dw"
  top: "conv1_dw"
}
layer {
  name: "conv2_ex"
  type: "Convolution"
  bottom: "conv1_dw"
  top: "conv2_ex"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv2_ex/bn"
  type: "BatchNorm"
  bottom: "conv2_ex"
  top: "conv2_ex"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2_ex/scale"
  type: "Scale"
  bottom: "conv2_ex"
  top: "conv2_ex"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_ex"
  type: "PReLU"
  bottom: "conv2_ex"
  top: "conv2_ex"
}
layer {
  name: "conv2_dw"
  type: "DepthwiseConvolution"
  bottom: "conv2_ex"
  top: "conv2_dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    group: 128
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CAFFE
  }
}
layer {
  name: "conv2_dw/bn"
  type: "BatchNorm"
  bottom: "conv2_dw"
  top: "conv2_dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2_dw/scale"
  type: "Scale"
  bottom: "conv2_dw"
  top: "conv2_dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_dw"
  type: "PReLU"
  bottom: "conv2_dw"
  top: "conv2_dw"
}
layer {
  name: "conv2_em"
  type: "Convolution"
  bottom: "conv2_dw"
  top: "conv2_em"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv2_em/bn"
  type: "BatchNorm"
  bottom: "conv2_em"
  top: "conv2_em"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2_em/scale"
  type: "Scale"
  bottom: "conv2_em"
  top: "conv2_em"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_1_ex"
  type: "Convolution"
  bottom: "conv2_em"
  top: "conv2_1_ex"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv2_1_ex/bn"
  type: "BatchNorm"
  bottom: "conv2_1_ex"
  top: "conv2_1_ex"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2_1_ex/scale"
  type: "Scale"
  bottom: "conv2_1_ex"
  top: "conv2_1_ex"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1_ex"
  type: "PReLU"
  bottom: "conv2_1_ex"
  top: "conv2_1_ex"
}
layer {
  name: "conv2_1_dw"
  type: "DepthwiseConvolution"
  bottom: "conv2_1_ex"
  top: "conv2_1_dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    group: 128
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CAFFE
  }
}
layer {
  name: "conv2_1_dw/bn"
  type: "BatchNorm"
  bottom: "conv2_1_dw"
  top: "conv2_1_dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2_1_dw/scale"
  type: "Scale"
  bottom: "conv2_1_dw"
  top: "conv2_1_dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1_dw"
  type: "PReLU"
  bottom: "conv2_1_dw"
  top: "conv2_1_dw"
}
layer {
  name: "conv2_1_em"
  type: "Convolution"
  bottom: "conv2_1_dw"
  top: "conv2_1_em"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv2_1_em/bn"
  type: "BatchNorm"
  bottom: "conv2_1_em"
  top: "conv2_1_em"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2_1_em/scale"
  type: "Scale"
  bottom: "conv2_1_em"
  top: "conv2_1_em"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2_1"
  type: "Eltwise"
  bottom: "conv2_em"
  bottom: "conv2_1_em"
  top: "res2_1"
}
layer {
  name: "conv2_2_ex"
  type: "Convolution"
  bottom: "res2_1"
  top: "conv2_2_ex"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv2_2_ex/bn"
  type: "BatchNorm"
  bottom: "conv2_2_ex"
  top: "conv2_2_ex"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2_2_ex/scale"
  type: "Scale"
  bottom: "conv2_2_ex"
  top: "conv2_2_ex"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2_ex"
  type: "PReLU"
  bottom: "conv2_2_ex"
  top: "conv2_2_ex"
}
layer {
  name: "conv2_2_dw"
  type: "DepthwiseConvolution"
  bottom: "conv2_2_ex"
  top: "conv2_2_dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    group: 128
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CAFFE
  }
}
layer {
  name: "conv2_2_dw/bn"
  type: "BatchNorm"
  bottom: "conv2_2_dw"
  top: "conv2_2_dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2_2_dw/scale"
  type: "Scale"
  bottom: "conv2_2_dw"
  top: "conv2_2_dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2_dw"
  type: "PReLU"
  bottom: "conv2_2_dw"
  top: "conv2_2_dw"
}
layer {
  name: "conv2_2_em"
  type: "Convolution"
  bottom: "conv2_2_dw"
  top: "conv2_2_em"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv2_2_em/bn"
  type: "BatchNorm"
  bottom: "conv2_2_em"
  top: "conv2_2_em"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2_2_em/scale"
  type: "Scale"
  bottom: "conv2_2_em"
  top: "conv2_2_em"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2_2"
  type: "Eltwise"
  bottom: "res2_1"
  bottom: "conv2_2_em"
  top: "res2_2"
}
layer {
  name: "conv2_3_ex"
  type: "Convolution"
  bottom: "res2_2"
  top: "conv2_3_ex"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv2_3_ex/bn"
  type: "BatchNorm"
  bottom: "conv2_3_ex"
  top: "conv2_3_ex"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2_3_ex/scale"
  type: "Scale"
  bottom: "conv2_3_ex"
  top: "conv2_3_ex"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_3_ex"
  type: "PReLU"
  bottom: "conv2_3_ex"
  top: "conv2_3_ex"
}
layer {
  name: "conv2_3_dw"
  type: "DepthwiseConvolution"
  bottom: "conv2_3_ex"
  top: "conv2_3_dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    group: 128
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CAFFE
  }
}
layer {
  name: "conv2_3_dw/bn"
  type: "BatchNorm"
  bottom: "conv2_3_dw"
  top: "conv2_3_dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2_3_dw/scale"
  type: "Scale"
  bottom: "conv2_3_dw"
  top: "conv2_3_dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_3_dw"
  type: "PReLU"
  bottom: "conv2_3_dw"
  top: "conv2_3_dw"
}
layer {
  name: "conv2_3_em"
  type: "Convolution"
  bottom: "conv2_3_dw"
  top: "conv2_3_em"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv2_3_em/bn"
  type: "BatchNorm"
  bottom: "conv2_3_em"
  top: "conv2_3_em"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2_3_em/scale"
  type: "Scale"
  bottom: "conv2_3_em"
  top: "conv2_3_em"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2_3"
  type: "Eltwise"
  bottom: "res2_2"
  bottom: "conv2_3_em"
  top: "res2_3"
}
layer {
  name: "conv2_4_ex"
  type: "Convolution"
  bottom: "res2_3"
  top: "conv2_4_ex"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv2_4_ex/bn"
  type: "BatchNorm"
  bottom: "conv2_4_ex"
  top: "conv2_4_ex"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2_4_ex/scale"
  type: "Scale"
  bottom: "conv2_4_ex"
  top: "conv2_4_ex"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_4_ex"
  type: "PReLU"
  bottom: "conv2_4_ex"
  top: "conv2_4_ex"
}
layer {
  name: "conv2_4_dw"
  type: "DepthwiseConvolution"
  bottom: "conv2_4_ex"
  top: "conv2_4_dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    group: 128
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CAFFE
  }
}
layer {
  name: "conv2_4_dw/bn"
  type: "BatchNorm"
  bottom: "conv2_4_dw"
  top: "conv2_4_dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2_4_dw/scale"
  type: "Scale"
  bottom: "conv2_4_dw"
  top: "conv2_4_dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_4_dw"
  type: "PReLU"
  bottom: "conv2_4_dw"
  top: "conv2_4_dw"
}
layer {
  name: "conv2_4_em"
  type: "Convolution"
  bottom: "conv2_4_dw"
  top: "conv2_4_em"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv2_4_em/bn"
  type: "BatchNorm"
  bottom: "conv2_4_em"
  top: "conv2_4_em"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2_4_em/scale"
  type: "Scale"
  bottom: "conv2_4_em"
  top: "conv2_4_em"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2_4"
  type: "Eltwise"
  bottom: "res2_3"
  bottom: "conv2_4_em"
  top: "res2_4"
}
layer {
  name: "conv3_ex"
  type: "Convolution"
  bottom: "res2_4"
  top: "conv3_ex"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv3_ex/bn"
  type: "BatchNorm"
  bottom: "conv3_ex"
  top: "conv3_ex"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv3_ex/scale"
  type: "Scale"
  bottom: "conv3_ex"
  top: "conv3_ex"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_ex"
  type: "PReLU"
  bottom: "conv3_ex"
  top: "conv3_ex"
}
layer {
  name: "conv3_dw"
  type: "DepthwiseConvolution"
  bottom: "conv3_ex"
  top: "conv3_dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 256
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CAFFE
  }
}
layer {
  name: "conv3_dw/bn"
  type: "BatchNorm"
  bottom: "conv3_dw"
  top: "conv3_dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv3_dw/scale"
  type: "Scale"
  bottom: "conv3_dw"
  top: "conv3_dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_dw"
  type: "PReLU"
  bottom: "conv3_dw"
  top: "conv3_dw"
}
layer {
  name: "conv3_em"
  type: "Convolution"
  bottom: "conv3_dw"
  top: "conv3_em"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv3_em/bn"
  type: "BatchNorm"
  bottom: "conv3_em"
  top: "conv3_em"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv3_em/scale"
  type: "Scale"
  bottom: "conv3_em"
  top: "conv3_em"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1_ex"
  type: "Convolution"
  bottom: "conv3_em"
  top: "conv3_1_ex"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv3_1_ex/bn"
  type: "BatchNorm"
  bottom: "conv3_1_ex"
  top: "conv3_1_ex"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv3_1_ex/scale"
  type: "Scale"
  bottom: "conv3_1_ex"
  top: "conv3_1_ex"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1_ex"
  type: "PReLU"
  bottom: "conv3_1_ex"
  top: "conv3_1_ex"
}
layer {
  name: "conv3_1_dw"
  type: "DepthwiseConvolution"
  bottom: "conv3_1_ex"
  top: "conv3_1_dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 256
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CAFFE
  }
}
layer {
  name: "conv3_1_dw/bn"
  type: "BatchNorm"
  bottom: "conv3_1_dw"
  top: "conv3_1_dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv3_1_dw/scale"
  type: "Scale"
  bottom: "conv3_1_dw"
  top: "conv3_1_dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1_dw"
  type: "PReLU"
  bottom: "conv3_1_dw"
  top: "conv3_1_dw"
}
layer {
  name: "conv3_1_em"
  type: "Convolution"
  bottom: "conv3_1_dw"
  top: "conv3_1_em"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv3_1_em/bn"
  type: "BatchNorm"
  bottom: "conv3_1_em"
  top: "conv3_1_em"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv3_1_em/scale"
  type: "Scale"
  bottom: "conv3_1_em"
  top: "conv3_1_em"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3_1"
  type: "Eltwise"
  bottom: "conv3_em"
  bottom: "conv3_1_em"
  top: "res3_1"
}
layer {
  name: "conv3_2_ex"
  type: "Convolution"
  bottom: "res3_1"
  top: "conv3_2_ex"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv3_2_ex/bn"
  type: "BatchNorm"
  bottom: "conv3_2_ex"
  top: "conv3_2_ex"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv3_2_ex/scale"
  type: "Scale"
  bottom: "conv3_2_ex"
  top: "conv3_2_ex"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_2_ex"
  type: "PReLU"
  bottom: "conv3_2_ex"
  top: "conv3_2_ex"
}
layer {
  name: "conv3_2_dw"
  type: "DepthwiseConvolution"
  bottom: "conv3_2_ex"
  top: "conv3_2_dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 256
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CAFFE
  }
}
layer {
  name: "conv3_2_dw/bn"
  type: "BatchNorm"
  bottom: "conv3_2_dw"
  top: "conv3_2_dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv3_2_dw/scale"
  type: "Scale"
  bottom: "conv3_2_dw"
  top: "conv3_2_dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_2_dw"
  type: "PReLU"
  bottom: "conv3_2_dw"
  top: "conv3_2_dw"
}
layer {
  name: "conv3_2_em"
  type: "Convolution"
  bottom: "conv3_2_dw"
  top: "conv3_2_em"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv3_2_em/bn"
  type: "BatchNorm"
  bottom: "conv3_2_em"
  top: "conv3_2_em"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv3_2_em/scale"
  type: "Scale"
  bottom: "conv3_2_em"
  top: "conv3_2_em"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3_2"
  type: "Eltwise"
  bottom: "res3_1"
  bottom: "conv3_2_em"
  top: "res3_2"
}
layer {
  name: "conv3_3_ex"
  type: "Convolution"
  bottom: "res3_2"
  top: "conv3_3_ex"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv3_3_ex/bn"
  type: "BatchNorm"
  bottom: "conv3_3_ex"
  top: "conv3_3_ex"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv3_3_ex/scale"
  type: "Scale"
  bottom: "conv3_3_ex"
  top: "conv3_3_ex"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_3_ex"
  type: "PReLU"
  bottom: "conv3_3_ex"
  top: "conv3_3_ex"
}
layer {
  name: "conv3_3_dw"
  type: "DepthwiseConvolution"
  bottom: "conv3_3_ex"
  top: "conv3_3_dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 256
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CAFFE
  }
}
layer {
  name: "conv3_3_dw/bn"
  type: "BatchNorm"
  bottom: "conv3_3_dw"
  top: "conv3_3_dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv3_3_dw/scale"
  type: "Scale"
  bottom: "conv3_3_dw"
  top: "conv3_3_dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_3_dw"
  type: "PReLU"
  bottom: "conv3_3_dw"
  top: "conv3_3_dw"
}
layer {
  name: "conv3_3_em"
  type: "Convolution"
  bottom: "conv3_3_dw"
  top: "conv3_3_em"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv3_3_em/bn"
  type: "BatchNorm"
  bottom: "conv3_3_em"
  top: "conv3_3_em"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv3_3_em/scale"
  type: "Scale"
  bottom: "conv3_3_em"
  top: "conv3_3_em"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3_3"
  type: "Eltwise"
  bottom: "res3_2"
  bottom: "conv3_3_em"
  top: "res3_3"
}
layer {
  name: "conv3_4_ex"
  type: "Convolution"
  bottom: "res3_3"
  top: "conv3_4_ex"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv3_4_ex/bn"
  type: "BatchNorm"
  bottom: "conv3_4_ex"
  top: "conv3_4_ex"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv3_4_ex/scale"
  type: "Scale"
  bottom: "conv3_4_ex"
  top: "conv3_4_ex"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_4_ex"
  type: "PReLU"
  bottom: "conv3_4_ex"
  top: "conv3_4_ex"
}
layer {
  name: "conv3_4_dw"
  type: "DepthwiseConvolution"
  bottom: "conv3_4_ex"
  top: "conv3_4_dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 256
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CAFFE
  }
}
layer {
  name: "conv3_4_dw/bn"
  type: "BatchNorm"
  bottom: "conv3_4_dw"
  top: "conv3_4_dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv3_4_dw/scale"
  type: "Scale"
  bottom: "conv3_4_dw"
  top: "conv3_4_dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_4_dw"
  type: "PReLU"
  bottom: "conv3_4_dw"
  top: "conv3_4_dw"
}
layer {
  name: "conv3_4_em"
  type: "Convolution"
  bottom: "conv3_4_dw"
  top: "conv3_4_em"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv3_4_em/bn"
  type: "BatchNorm"
  bottom: "conv3_4_em"
  top: "conv3_4_em"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv3_4_em/scale"
  type: "Scale"
  bottom: "conv3_4_em"
  top: "conv3_4_em"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3_4"
  type: "Eltwise"
  bottom: "res3_3"
  bottom: "conv3_4_em"
  top: "res3_4"
}
layer {
  name: "conv3_5_ex"
  type: "Convolution"
  bottom: "res3_4"
  top: "conv3_5_ex"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv3_5_ex/bn"
  type: "BatchNorm"
  bottom: "conv3_5_ex"
  top: "conv3_5_ex"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv3_5_ex/scale"
  type: "Scale"
  bottom: "conv3_5_ex"
  top: "conv3_5_ex"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_5_ex"
  type: "PReLU"
  bottom: "conv3_5_ex"
  top: "conv3_5_ex"
}
layer {
  name: "conv3_5_dw"
  type: "DepthwiseConvolution"
  botto
I0423 22:44:02.437227 21205 layer_factory.hpp:77] Creating layer data
I0423 22:44:02.437340 21205 db_lmdb.cpp:35] Opened lmdb /raid/face_dataset/CASIA-Webface_lmdb/
I0423 22:44:02.437373 21205 net.cpp:84] Creating Layer data
I0423 22:44:02.437381 21205 net.cpp:380] data -> data
I0423 22:44:02.437412 21205 net.cpp:380] data -> label
I0423 22:44:02.438849 21205 data_layer.cpp:45] output data size: 128,3,112,96
I0423 22:44:02.467597 21205 net.cpp:122] Setting up data
I0423 22:44:02.467627 21205 net.cpp:129] Top shape: 128 3 112 96 (4128768)
I0423 22:44:02.467631 21205 net.cpp:129] Top shape: 128 (128)
I0423 22:44:02.467633 21205 net.cpp:137] Memory required for data: 16515584
I0423 22:44:02.467643 21205 layer_factory.hpp:77] Creating layer label_data_1_split
I0423 22:44:02.467655 21205 net.cpp:84] Creating Layer label_data_1_split
I0423 22:44:02.467663 21205 net.cpp:406] label_data_1_split <- label
I0423 22:44:02.467675 21205 net.cpp:380] label_data_1_split -> label_data_1_split_0
I0423 22:44:02.467686 21205 net.cpp:380] label_data_1_split -> label_data_1_split_1
I0423 22:44:02.467692 21205 net.cpp:380] label_data_1_split -> label_data_1_split_2
I0423 22:44:02.467746 21205 net.cpp:122] Setting up label_data_1_split
I0423 22:44:02.467753 21205 net.cpp:129] Top shape: 128 (128)
I0423 22:44:02.467756 21205 net.cpp:129] Top shape: 128 (128)
I0423 22:44:02.467761 21205 net.cpp:129] Top shape: 128 (128)
I0423 22:44:02.467762 21205 net.cpp:137] Memory required for data: 16517120
I0423 22:44:02.467766 21205 layer_factory.hpp:77] Creating layer conv1
I0423 22:44:02.467784 21205 net.cpp:84] Creating Layer conv1
I0423 22:44:02.467795 21205 net.cpp:406] conv1 <- data
I0423 22:44:02.467803 21205 net.cpp:380] conv1 -> conv1
I0423 22:44:03.245367 21205 net.cpp:122] Setting up conv1
I0423 22:44:03.245429 21205 net.cpp:129] Top shape: 128 64 56 48 (22020096)
I0423 22:44:03.245434 21205 net.cpp:137] Memory required for data: 104597504
I0423 22:44:03.245453 21205 layer_factory.hpp:77] Creating layer conv1/bn
I0423 22:44:03.245465 21205 net.cpp:84] Creating Layer conv1/bn
I0423 22:44:03.245471 21205 net.cpp:406] conv1/bn <- conv1
I0423 22:44:03.245478 21205 net.cpp:367] conv1/bn -> conv1 (in-place)
I0423 22:44:03.245684 21205 net.cpp:122] Setting up conv1/bn
I0423 22:44:03.245692 21205 net.cpp:129] Top shape: 128 64 56 48 (22020096)
I0423 22:44:03.245695 21205 net.cpp:137] Memory required for data: 192677888
I0423 22:44:03.245705 21205 layer_factory.hpp:77] Creating layer conv1/scale
I0423 22:44:03.245717 21205 net.cpp:84] Creating Layer conv1/scale
I0423 22:44:03.245719 21205 net.cpp:406] conv1/scale <- conv1
I0423 22:44:03.245724 21205 net.cpp:367] conv1/scale -> conv1 (in-place)
I0423 22:44:03.245766 21205 layer_factory.hpp:77] Creating layer conv1/scale
I0423 22:44:03.245884 21205 net.cpp:122] Setting up conv1/scale
I0423 22:44:03.245892 21205 net.cpp:129] Top shape: 128 64 56 48 (22020096)
I0423 22:44:03.245894 21205 net.cpp:137] Memory required for data: 280758272
I0423 22:44:03.245900 21205 layer_factory.hpp:77] Creating layer relu1
I0423 22:44:03.245904 21205 net.cpp:84] Creating Layer relu1
I0423 22:44:03.245908 21205 net.cpp:406] relu1 <- conv1
I0423 22:44:03.245911 21205 net.cpp:367] relu1 -> conv1 (in-place)
I0423 22:44:03.247018 21205 net.cpp:122] Setting up relu1
I0423 22:44:03.247033 21205 net.cpp:129] Top shape: 128 64 56 48 (22020096)
I0423 22:44:03.247036 21205 net.cpp:137] Memory required for data: 368838656
I0423 22:44:03.247041 21205 layer_factory.hpp:77] Creating layer conv1_dw
I0423 22:44:03.247053 21205 net.cpp:84] Creating Layer conv1_dw
I0423 22:44:03.247057 21205 net.cpp:406] conv1_dw <- conv1
I0423 22:44:03.247062 21205 net.cpp:380] conv1_dw -> conv1_dw
I0423 22:44:03.251330 21205 net.cpp:122] Setting up conv1_dw
I0423 22:44:03.251348 21205 net.cpp:129] Top shape: 128 64 56 48 (22020096)
I0423 22:44:03.251350 21205 net.cpp:137] Memory required for data: 456919040
I0423 22:44:03.251360 21205 layer_factory.hpp:77] Creating layer conv1_dw/bn
I0423 22:44:03.251368 21205 net.cpp:84] Creating Layer conv1_dw/bn
I0423 22:44:03.251372 21205 net.cpp:406] conv1_dw/bn <- conv1_dw
I0423 22:44:03.251377 21205 net.cpp:367] conv1_dw/bn -> conv1_dw (in-place)
I0423 22:44:03.251580 21205 net.cpp:122] Setting up conv1_dw/bn
I0423 22:44:03.251588 21205 net.cpp:129] Top shape: 128 64 56 48 (22020096)
I0423 22:44:03.251591 21205 net.cpp:137] Memory required for data: 544999424
I0423 22:44:03.251598 21205 layer_factory.hpp:77] Creating layer conv1_dw/scale
I0423 22:44:03.251605 21205 net.cpp:84] Creating Layer conv1_dw/scale
I0423 22:44:03.251608 21205 net.cpp:406] conv1_dw/scale <- conv1_dw
I0423 22:44:03.251613 21205 net.cpp:367] conv1_dw/scale -> conv1_dw (in-place)
I0423 22:44:03.251649 21205 layer_factory.hpp:77] Creating layer conv1_dw/scale
I0423 22:44:03.251762 21205 net.cpp:122] Setting up conv1_dw/scale
I0423 22:44:03.251770 21205 net.cpp:129] Top shape: 128 64 56 48 (22020096)
I0423 22:44:03.251772 21205 net.cpp:137] Memory required for data: 633079808
I0423 22:44:03.251777 21205 layer_factory.hpp:77] Creating layer relu1_dw
I0423 22:44:03.251782 21205 net.cpp:84] Creating Layer relu1_dw
I0423 22:44:03.251785 21205 net.cpp:406] relu1_dw <- conv1_dw
I0423 22:44:03.251790 21205 net.cpp:367] relu1_dw -> conv1_dw (in-place)
I0423 22:44:03.251981 21205 net.cpp:122] Setting up relu1_dw
I0423 22:44:03.251987 21205 net.cpp:129] Top shape: 128 64 56 48 (22020096)
I0423 22:44:03.251991 21205 net.cpp:137] Memory required for data: 721160192
I0423 22:44:03.251996 21205 layer_factory.hpp:77] Creating layer conv2_ex
I0423 22:44:03.252002 21205 net.cpp:84] Creating Layer conv2_ex
I0423 22:44:03.252005 21205 net.cpp:406] conv2_ex <- conv1_dw
I0423 22:44:03.252010 21205 net.cpp:380] conv2_ex -> conv2_ex
I0423 22:44:03.255585 21205 net.cpp:122] Setting up conv2_ex
I0423 22:44:03.255620 21205 net.cpp:129] Top shape: 128 128 56 48 (44040192)
I0423 22:44:03.255625 21205 net.cpp:137] Memory required for data: 897320960
I0423 22:44:03.255633 21205 layer_factory.hpp:77] Creating layer conv2_ex/bn
I0423 22:44:03.255640 21205 net.cpp:84] Creating Layer conv2_ex/bn
I0423 22:44:03.255645 21205 net.cpp:406] conv2_ex/bn <- conv2_ex
I0423 22:44:03.255650 21205 net.cpp:367] conv2_ex/bn -> conv2_ex (in-place)
I0423 22:44:03.255846 21205 net.cpp:122] Setting up conv2_ex/bn
I0423 22:44:03.255854 21205 net.cpp:129] Top shape: 128 128 56 48 (44040192)
I0423 22:44:03.255856 21205 net.cpp:137] Memory required for data: 1073481728
I0423 22:44:03.255864 21205 layer_factory.hpp:77] Creating layer conv2_ex/scale
I0423 22:44:03.255869 21205 net.cpp:84] Creating Layer conv2_ex/scale
I0423 22:44:03.255873 21205 net.cpp:406] conv2_ex/scale <- conv2_ex
I0423 22:44:03.255877 21205 net.cpp:367] conv2_ex/scale -> conv2_ex (in-place)
I0423 22:44:03.255913 21205 layer_factory.hpp:77] Creating layer conv2_ex/scale
I0423 22:44:03.256019 21205 net.cpp:122] Setting up conv2_ex/scale
I0423 22:44:03.256027 21205 net.cpp:129] Top shape: 128 128 56 48 (44040192)
I0423 22:44:03.256029 21205 net.cpp:137] Memory required for data: 1249642496
I0423 22:44:03.256036 21205 layer_factory.hpp:77] Creating layer relu2_ex
I0423 22:44:03.256039 21205 net.cpp:84] Creating Layer relu2_ex
I0423 22:44:03.256043 21205 net.cpp:406] relu2_ex <- conv2_ex
I0423 22:44:03.256047 21205 net.cpp:367] relu2_ex -> conv2_ex (in-place)
I0423 22:44:03.257231 21205 net.cpp:122] Setting up relu2_ex
I0423 22:44:03.257246 21205 net.cpp:129] Top shape: 128 128 56 48 (44040192)
I0423 22:44:03.257251 21205 net.cpp:137] Memory required for data: 1425803264
I0423 22:44:03.257256 21205 layer_factory.hpp:77] Creating layer conv2_dw
I0423 22:44:03.257264 21205 net.cpp:84] Creating Layer conv2_dw
I0423 22:44:03.257269 21205 net.cpp:406] conv2_dw <- conv2_ex
I0423 22:44:03.257275 21205 net.cpp:380] conv2_dw -> conv2_dw
I0423 22:44:03.258375 21205 net.cpp:122] Setting up conv2_dw
I0423 22:44:03.258390 21205 net.cpp:129] Top shape: 128 128 28 24 (11010048)
I0423 22:44:03.258394 21205 net.cpp:137] Memory required for data: 1469843456
I0423 22:44:03.258401 21205 layer_factory.hpp:77] Creating layer conv2_dw/bn
I0423 22:44:03.258407 21205 net.cpp:84] Creating Layer conv2_dw/bn
I0423 22:44:03.258410 21205 net.cpp:406] conv2_dw/bn <- conv2_dw
I0423 22:44:03.258415 21205 net.cpp:367] conv2_dw/bn -> conv2_dw (in-place)
I0423 22:44:03.258613 21205 net.cpp:122] Setting up conv2_dw/bn
I0423 22:44:03.258621 21205 net.cpp:129] Top shape: 128 128 28 24 (11010048)
I0423 22:44:03.258625 21205 net.cpp:137] Memory required for data: 1513883648
I0423 22:44:03.258630 21205 layer_factory.hpp:77] Creating layer conv2_dw/scale
I0423 22:44:03.258638 21205 net.cpp:84] Creating Layer conv2_dw/scale
I0423 22:44:03.258641 21205 net.cpp:406] conv2_dw/scale <- conv2_dw
I0423 22:44:03.258646 21205 net.cpp:367] conv2_dw/scale -> conv2_dw (in-place)
I0423 22:44:03.258682 21205 layer_factory.hpp:77] Creating layer conv2_dw/scale
I0423 22:44:03.258786 21205 net.cpp:122] Setting up conv2_dw/scale
I0423 22:44:03.258793 21205 net.cpp:129] Top shape: 128 128 28 24 (11010048)
I0423 22:44:03.258795 21205 net.cpp:137] Memory required for data: 1557923840
I0423 22:44:03.258801 21205 layer_factory.hpp:77] Creating layer relu2_dw
I0423 22:44:03.258805 21205 net.cpp:84] Creating Layer relu2_dw
I0423 22:44:03.258808 21205 net.cpp:406] relu2_dw <- conv2_dw
I0423 22:44:03.258812 21205 net.cpp:367] relu2_dw -> conv2_dw (in-place)
I0423 22:44:03.258949 21205 net.cpp:122] Setting up relu2_dw
I0423 22:44:03.258957 21205 net.cpp:129] Top shape: 128 128 28 24 (11010048)
I0423 22:44:03.258960 21205 net.cpp:137] Memory required for data: 1601964032
I0423 22:44:03.258965 21205 layer_factory.hpp:77] Creating layer conv2_em
I0423 22:44:03.258971 21205 net.cpp:84] Creating Layer conv2_em
I0423 22:44:03.258975 21205 net.cpp:406] conv2_em <- conv2_dw
I0423 22:44:03.258980 21205 net.cpp:380] conv2_em -> conv2_em
I0423 22:44:03.261431 21205 net.cpp:122] Setting up conv2_em
I0423 22:44:03.261466 21205 net.cpp:129] Top shape: 128 64 28 24 (5505024)
I0423 22:44:03.261471 21205 net.cpp:137] Memory required for data: 1623984128
I0423 22:44:03.261477 21205 layer_factory.hpp:77] Creating layer conv2_em/bn
I0423 22:44:03.261483 21205 net.cpp:84] Creating Layer conv2_em/bn
I0423 22:44:03.261487 21205 net.cpp:406] conv2_em/bn <- conv2_em
I0423 22:44:03.261492 21205 net.cpp:367] conv2_em/bn -> conv2_em (in-place)
I0423 22:44:03.261699 21205 net.cpp:122] Setting up conv2_em/bn
I0423 22:44:03.261708 21205 net.cpp:129] Top shape: 128 64 28 24 (5505024)
I0423 22:44:03.261710 21205 net.cpp:137] Memory required for data: 1646004224
I0423 22:44:03.261721 21205 layer_factory.hpp:77] Creating layer conv2_em/scale
I0423 22:44:03.261729 21205 net.cpp:84] Creating Layer conv2_em/scale
I0423 22:44:03.261732 21205 net.cpp:406] conv2_em/scale <- conv2_em
I0423 22:44:03.261736 21205 net.cpp:367] conv2_em/scale -> conv2_em (in-place)
I0423 22:44:03.261775 21205 layer_factory.hpp:77] Creating layer conv2_em/scale
I0423 22:44:03.261889 21205 net.cpp:122] Setting up conv2_em/scale
I0423 22:44:03.261898 21205 net.cpp:129] Top shape: 128 64 28 24 (5505024)
I0423 22:44:03.261899 21205 net.cpp:137] Memory required for data: 1668024320
I0423 22:44:03.261905 21205 layer_factory.hpp:77] Creating layer conv2_em_conv2_em/scale_0_split
I0423 22:44:03.261910 21205 net.cpp:84] Creating Layer conv2_em_conv2_em/scale_0_split
I0423 22:44:03.261914 21205 net.cpp:406] conv2_em_conv2_em/scale_0_split <- conv2_em
I0423 22:44:03.261917 21205 net.cpp:380] conv2_em_conv2_em/scale_0_split -> conv2_em_conv2_em/scale_0_split_0
I0423 22:44:03.261924 21205 net.cpp:380] conv2_em_conv2_em/scale_0_split -> conv2_em_conv2_em/scale_0_split_1
I0423 22:44:03.261962 21205 net.cpp:122] Setting up conv2_em_conv2_em/scale_0_split
I0423 22:44:03.261970 21205 net.cpp:129] Top shape: 128 64 28 24 (5505024)
I0423 22:44:03.261973 21205 net.cpp:129] Top shape: 128 64 28 24 (5505024)
I0423 22:44:03.261976 21205 net.cpp:137] Memory required for data: 1712064512
I0423 22:44:03.261978 21205 layer_factory.hpp:77] Creating layer conv2_1_ex
I0423 22:44:03.261986 21205 net.cpp:84] Creating Layer conv2_1_ex
I0423 22:44:03.261989 21205 net.cpp:406] conv2_1_ex <- conv2_em_conv2_em/scale_0_split_0
I0423 22:44:03.261994 21205 net.cpp:380] conv2_1_ex -> conv2_1_ex
I0423 22:44:03.264420 21205 net.cpp:122] Setting up conv2_1_ex
I0423 22:44:03.264434 21205 net.cpp:129] Top shape: 128 128 28 24 (11010048)
I0423 22:44:03.264437 21205 net.cpp:137] Memory required for data: 1756104704
I0423 22:44:03.264444 21205 layer_factory.hpp:77] Creating layer conv2_1_ex/bn
I0423 22:44:03.264451 21205 net.cpp:84] Creating Layer conv2_1_ex/bn
I0423 22:44:03.264453 21205 net.cpp:406] conv2_1_ex/bn <- conv2_1_ex
I0423 22:44:03.264458 21205 net.cpp:367] conv2_1_ex/bn -> conv2_1_ex (in-place)
I0423 22:44:03.264658 21205 net.cpp:122] Setting up conv2_1_ex/bn
I0423 22:44:03.264667 21205 net.cpp:129] Top shape: 128 128 28 24 (11010048)
I0423 22:44:03.264669 21205 net.cpp:137] Memory required for data: 1800144896
I0423 22:44:03.264677 21205 layer_factory.hpp:77] Creating layer conv2_1_ex/scale
I0423 22:44:03.264683 21205 net.cpp:84] Creating Layer conv2_1_ex/scale
I0423 22:44:03.264686 21205 net.cpp:406] conv2_1_ex/scale <- conv2_1_ex
I0423 22:44:03.264690 21205 net.cpp:367] conv2_1_ex/scale -> conv2_1_ex (in-place)
I0423 22:44:03.264727 21205 layer_factory.hpp:77] Creating layer conv2_1_ex/scale
I0423 22:44:03.264837 21205 net.cpp:122] Setting up conv2_1_ex/scale
I0423 22:44:03.264845 21205 net.cpp:129] Top shape: 128 128 28 24 (11010048)
I0423 22:44:03.264847 21205 net.cpp:137] Memory required for data: 1844185088
I0423 22:44:03.264853 21205 layer_factory.hpp:77] Creating layer relu2_1_ex
I0423 22:44:03.264858 21205 net.cpp:84] Creating Layer relu2_1_ex
I0423 22:44:03.264860 21205 net.cpp:406] relu2_1_ex <- conv2_1_ex
I0423 22:44:03.264864 21205 net.cpp:367] relu2_1_ex -> conv2_1_ex (in-place)
I0423 22:44:03.265004 21205 net.cpp:122] Setting up relu2_1_ex
I0423 22:44:03.265030 21205 net.cpp:129] Top shape: 128 128 28 24 (11010048)
I0423 22:44:03.265033 21205 net.cpp:137] Memory required for data: 1888225280
I0423 22:44:03.265038 21205 layer_factory.hpp:77] Creating layer conv2_1_dw
I0423 22:44:03.265045 21205 net.cpp:84] Creating Layer conv2_1_dw
I0423 22:44:03.265048 21205 net.cpp:406] conv2_1_dw <- conv2_1_ex
I0423 22:44:03.265053 21205 net.cpp:380] conv2_1_dw -> conv2_1_dw
I0423 22:44:03.265316 21205 net.cpp:122] Setting up conv2_1_dw
I0423 22:44:03.265326 21205 net.cpp:129] Top shape: 128 128 28 24 (11010048)
I0423 22:44:03.265328 21205 net.cpp:137] Memory required for data: 1932265472
I0423 22:44:03.265334 21205 layer_factory.hpp:77] Creating layer conv2_1_dw/bn
I0423 22:44:03.265339 21205 net.cpp:84] Creating Layer conv2_1_dw/bn
I0423 22:44:03.265342 21205 net.cpp:406] conv2_1_dw/bn <- conv2_1_dw
I0423 22:44:03.265348 21205 net.cpp:367] conv2_1_dw/bn -> conv2_1_dw (in-place)
I0423 22:44:03.265539 21205 net.cpp:122] Setting up conv2_1_dw/bn
I0423 22:44:03.265547 21205 net.cpp:129] Top shape: 128 128 28 24 (11010048)
I0423 22:44:03.265549 21205 net.cpp:137] Memory required for data: 1976305664
I0423 22:44:03.265556 21205 layer_factory.hpp:77] Creating layer conv2_1_dw/scale
I0423 22:44:03.265561 21205 net.cpp:84] Creating Layer conv2_1_dw/scale
I0423 22:44:03.265564 21205 net.cpp:406] conv2_1_dw/scale <- conv2_1_dw
I0423 22:44:03.265568 21205 net.cpp:367] conv2_1_dw/scale -> conv2_1_dw (in-place)
I0423 22:44:03.265604 21205 layer_factory.hpp:77] Creating layer conv2_1_dw/scale
I0423 22:44:03.265712 21205 net.cpp:122] Setting up conv2_1_dw/scale
I0423 22:44:03.265718 21205 net.cpp:129] Top shape: 128 128 28 24 (11010048)
I0423 22:44:03.265720 21205 net.cpp:137] Memory required for data: 2020345856
I0423 22:44:03.265727 21205 layer_factory.hpp:77] Creating layer relu2_1_dw
I0423 22:44:03.265730 21205 net.cpp:84] Creating Layer relu2_1_dw
I0423 22:44:03.265733 21205 net.cpp:406] relu2_1_dw <- conv2_1_dw
I0423 22:44:03.265738 21205 net.cpp:367] relu2_1_dw -> conv2_1_dw (in-place)
I0423 22:44:03.265877 21205 net.cpp:122] Setting up relu2_1_dw
I0423 22:44:03.265885 21205 net.cpp:129] Top shape: 128 128 28 24 (11010048)
I0423 22:44:03.265888 21205 net.cpp:137] Memory required for data: 2064386048
I0423 22:44:03.265892 21205 layer_factory.hpp:77] Creating layer conv2_1_em
I0423 22:44:03.265900 21205 net.cpp:84] Creating Layer conv2_1_em
I0423 22:44:03.265902 21205 net.cpp:406] conv2_1_em <- conv2_1_dw
I0423 22:44:03.265908 21205 net.cpp:380] conv2_1_em -> conv2_1_em
I0423 22:44:03.268656 21205 net.cpp:122] Setting up conv2_1_em
I0423 22:44:03.268673 21205 net.cpp:129] Top shape: 128 64 28 24 (5505024)
I0423 22:44:03.268676 21205 net.cpp:137] Memory required for data: 2086406144
I0423 22:44:03.268682 21205 layer_factory.hpp:77] Creating layer conv2_1_em/bn
I0423 22:44:03.268688 21205 net.cpp:84] Creating Layer conv2_1_em/bn
I0423 22:44:03.268692 21205 net.cpp:406] conv2_1_em/bn <- conv2_1_em
I0423 22:44:03.268697 21205 net.cpp:367] conv2_1_em/bn -> conv2_1_em (in-place)
I0423 22:44:03.268908 21205 net.cpp:122] Setting up conv2_1_em/bn
I0423 22:44:03.268916 21205 net.cpp:129] Top shape: 128 64 28 24 (5505024)
I0423 22:44:03.268919 21205 net.cpp:137] Memory required for data: 2108426240
I0423 22:44:03.268926 21205 layer_factory.hpp:77] Creating layer conv2_1_em/scale
I0423 22:44:03.268934 21205 net.cpp:84] Creating Layer conv2_1_em/scale
I0423 22:44:03.268939 21205 net.cpp:406] conv2_1_em/scale <- conv2_1_em
I0423 22:44:03.268944 21205 net.cpp:367] conv2_1_em/scale -> conv2_1_em (in-place)
I0423 22:44:03.268982 21205 layer_factory.hpp:77] Creating layer conv2_1_em/scale
I0423 22:44:03.269101 21205 net.cpp:122] Setting up conv2_1_em/scale
I0423 22:44:03.269109 21205 net.cpp:129] Top shape: 128 64 28 24 (5505024)
I0423 22:44:03.269111 21205 net.cpp:137] Memory required for data: 2130446336
I0423 22:44:03.269117 21205 layer_factory.hpp:77] Creating layer res2_1
I0423 22:44:03.269122 21205 net.cpp:84] Creating Layer res2_1
I0423 22:44:03.269125 21205 net.cpp:406] res2_1 <- conv2_em_conv2_em/scale_0_split_1
I0423 22:44:03.269150 21205 net.cpp:406] res2_1 <- conv2_1_em
I0423 22:44:03.269155 21205 net.cpp:380] res2_1 -> res2_1
I0423 22:44:03.269186 21205 net.cpp:122] Setting up res2_1
I0423 22:44:03.269193 21205 net.cpp:129] Top shape: 128 64 28 24 (5505024)
I0423 22:44:03.269196 21205 net.cpp:137] Memory required for data: 2152466432
I0423 22:44:03.269199 21205 layer_factory.hpp:77] Creating layer res2_1_res2_1_0_split
I0423 22:44:03.269204 21205 net.cpp:84] Creating Layer res2_1_res2_1_0_split
I0423 22:44:03.269207 21205 net.cpp:406] res2_1_res2_1_0_split <- res2_1
I0423 22:44:03.269212 21205 net.cpp:380] res2_1_res2_1_0_split -> res2_1_res2_1_0_split_0
I0423 22:44:03.269230 21205 net.cpp:380] res2_1_res2_1_0_split -> res2_1_res2_1_0_split_1
I0423 22:44:03.269273 21205 net.cpp:122] Setting up res2_1_res2_1_0_split
I0423 22:44:03.269279 21205 net.cpp:129] Top shape: 128 64 28 24 (5505024)
I0423 22:44:03.269284 21205 net.cpp:129] Top shape: 128 64 28 24 (5505024)
I0423 22:44:03.269287 21205 net.cpp:137] Memory required for data: 2196506624
I0423 22:44:03.269290 21205 layer_factory.hpp:77] Creating layer conv2_2_ex
I0423 22:44:03.269299 21205 net.cpp:84] Creating Layer conv2_2_ex
I0423 22:44:03.269302 21205 net.cpp:406] conv2_2_ex <- res2_1_res2_1_0_split_0
I0423 22:44:03.269309 21205 net.cpp:380] conv2_2_ex -> conv2_2_ex
I0423 22:44:03.271854 21205 net.cpp:122] Setting up conv2_2_ex
I0423 22:44:03.271869 21205 net.cpp:129] Top shape: 128 128 28 24 (11010048)
I0423 22:44:03.271873 21205 net.cpp:137] Memory required for data: 2240546816
I0423 22:44:03.271879 21205 layer_factory.hpp:77] Creating layer conv2_2_ex/bn
I0423 22:44:03.271885 21205 net.cpp:84] Creating Layer conv2_2_ex/bn
I0423 22:44:03.271889 21205 net.cpp:406] conv2_2_ex/bn <- conv2_2_ex
I0423 22:44:03.271894 21205 net.cpp:367] conv2_2_ex/bn -> conv2_2_ex (in-place)
I0423 22:44:03.272100 21205 net.cpp:122] Setting up conv2_2_ex/bn
I0423 22:44:03.272109 21205 net.cpp:129] Top shape: 128 128 28 24 (11010048)
I0423 22:44:03.272111 21205 net.cpp:137] Memory required for data: 2284587008
I0423 22:44:03.272119 21205 layer_factory.hpp:77] Creating layer conv2_2_ex/scale
I0423 22:44:03.272125 21205 net.cpp:84] Creating Layer conv2_2_ex/scale
I0423 22:44:03.272128 21205 net.cpp:406] conv2_2_ex/scale <- conv2_2_ex
I0423 22:44:03.272132 21205 net.cpp:367] conv2_2_ex/scale -> conv2_2_ex (in-place)
I0423 22:44:03.272169 21205 layer_factory.hpp:77] Creating layer conv2_2_ex/scale
I0423 22:44:03.272282 21205 net.cpp:122] Setting up conv2_2_ex/scale
I0423 22:44:03.272289 21205 net.cpp:129] Top shape: 128 128 28 24 (11010048)
I0423 22:44:03.272292 21205 net.cpp:137] Memory required for data: 2328627200
I0423 22:44:03.272298 21205 layer_factory.hpp:77] Creating layer relu2_2_ex
I0423 22:44:03.272302 21205 net.cpp:84] Creating Layer relu2_2_ex
I0423 22:44:03.272305 21205 net.cpp:406] relu2_2_ex <- conv2_2_ex
I0423 22:44:03.272310 21205 net.cpp:367] relu2_2_ex -> conv2_2_ex (in-place)
I0423 22:44:03.272454 21205 net.cpp:122] Setting up relu2_2_ex
I0423 22:44:03.272461 21205 net.cpp:129] Top shape: 128 128 28 24 (11010048)
I0423 22:44:03.272464 21205 net.cpp:137] Memory required for data: 2372667392
I0423 22:44:03.272473 21205 layer_factory.hpp:77] Creating layer conv2_2_dw
I0423 22:44:03.272481 21205 net.cpp:84] Creating Layer conv2_2_dw
I0423 22:44:03.272485 21205 net.cpp:406] conv2_2_dw <- conv2_2_ex
I0423 22:44:03.272490 21205 net.cpp:380] conv2_2_dw -> conv2_2_dw
I0423 22:44:03.272740 21205 net.cpp:122] Setting up conv2_2_dw
I0423 22:44:03.272749 21205 net.cpp:129] Top shape: 128 128 28 24 (11010048)
I0423 22:44:03.272752 21205 net.cpp:137] Memory required for data: 2416707584
I0423 22:44:03.272758 21205 layer_factory.hpp:77] Creating layer conv2_2_dw/bn
I0423 22:44:03.272763 21205 net.cpp:84] Creating Layer conv2_2_dw/bn
I0423 22:44:03.272765 21205 net.cpp:406] conv2_2_dw/bn <- conv2_2_dw
I0423 22:44:03.272769 21205 net.cpp:367] conv2_2_dw/bn -> conv2_2_dw (in-place)
I0423 22:44:03.272960 21205 net.cpp:122] Setting up conv2_2_dw/bn
I0423 22:44:03.272967 21205 net.cpp:129] Top shape: 128 128 28 24 (11010048)
I0423 22:44:03.272989 21205 net.cpp:137] Memory required for data: 2460747776
I0423 22:44:03.272996 21205 layer_factory.hpp:77] Creating layer conv2_2_dw/scale
I0423 22:44:03.273001 21205 net.cpp:84] Creating Layer conv2_2_dw/scale
I0423 22:44:03.273005 21205 net.cpp:406] conv2_2_dw/scale <- conv2_2_dw
I0423 22:44:03.273010 21205 net.cpp:367] conv2_2_dw/scale -> conv2_2_dw (in-place)
I0423 22:44:03.273049 21205 layer_factory.hpp:77] Creating layer conv2_2_dw/scale
I0423 22:44:03.273160 21205 net.cpp:122] Setting up conv2_2_dw/scale
I0423 22:44:03.273167 21205 net.cpp:129] Top shape: 128 128 28 24 (11010048)
I0423 22:44:03.273170 21205 net.cpp:137] Memory required for data: 2504787968
I0423 22:44:03.273175 21205 layer_factory.hpp:77] Creating layer relu2_2_dw
I0423 22:44:03.273180 21205 net.cpp:84] Creating Layer relu2_2_dw
I0423 22:44:03.273182 21205 net.cpp:406] relu2_2_dw <- conv2_2_dw
I0423 22:44:03.273187 21205 net.cpp:367] relu2_2_dw -> conv2_2_dw (in-place)
I0423 22:44:03.274212 21205 net.cpp:122] Setting up relu2_2_dw
I0423 22:44:03.274227 21205 net.cpp:129] Top shape: 128 128 28 24 (11010048)
I0423 22:44:03.274230 21205 net.cpp:137] Memory required for data: 2548828160
I0423 22:44:03.274236 21205 layer_factory.hpp:77] Creating layer conv2_2_em
I0423 22:44:03.274245 21205 net.cpp:84] Creating Layer conv2_2_em
I0423 22:44:03.274248 21205 net.cpp:406] conv2_2_em <- conv2_2_dw
I0423 22:44:03.274253 21205 net.cpp:380] conv2_2_em -> conv2_2_em
I0423 22:44:03.276527 21205 net.cpp:122] Setting up conv2_2_em
I0423 22:44:03.276543 21205 net.cpp:129] Top shape: 128 64 28 24 (5505024)
I0423 22:44:03.276546 21205 net.cpp:137] Memory required for data: 2570848256
I0423 22:44:03.276552 21205 layer_factory.hpp:77] Creating layer conv2_2_em/bn
I0423 22:44:03.276559 21205 net.cpp:84] Creating Layer conv2_2_em/bn
I0423 22:44:03.276563 21205 net.cpp:406] conv2_2_em/bn <- conv2_2_em
I0423 22:44:03.276568 21205 net.cpp:367] conv2_2_em/bn -> conv2_2_em (in-place)
I0423 22:44:03.276782 21205 net.cpp:122] Setting up conv2_2_em/bn
I0423 22:44:03.276792 21205 net.cpp:129] Top shape: 128 64 28 24 (5505024)
I0423 22:44:03.276793 21205 net.cpp:137] Memory required for data: 2592868352
I0423 22:44:03.276800 21205 layer_factory.hpp:77] Creating layer conv2_2_em/scale
I0423 22:44:03.276806 21205 net.cpp:84] Creating Layer conv2_2_em/scale
I0423 22:44:03.276811 21205 net.cpp:406] conv2_2_em/scale <- conv2_2_em
I0423 22:44:03.276815 21205 net.cpp:367] conv2_2_em/scale -> conv2_2_em (in-place)
I0423 22:44:03.276854 21205 layer_factory.hpp:77] Creating layer conv2_2_em/scale
I0423 22:44:03.276974 21205 net.cpp:122] Setting up conv2_2_em/scale
I0423 22:44:03.276983 21205 net.cpp:129] Top shape: 128 64 28 24 (5505024)
I0423 22:44:03.276984 21205 net.cpp:137] Memory required for data: 2614888448
I0423 22:44:03.276990 21205 layer_factory.hpp:77] Creating layer res2_2
I0423 22:44:03.276995 21205 net.cpp:84] Creating Layer res2_2
I0423 22:44:03.276998 21205 net.cpp:406] res2_2 <- res2_1_res2_1_0_split_1
I0423 22:44:03.277003 21205 net.cpp:406] res2_2 <- conv2_2_em
I0423 22:44:03.277006 21205 net.cpp:380] res2_2 -> res2_2
I0423 22:44:03.277032 21205 net.cpp:122] Setting up res2_2
I0423 22:44:03.277040 21205 net.cpp:129] Top shape: 128 64 28 24 (5505024)
I0423 22:44:03.277042 21205 net.cpp:137] Memory required for data: 2636908544
I0423 22:44:03.277045 21205 layer_factory.hpp:77] Creating layer res2_2_res2_2_0_split
I0423 22:44:03.277050 21205 net.cpp:84] Creating Layer res2_2_res2_2_0_split
I0423 22:44:03.277053 21205 net.cpp:406] res2_2_res2_2_0_split <- res2_2
I0423 22:44:03.277057 21205 net.cpp:380] res2_2_res2_2_0_split -> res2_2_res2_2_0_split_0
I0423 22:44:03.277063 21205 net.cpp:380] res2_2_res2_2_0_split -> res2_2_res2_2_0_split_1
I0423 22:44:03.277099 21205 net.cpp:122] Setting up res2_2_res2_2_0_split
I0423 22:44:03.277106 21205 net.cpp:129] Top shape: 128 64 28 24 (5505024)
I0423 22:44:03.277109 21205 net.cpp:129] Top shape: 128 64 28 24 (5505024)
I0423 22:44:03.277112 21205 net.cpp:137] Memory required for data: 2680948736
I0423 22:44:03.277133 21205 layer_factory.hpp:77] Creating layer conv2_3_ex
I0423 22:44:03.277143 21205 net.cpp:84] Creating Layer conv2_3_ex
I0423 22:44:03.277146 21205 net.cpp:406] conv2_3_ex <- res2_2_res2_2_0_split_0
I0423 22:44:03.277151 21205 net.cpp:380] conv2_3_ex -> conv2_3_ex
I0423 22:44:03.279430 21205 net.cpp:122] Setting up conv2_3_ex
I0423 22:44:03.279446 21205 net.cpp:129] Top shape: 128 128 28 24 (11010048)
I0423 22:44:03.279450 21205 net.cpp:137] Memory required for data: 2724988928
I0423 22:44:03.279455 21205 layer_factory.hpp:77] Creating layer conv2_3_ex/bn
I0423 22:44:03.279461 21205 net.cpp:84] Creating Layer conv2_3_ex/bn
I0423 22:44:03.279465 21205 net.cpp:406] conv2_3_ex/bn <- conv2_3_ex
I0423 22:44:03.279470 21205 net.cpp:367] conv2_3_ex/bn -> conv2_3_ex (in-place)
I0423 22:44:03.279676 21205 net.cpp:122] Setting up conv2_3_ex/bn
I0423 22:44:03.279685 21205 net.cpp:129] Top shape: 128 128 28 24 (11010048)
I0423 22:44:03.279687 21205 net.cpp:137] Memory required for data: 2769029120
I0423 22:44:03.279695 21205 layer_factory.hpp:77] Creating layer conv2_3_ex/scale
I0423 22:44:03.279700 21205 net.cpp:84] Creating Layer conv2_3_ex/scale
I0423 22:44:03.279703 21205 net.cpp:406] conv2_3_ex/scale <- conv2_3_ex
I0423 22:44:03.279707 21205 net.cpp:367] conv2_3_ex/scale -> conv2_3_ex (in-place)
I0423 22:44:03.279745 21205 layer_factory.hpp:77] Creating layer conv2_3_ex/scale
I0423 22:44:03.279860 21205 net.cpp:122] Setting up conv2_3_ex/scale
I0423 22:44:03.279867 21205 net.cpp:129] Top shape: 128 128 28 24 (11010048)
I0423 22:44:03.279870 21205 net.cpp:137] Memory required for data: 2813069312
I0423 22:44:03.279876 21205 layer_factory.hpp:77] Creating layer relu2_3_ex
I0423 22:44:03.279881 21205 net.cpp:84] Creating Layer relu2_3_ex
I0423 22:44:03.279883 21205 net.cpp:406] relu2_3_ex <- conv2_3_ex
I0423 22:44:03.279887 21205 net.cpp:367] relu2_3_ex -> conv2_3_ex (in-place)
I0423 22:44:03.280028 21205 net.cpp:122] Setting up relu2_3_ex
I0423 22:44:03.280036 21205 net.cpp:129] Top shape: 128 128 28 24 (11010048)
I0423 22:44:03.280040 21205 net.cpp:137] Memory required for data: 2857109504
I0423 22:44:03.280043 21205 layer_factory.hpp:77] Creating layer conv2_3_dw
I0423 22:44:03.280050 21205 net.cpp:84] Creating Layer conv2_3_dw
I0423 22:44:03.280055 21205 net.cpp:406] conv2_3_dw <- conv2_3_ex
I0423 22:44:03.280058 21205 net.cpp:380] conv2_3_dw -> conv2_3_dw
I0423 22:44:03.280314 21205 net.cpp:122] Setting up conv2_3_dw
I0423 22:44:03.280323 21205 net.cpp:129] Top shape: 128 128 28 24 (11010048)
I0423 22:44:03.280326 21205 net.cpp:137] Memory required for data: 2901149696
I0423 22:44:03.280331 21205 layer_factory.hpp:77] Creating layer conv2_3_dw/bn
I0423 22:44:03.280336 21205 net.cpp:84] Creating Layer conv2_3_dw/bn
I0423 22:44:03.280339 21205 net.cpp:406] conv2_3_dw/bn <- conv2_3_dw
I0423 22:44:03.280344 21205 net.cpp:367] conv2_3_dw/bn -> conv2_3_dw (in-place)
I0423 22:44:03.280539 21205 net.cpp:122] Setting up conv2_3_dw/bn
I0423 22:44:03.280546 21205 net.cpp:129] Top shape: 128 128 28 24 (11010048)
I0423 22:44:03.280549 21205 net.cpp:137] Memory required for data: 2945189888
I0423 22:44:03.280555 21205 layer_factory.hpp:77] Creating layer conv2_3_dw/scale
I0423 22:44:03.280560 21205 net.cpp:84] Creating Layer conv2_3_dw/scale
I0423 22:44:03.280565 21205 net.cpp:406] conv2_3_dw/scale <- conv2_3_dw
I0423 22:44:03.280568 21205 net.cpp:367] conv2_3_dw/scale -> conv2_3_dw (in-place)
I0423 22:44:03.280604 21205 layer_factory.hpp:77] Creating layer conv2_3_dw/scale
I0423 22:44:03.280716 21205 net.cpp:122] Setting up conv2_3_dw/scale
I0423 22:44:03.280725 21205 net.cpp:129] Top shape: 128 128 28 24 (11010048)
I0423 22:44:03.280727 21205 net.cpp:137] Memory required for data: 2989230080
I0423 22:44:03.280732 21205 layer_factory.hpp:77] Creating layer relu2_3_dw
I0423 22:44:03.280736 21205 net.cpp:84] Creating Layer relu2_3_dw
I0423 22:44:03.280740 21205 net.cpp:406] relu2_3_dw <- conv2_3_dw
I0423 22:44:03.280743 21205 net.cpp:367] relu2_3_dw -> conv2_3_dw (in-place)
I0423 22:44:03.280885 21205 net.cpp:122] Setting up relu2_3_dw
I0423 22:44:03.280910 21205 net.cpp:129] Top shape: 128 128 28 24 (11010048)
I0423 22:44:03.280915 21205 net.cpp:137] Memory required for data: 3033270272
I0423 22:44:03.280920 21205 layer_factory.hpp:77] Creating layer conv2_3_em
I0423 22:44:03.280927 21205 net.cpp:84] Creating Layer conv2_3_em
I0423 22:44:03.280930 21205 net.cpp:406] conv2_3_em <- conv2_3_dw
I0423 22:44:03.280936 21205 net.cpp:380] conv2_3_em -> conv2_3_em
I0423 22:44:03.283613 21205 net.cpp:122] Setting up conv2_3_em
I0423 22:44:03.283629 21205 net.cpp:129] Top shape: 128 64 28 24 (5505024)
I0423 22:44:03.283633 21205 net.cpp:137] Memory required for data: 3055290368
I0423 22:44:03.283639 21205 layer_factory.hpp:77] Creating layer conv2_3_em/bn
I0423 22:44:03.283645 21205 net.cpp:84] Creating Layer conv2_3_em/bn
I0423 22:44:03.283648 21205 net.cpp:406] conv2_3_em/bn <- conv2_3_em
I0423 22:44:03.283653 21205 net.cpp:367] conv2_3_em/bn -> conv2_3_em (in-place)
I0423 22:44:03.283870 21205 net.cpp:122] Setting up conv2_3_em/bn
I0423 22:44:03.283879 21205 net.cpp:129] Top shape: 128 64 28 24 (5505024)
I0423 22:44:03.283881 21205 net.cpp:137] Memory required for data: 3077310464
I0423 22:44:03.283888 21205 layer_factory.hpp:77] Creating layer conv2_3_em/scale
I0423 22:44:03.283895 21205 net.cpp:84] Creating Layer conv2_3_em/scale
I0423 22:44:03.283897 21205 net.cpp:406] conv2_3_em/scale <- conv2_3_em
I0423 22:44:03.283901 21205 net.cpp:367] conv2_3_em/scale -> conv2_3_em (in-place)
I0423 22:44:03.283941 21205 layer_factory.hpp:77] Creating layer conv2_3_em/scale
I0423 22:44:03.284065 21205 net.cpp:122] Setting up conv2_3_em/scale
I0423 22:44:03.284072 21205 net.cpp:129] Top shape: 128 64 28 24 (5505024)
I0423 22:44:03.284075 21205 net.cpp:137] Memory required for data: 3099330560
I0423 22:44:03.284080 21205 layer_factory.hpp:77] Creating layer res2_3
I0423 22:44:03.284085 21205 net.cpp:84] Creating Layer res2_3
I0423 22:44:03.284088 21205 net.cpp:406] res2_3 <- res2_2_res2_2_0_split_1
I0423 22:44:03.284091 21205 net.cpp:406] res2_3 <- conv2_3_em
I0423 22:44:03.284096 21205 net.cpp:380] res2_3 -> res2_3
I0423 22:44:03.284123 21205 net.cpp:122] Setting up res2_3
I0423 22:44:03.284129 21205 net.cpp:129] Top shape: 128 64 28 24 (5505024)
I0423 22:44:03.284132 21205 net.cpp:137] Memory required for data: 3121350656
I0423 22:44:03.284134 21205 layer_factory.hpp:77] Creating layer res2_3_res2_3_0_split
I0423 22:44:03.284140 21205 net.cpp:84] Creating Layer res2_3_res2_3_0_split
I0423 22:44:03.284143 21205 net.cpp:406] res2_3_res2_3_0_split <- res2_3
I0423 22:44:03.284147 21205 net.cpp:380] res2_3_res2_3_0_split -> res2_3_res2_3_0_split_0
I0423 22:44:03.284152 21205 net.cpp:380] res2_3_res2_3_0_split -> res2_3_res2_3_0_split_1
I0423 22:44:03.284191 21205 net.cpp:122] Setting up res2_3_res2_3_0_split
I0423 22:44:03.284198 21205 net.cpp:129] Top shape: 128 64 28 24 (5505024)
I0423 22:44:03.284200 21205 net.cpp:129] Top shape: 128 64 28 24 (5505024)
I0423 22:44:03.284204 21205 net.cpp:137] Memory required for data: 3165390848
I0423 22:44:03.284206 21205 layer_factory.hpp:77] Creating layer conv2_4_ex
I0423 22:44:03.284214 21205 net.cpp:84] Creating Layer conv2_4_ex
I0423 22:44:03.284217 21205 net.cpp:406] conv2_4_ex <- res2_3_res2_3_0_split_0
I0423 22:44:03.284221 21205 net.cpp:380] conv2_4_ex -> conv2_4_ex
I0423 22:44:03.286536 21205 net.cpp:122] Setting up conv2_4_ex
I0423 22:44:03.286552 21205 net.cpp:129] Top shape: 128 128 28 24 (11010048)
I0423 22:44:03.286556 21205 net.cpp:137] Memory required for data: 3209431040
I0423 22:44:03.286561 21205 layer_factory.hpp:77] Creating layer conv2_4_ex/bn
I0423 22:44:03.286567 21205 net.cpp:84] Creating Layer conv2_4_ex/bn
I0423 22:44:03.286571 21205 net.cpp:406] conv2_4_ex/bn <- conv2_4_ex
I0423 22:44:03.286576 21205 net.cpp:367] conv2_4_ex/bn -> conv2_4_ex (in-place)
I0423 22:44:03.286784 21205 net.cpp:122] Setting up conv2_4_ex/bn
I0423 22:44:03.286793 21205 net.cpp:129] Top shape: 128 128 28 24 (11010048)
I0423 22:44:03.286795 21205 net.cpp:137] Memory required for data: 3253471232
I0423 22:44:03.286828 21205 layer_factory.hpp:77] Creating layer conv2_4_ex/scale
I0423 22:44:03.286834 21205 net.cpp:84] Creating Layer conv2_4_ex/scale
I0423 22:44:03.286839 21205 net.cpp:406] conv2_4_ex/scale <- conv2_4_ex
I0423 22:44:03.286842 21205 net.cpp:367] conv2_4_ex/scale -> conv2_4_ex (in-place)
I0423 22:44:03.286885 21205 layer_factory.hpp:77] Creating layer conv2_4_ex/scale
I0423 22:44:03.287003 21205 net.cpp:122] Setting up conv2_4_ex/scale
I0423 22:44:03.287010 21205 net.cpp:129] Top shape: 128 128 28 24 (11010048)
I0423 22:44:03.287014 21205 net.cpp:137] Memory required for data: 3297511424
I0423 22:44:03.287019 21205 layer_factory.hpp:77] Creating layer relu2_4_ex
I0423 22:44:03.287029 21205 net.cpp:84] Creating Layer relu2_4_ex
I0423 22:44:03.287032 21205 net.cpp:406] relu2_4_ex <- conv2_4_ex
I0423 22:44:03.287036 21205 net.cpp:367] relu2_4_ex -> conv2_4_ex (in-place)
I0423 22:44:03.287180 21205 net.cpp:122] Setting up relu2_4_ex
I0423 22:44:03.287189 21205 net.cpp:129] Top shape: 128 128 28 24 (11010048)
I0423 22:44:03.287192 21205 net.cpp:137] Memory required for data: 3341551616
I0423 22:44:03.287196 21205 layer_factory.hpp:77] Creating layer conv2_4_dw
I0423 22:44:03.287204 21205 net.cpp:84] Creating Layer conv2_4_dw
I0423 22:44:03.287207 21205 net.cpp:406] conv2_4_dw <- conv2_4_ex
I0423 22:44:03.287212 21205 net.cpp:380] conv2_4_dw -> conv2_4_dw
I0423 22:44:03.287472 21205 net.cpp:122] Setting up conv2_4_dw
I0423 22:44:03.287480 21205 net.cpp:129] Top shape: 128 128 28 24 (11010048)
I0423 22:44:03.287483 21205 net.cpp:137] Memory required for data: 3385591808
I0423 22:44:03.287488 21205 layer_factory.hpp:77] Creating layer conv2_4_dw/bn
I0423 22:44:03.287494 21205 net.cpp:84] Creating Layer conv2_4_dw/bn
I0423 22:44:03.287497 21205 net.cpp:406] conv2_4_dw/bn <- conv2_4_dw
I0423 22:44:03.287500 21205 net.cpp:367] conv2_4_dw/bn -> conv2_4_dw (in-place)
I0423 22:44:03.287701 21205 net.cpp:122] Setting up conv2_4_dw/bn
I0423 22:44:03.287708 21205 net.cpp:129] Top shape: 128 128 28 24 (11010048)
I0423 22:44:03.287710 21205 net.cpp:137] Memory required for data: 3429632000
I0423 22:44:03.287717 21205 layer_factory.hpp:77] Creating layer conv2_4_dw/scale
I0423 22:44:03.287724 21205 net.cpp:84] Creating Layer conv2_4_dw/scale
I0423 22:44:03.287726 21205 net.cpp:406] conv2_4_dw/scale <- conv2_4_dw
I0423 22:44:03.287730 21205 net.cpp:367] conv2_4_dw/scale -> conv2_4_dw (in-place)
I0423 22:44:03.287766 21205 layer_factory.hpp:77] Creating layer conv2_4_dw/scale
I0423 22:44:03.287881 21205 net.cpp:122] Setting up conv2_4_dw/scale
I0423 22:44:03.287889 21205 net.cpp:129] Top shape: 128 128 28 24 (11010048)
I0423 22:44:03.287890 21205 net.cpp:137] Memory required for data: 3473672192
I0423 22:44:03.287895 21205 layer_factory.hpp:77] Creating layer relu2_4_dw
I0423 22:44:03.287900 21205 net.cpp:84] Creating Layer relu2_4_dw
I0423 22:44:03.287904 21205 net.cpp:406] relu2_4_dw <- conv2_4_dw
I0423 22:44:03.287907 21205 net.cpp:367] relu2_4_dw -> conv2_4_dw (in-place)
I0423 22:44:03.288048 21205 net.cpp:122] Setting up relu2_4_dw
I0423 22:44:03.288056 21205 net.cpp:129] Top shape: 128 128 28 24 (11010048)
I0423 22:44:03.288059 21205 net.cpp:137] Memory required for data: 3517712384
I0423 22:44:03.288064 21205 layer_factory.hpp:77] Creating layer conv2_4_em
I0423 22:44:03.288069 21205 net.cpp:84] Creating Layer conv2_4_em
I0423 22:44:03.288074 21205 net.cpp:406] conv2_4_em <- conv2_4_dw
I0423 22:44:03.288079 21205 net.cpp:380] conv2_4_em -> conv2_4_em
I0423 22:44:03.291250 21205 net.cpp:122] Setting up conv2_4_em
I0423 22:44:03.291266 21205 net.cpp:129] Top shape: 128 64 28 24 (5505024)
I0423 22:44:03.291270 21205 net.cpp:137] Memory required for data: 3539732480
I0423 22:44:03.291276 21205 layer_factory.hpp:77] Creating layer conv2_4_em/bn
I0423 22:44:03.291282 21205 net.cpp:84] Creating Layer conv2_4_em/bn
I0423 22:44:03.291286 21205 net.cpp:406] conv2_4_em/bn <- conv2_4_em
I0423 22:44:03.291292 21205 net.cpp:367] conv2_4_em/bn -> conv2_4_em (in-place)
I0423 22:44:03.291514 21205 net.cpp:122] Setting up conv2_4_em/bn
I0423 22:44:03.291540 21205 net.cpp:129] Top shape: 128 64 28 24 (5505024)
I0423 22:44:03.291544 21205 net.cpp:137] Memory required for data: 3561752576
I0423 22:44:03.291553 21205 layer_factory.hpp:77] Creating layer conv2_4_em/scale
I0423 22:44:03.291558 21205 net.cpp:84] Creating Layer conv2_4_em/scale
I0423 22:44:03.291561 21205 net.cpp:406] conv2_4_em/scale <- conv2_4_em
I0423 22:44:03.291566 21205 net.cpp:367] conv2_4_em/scale -> conv2_4_em (in-place)
I0423 22:44:03.291610 21205 layer_factory.hpp:77] Creating layer conv2_4_em/scale
I0423 22:44:03.291736 21205 net.cpp:122] Setting up conv2_4_em/scale
I0423 22:44:03.291744 21205 net.cpp:129] Top shape: 128 64 28 24 (5505024)
I0423 22:44:03.291746 21205 net.cpp:137] Memory required for data: 3583772672
I0423 22:44:03.291752 21205 layer_factory.hpp:77] Creating layer res2_4
I0423 22:44:03.291757 21205 net.cpp:84] Creating Layer res2_4
I0423 22:44:03.291760 21205 net.cpp:406] res2_4 <- res2_3_res2_3_0_split_1
I0423 22:44:03.291764 21205 net.cpp:406] res2_4 <- conv2_4_em
I0423 22:44:03.291769 21205 net.cpp:380] res2_4 -> res2_4
I0423 22:44:03.291795 21205 net.cpp:122] Setting up res2_4
I0423 22:44:03.291802 21205 net.cpp:129] Top shape: 128 64 28 24 (5505024)
I0423 22:44:03.291805 21205 net.cpp:137] Memory required for data: 3605792768
I0423 22:44:03.291808 21205 layer_factory.hpp:77] Creating layer conv3_ex
I0423 22:44:03.291815 21205 net.cpp:84] Creating Layer conv3_ex
I0423 22:44:03.291818 21205 net.cpp:406] conv3_ex <- res2_4
I0423 22:44:03.291823 21205 net.cpp:380] conv3_ex -> conv3_ex
I0423 22:44:03.295614 21205 net.cpp:122] Setting up conv3_ex
I0423 22:44:03.295629 21205 net.cpp:129] Top shape: 128 256 28 24 (22020096)
I0423 22:44:03.295632 21205 net.cpp:137] Memory required for data: 3693873152
I0423 22:44:03.295639 21205 layer_factory.hpp:77] Creating layer conv3_ex/bn
I0423 22:44:03.295645 21205 net.cpp:84] Creating Layer conv3_ex/bn
I0423 22:44:03.295648 21205 net.cpp:406] conv3_ex/bn <- conv3_ex
I0423 22:44:03.295653 21205 net.cpp:367] conv3_ex/bn -> conv3_ex (in-place)
I0423 22:44:03.295869 21205 net.cpp:122] Setting up conv3_ex/bn
I0423 22:44:03.295878 21205 net.cpp:129] Top shape: 128 256 28 24 (22020096)
I0423 22:44:03.295881 21205 net.cpp:137] Memory required for data: 3781953536
I0423 22:44:03.295888 21205 layer_factory.hpp:77] Creating layer conv3_ex/scale
I0423 22:44:03.295893 21205 net.cpp:84] Creating Layer conv3_ex/scale
I0423 22:44:03.295897 21205 net.cpp:406] conv3_ex/scale <- conv3_ex
I0423 22:44:03.295902 21205 net.cpp:367] conv3_ex/scale -> conv3_ex (in-place)
I0423 22:44:03.295939 21205 layer_factory.hpp:77] Creating layer conv3_ex/scale
I0423 22:44:03.296061 21205 net.cpp:122] Setting up conv3_ex/scale
I0423 22:44:03.296069 21205 net.cpp:129] Top shape: 128 256 28 24 (22020096)
I0423 22:44:03.296072 21205 net.cpp:137] Memory required for data: 3870033920
I0423 22:44:03.296077 21205 layer_factory.hpp:77] Creating layer relu3_ex
I0423 22:44:03.296082 21205 net.cpp:84] Creating Layer relu3_ex
I0423 22:44:03.296084 21205 net.cpp:406] relu3_ex <- conv3_ex
I0423 22:44:03.296088 21205 net.cpp:367] relu3_ex -> conv3_ex (in-place)
I0423 22:44:03.297170 21205 net.cpp:122] Setting up relu3_ex
I0423 22:44:03.297184 21205 net.cpp:129] Top shape: 128 256 28 24 (22020096)
I0423 22:44:03.297188 21205 net.cpp:137] Memory required for data: 3958114304
I0423 22:44:03.297194 21205 layer_factory.hpp:77] Creating layer conv3_dw
I0423 22:44:03.297201 21205 net.cpp:84] Creating Layer conv3_dw
I0423 22:44:03.297204 21205 net.cpp:406] conv3_dw <- conv3_ex
I0423 22:44:03.297211 21205 net.cpp:380] conv3_dw -> conv3_dw
I0423 22:44:03.297504 21205 net.cpp:122] Setting up conv3_dw
I0423 22:44:03.297513 21205 net.cpp:129] Top shape: 128 256 14 12 (5505024)
I0423 22:44:03.297516 21205 net.cpp:137] Memory required for data: 3980134400
I0423 22:44:03.297531 21205 layer_factory.hpp:77] Creating layer conv3_dw/bn
I0423 22:44:03.297538 21205 net.cpp:84] Creating Layer conv3_dw/bn
I0423 22:44:03.297541 21205 net.cpp:406] conv3_dw/bn <- conv3_dw
I0423 22:44:03.297545 21205 net.cpp:367] conv3_dw/bn -> conv3_dw (in-place)
I0423 22:44:03.297777 21205 net.cpp:122] Setting up conv3_dw/bn
I0423 22:44:03.297786 21205 net.cpp:129] Top shape: 128 256 14 12 (5505024)
I0423 22:44:03.297788 21205 net.cpp:137] Memory required for data: 4002154496
I0423 22:44:03.297796 21205 layer_factory.hpp:77] Creating layer conv3_dw/scale
I0423 22:44:03.297802 21205 net.cpp:84] Creating Layer conv3_dw/scale
I0423 22:44:03.297804 21205 net.cpp:406] conv3_dw/scale <- conv3_dw
I0423 22:44:03.297808 21205 net.cpp:367] conv3_dw/scale -> conv3_dw (in-place)
I0423 22:44:03.297848 21205 layer_factory.hpp:77] Creating layer conv3_dw/scale
I0423 22:44:03.297966 21205 net.cpp:122] Setting up conv3_dw/scale
I0423 22:44:03.297972 21205 net.cpp:129] Top shape: 128 256 14 12 (5505024)
I0423 22:44:03.297976 21205 net.cpp:137] Memory required for data: 4024174592
I0423 22:44:03.297981 21205 layer_factory.hpp:77] Creating layer relu3_dw
I0423 22:44:03.297986 21205 net.cpp:84] Creating Layer relu3_dw
I0423 22:44:03.297988 21205 net.cpp:406] relu3_dw <- conv3_dw
I0423 22:44:03.297992 21205 net.cpp:367] relu3_dw -> conv3_dw (in-place)
I0423 22:44:03.298110 21205 net.cpp:122] Setting up relu3_dw
I0423 22:44:03.298120 21205 net.cpp:129] Top shape: 128 256 14 12 (5505024)
I0423 22:44:03.298121 21205 net.cpp:137] Memory required for data: 4046194688
I0423 22:44:03.298125 21205 layer_factory.hpp:77] Creating layer conv3_em
I0423 22:44:03.298132 21205 net.cpp:84] Creating Layer conv3_em
I0423 22:44:03.298136 21205 net.cpp:406] conv3_em <- conv3_dw
I0423 22:44:03.298141 21205 net.cpp:380] conv3_em -> conv3_em
I0423 22:44:03.300590 21205 net.cpp:122] Setting up conv3_em
I0423 22:44:03.300604 21205 net.cpp:129] Top shape: 128 128 14 12 (2752512)
I0423 22:44:03.300608 21205 net.cpp:137] Memory required for data: 4057204736
I0423 22:44:03.300614 21205 layer_factory.hpp:77] Creating layer conv3_em/bn
I0423 22:44:03.300621 21205 net.cpp:84] Creating Layer conv3_em/bn
I0423 22:44:03.300623 21205 net.cpp:406] conv3_em/bn <- conv3_em
I0423 22:44:03.300629 21205 net.cpp:367] conv3_em/bn -> conv3_em (in-place)
I0423 22:44:03.300842 21205 net.cpp:122] Setting up conv3_em/bn
I0423 22:44:03.300849 21205 net.cpp:129] Top shape: 128 128 14 12 (2752512)
I0423 22:44:03.300853 21205 net.cpp:137] Memory required for data: 4068214784
I0423 22:44:03.300860 21205 layer_factory.hpp:77] Creating layer conv3_em/scale
I0423 22:44:03.300865 21205 net.cpp:84] Creating Layer conv3_em/scale
I0423 22:44:03.300868 21205 net.cpp:406] conv3_em/scale <- conv3_em
I0423 22:44:03.300873 21205 net.cpp:367] conv3_em/scale -> conv3_em (in-place)
I0423 22:44:03.300911 21205 layer_factory.hpp:77] Creating layer conv3_em/scale
I0423 22:44:03.301029 21205 net.cpp:122] Setting up conv3_em/scale
I0423 22:44:03.301036 21205 net.cpp:129] Top shape: 128 128 14 12 (2752512)
I0423 22:44:03.301039 21205 net.cpp:137] Memory required for data: 4079224832
I0423 22:44:03.301045 21205 layer_factory.hpp:77] Creating layer conv3_em_conv3_em/scale_0_split
I0423 22:44:03.301050 21205 net.cpp:84] Creating Layer conv3_em_conv3_em/scale_0_split
I0423 22:44:03.301053 21205 net.cpp:406] conv3_em_conv3_em/scale_0_split <- conv3_em
I0423 22:44:03.301057 21205 net.cpp:380] conv3_em_conv3_em/scale_0_split -> conv3_em_conv3_em/scale_0_split_0
I0423 22:44:03.301064 21205 net.cpp:380] conv3_em_conv3_em/scale_0_split -> conv3_em_conv3_em/scale_0_split_1
I0423 22:44:03.301105 21205 net.cpp:122] Setting up conv3_em_conv3_em/scale_0_split
I0423 22:44:03.301111 21205 net.cpp:129] Top shape: 128 128 14 12 (2752512)
I0423 22:44:03.301115 21205 net.cpp:129] Top shape: 128 128 14 12 (2752512)
I0423 22:44:03.301118 21205 net.cpp:137] Memory required for data: 4101244928
I0423 22:44:03.301121 21205 layer_factory.hpp:77] Creating layer conv3_1_ex
I0423 22:44:03.301128 21205 net.cpp:84] Creating Layer conv3_1_ex
I0423 22:44:03.301131 21205 net.cpp:406] conv3_1_ex <- conv3_em_conv3_em/scale_0_split_0
I0423 22:44:03.301136 21205 net.cpp:380] conv3_1_ex -> conv3_1_ex
I0423 22:44:03.303612 21205 net.cpp:122] Setting up conv3_1_ex
I0423 22:44:03.303645 21205 net.cpp:129] Top shape: 128 256 14 12 (5505024)
I0423 22:44:03.303650 21205 net.cpp:137] Memory required for data: 4123265024
I0423 22:44:03.303656 21205 layer_factory.hpp:77] Creating layer conv3_1_ex/bn
I0423 22:44:03.303663 21205 net.cpp:84] Creating Layer conv3_1_ex/bn
I0423 22:44:03.303666 21205 net.cpp:406] conv3_1_ex/bn <- conv3_1_ex
I0423 22:44:03.303671 21205 net.cpp:367] conv3_1_ex/bn -> conv3_1_ex (in-place)
I0423 22:44:03.303884 21205 net.cpp:122] Setting up conv3_1_ex/bn
I0423 22:44:03.303892 21205 net.cpp:129] Top shape: 128 256 14 12 (5505024)
I0423 22:44:03.303895 21205 net.cpp:137] Memory required for data: 4145285120
I0423 22:44:03.303902 21205 layer_factory.hpp:77] Creating layer conv3_1_ex/scale
I0423 22:44:03.303908 21205 net.cpp:84] Creating Layer conv3_1_ex/scale
I0423 22:44:03.303911 21205 net.cpp:406] conv3_1_ex/scale <- conv3_1_ex
I0423 22:44:03.303915 21205 net.cpp:367] conv3_1_ex/scale -> conv3_1_ex (in-place)
I0423 22:44:03.303954 21205 layer_factory.hpp:77] Creating layer conv3_1_ex/scale
I0423 22:44:03.304075 21205 net.cpp:122] Setting up conv3_1_ex/scale
I0423 22:44:03.304081 21205 net.cpp:129] Top shape: 128 256 14 12 (5505024)
I0423 22:44:03.304085 21205 net.cpp:137] Memory required for data: 4167305216
I0423 22:44:03.304090 21205 layer_factory.hpp:77] Creating layer relu3_1_ex
I0423 22:44:03.304095 21205 net.cpp:84] Creating Layer relu3_1_ex
I0423 22:44:03.304096 21205 net.cpp:406] relu3_1_ex <- conv3_1_ex
I0423 22:44:03.304100 21205 net.cpp:367] relu3_1_ex -> conv3_1_ex (in-place)
I0423 22:44:03.304220 21205 net.cpp:122] Setting up relu3_1_ex
I0423 22:44:03.304229 21205 net.cpp:129] Top shape: 128 256 14 12 (5505024)
I0423 22:44:03.304231 21205 net.cpp:137] Memory required for data: 4189325312
I0423 22:44:03.304235 21205 layer_factory.hpp:77] Creating layer conv3_1_dw
I0423 22:44:03.304242 21205 net.cpp:84] Creating Layer conv3_1_dw
I0423 22:44:03.304246 21205 net.cpp:406] conv3_1_dw <- conv3_1_ex
I0423 22:44:03.304250 21205 net.cpp:380] conv3_1_dw -> conv3_1_dw
I0423 22:44:03.304522 21205 net.cpp:122] Setting up conv3_1_dw
I0423 22:44:03.304530 21205 net.cpp:129] Top shape: 128 256 14 12 (5505024)
I0423 22:44:03.304533 21205 net.cpp:137] Memory required for data: 4211345408
I0423 22:44:03.304538 21205 layer_factory.hpp:77] Creating layer conv3_1_dw/bn
I0423 22:44:03.304544 21205 net.cpp:84] Creating Layer conv3_1_dw/bn
I0423 22:44:03.304546 21205 net.cpp:406] conv3_1_dw/bn <- conv3_1_dw
I0423 22:44:03.304551 21205 net.cpp:367] conv3_1_dw/bn -> conv3_1_dw (in-place)
I0423 22:44:03.304752 21205 net.cpp:122] Setting up conv3_1_dw/bn
I0423 22:44:03.304759 21205 net.cpp:129] Top shape: 128 256 14 12 (5505024)
I0423 22:44:03.304762 21205 net.cpp:137] Memory required for data: 4233365504
I0423 22:44:03.304769 21205 layer_factory.hpp:77] Creating layer conv3_1_dw/scale
I0423 22:44:03.304774 21205 net.cpp:84] Creating Layer conv3_1_dw/scale
I0423 22:44:03.304777 21205 net.cpp:406] conv3_1_dw/scale <- conv3_1_dw
I0423 22:44:03.304780 21205 net.cpp:367] conv3_1_dw/scale -> conv3_1_dw (in-place)
I0423 22:44:03.304818 21205 layer_factory.hpp:77] Creating layer conv3_1_dw/scale
I0423 22:44:03.304934 21205 net.cpp:122] Setting up conv3_1_dw/scale
I0423 22:44:03.304940 21205 net.cpp:129] Top shape: 128 256 14 12 (5505024)
I0423 22:44:03.304944 21205 net.cpp:137] Memory required for data: 4255385600
I0423 22:44:03.304949 21205 layer_factory.hpp:77] Creating layer relu3_1_dw
I0423 22:44:03.304953 21205 net.cpp:84] Creating Layer relu3_1_dw
I0423 22:44:03.304955 21205 net.cpp:406] relu3_1_dw <- conv3_1_dw
I0423 22:44:03.304960 21205 net.cpp:367] relu3_1_dw -> conv3_1_dw (in-place)
I0423 22:44:03.305078 21205 net.cpp:122] Setting up relu3_1_dw
I0423 22:44:03.305085 21205 net.cpp:129] Top shape: 128 256 14 12 (5505024)
I0423 22:44:03.305088 21205 net.cpp:137] Memory required for data: 4277405696
I0423 22:44:03.305093 21205 layer_factory.hpp:77] Creating layer conv3_1_em
I0423 22:44:03.305100 21205 net.cpp:84] Creating Layer conv3_1_em
I0423 22:44:03.305104 21205 net.cpp:406] conv3_1_em <- conv3_1_dw
I0423 22:44:03.305124 21205 net.cpp:380] conv3_1_em -> conv3_1_em
I0423 22:44:03.307885 21205 net.cpp:122] Setting up conv3_1_em
I0423 22:44:03.307902 21205 net.cpp:129] Top shape: 128 128 14 12 (2752512)
I0423 22:44:03.307905 21205 net.cpp:137] Memory required for data: 4288415744
I0423 22:44:03.307912 21205 layer_factory.hpp:77] Creating layer conv3_1_em/bn
I0423 22:44:03.307919 21205 net.cpp:84] Creating Layer conv3_1_em/bn
I0423 22:44:03.307922 21205 net.cpp:406] conv3_1_em/bn <- conv3_1_em
I0423 22:44:03.307927 21205 net.cpp:367] conv3_1_em/bn -> conv3_1_em (in-place)
I0423 22:44:03.308145 21205 net.cpp:122] Setting up conv3_1_em/bn
I0423 22:44:03.308152 21205 net.cpp:129] Top shape: 128 128 14 12 (2752512)
I0423 22:44:03.308156 21205 net.cpp:137] Memory required for data: 4299425792
I0423 22:44:03.308162 21205 layer_factory.hpp:77] Creating layer conv3_1_em/scale
I0423 22:44:03.308168 21205 net.cpp:84] Creating Layer conv3_1_em/scale
I0423 22:44:03.308171 21205 net.cpp:406] conv3_1_em/scale <- conv3_1_em
I0423 22:44:03.308176 21205 net.cpp:367] conv3_1_em/scale -> conv3_1_em (in-place)
I0423 22:44:03.308215 21205 layer_factory.hpp:77] Creating layer conv3_1_em/scale
I0423 22:44:03.308333 21205 net.cpp:122] Setting up conv3_1_em/scale
I0423 22:44:03.308341 21205 net.cpp:129] Top shape: 128 128 14 12 (2752512)
I0423 22:44:03.308343 21205 net.cpp:137] Memory required for data: 4310435840
I0423 22:44:03.308348 21205 layer_factory.hpp:77] Creating layer res3_1
I0423 22:44:03.308353 21205 net.cpp:84] Creating Layer res3_1
I0423 22:44:03.308357 21205 net.cpp:406] res3_1 <- conv3_em_conv3_em/scale_0_split_1
I0423 22:44:03.308362 21205 net.cpp:406] res3_1 <- conv3_1_em
I0423 22:44:03.308365 21205 net.cpp:380] res3_1 -> res3_1
I0423 22:44:03.308392 21205 net.cpp:122] Setting up res3_1
I0423 22:44:03.308398 21205 net.cpp:129] Top shape: 128 128 14 12 (2752512)
I0423 22:44:03.308401 21205 net.cpp:137] Memory required for data: 4321445888
I0423 22:44:03.308404 21205 layer_factory.hpp:77] Creating layer res3_1_res3_1_0_split
I0423 22:44:03.308409 21205 net.cpp:84] Creating Layer res3_1_res3_1_0_split
I0423 22:44:03.308411 21205 net.cpp:406] res3_1_res3_1_0_split <- res3_1
I0423 22:44:03.308418 21205 net.cpp:380] res3_1_res3_1_0_split -> res3_1_res3_1_0_split_0
I0423 22:44:03.308423 21205 net.cpp:380] res3_1_res3_1_0_split -> res3_1_res3_1_0_split_1
I0423 22:44:03.308460 21205 net.cpp:122] Setting up res3_1_res3_1_0_split
I0423 22:44:03.308466 21205 net.cpp:129] Top shape: 128 128 14 12 (2752512)
I0423 22:44:03.308471 21205 net.cpp:129] Top shape: 128 128 14 12 (2752512)
I0423 22:44:03.308473 21205 net.cpp:137] Memory required for data: 4343465984
I0423 22:44:03.308476 21205 layer_factory.hpp:77] Creating layer conv3_2_ex
I0423 22:44:03.308483 21205 net.cpp:84] Creating Layer conv3_2_ex
I0423 22:44:03.308487 21205 net.cpp:406] conv3_2_ex <- res3_1_res3_1_0_split_0
I0423 22:44:03.308491 21205 net.cpp:380] conv3_2_ex -> conv3_2_ex
I0423 22:44:03.310947 21205 net.cpp:122] Setting up conv3_2_ex
I0423 22:44:03.310963 21205 net.cpp:129] Top shape: 128 256 14 12 (5505024)
I0423 22:44:03.310967 21205 net.cpp:137] Memory required for data: 4365486080
I0423 22:44:03.310973 21205 layer_factory.hpp:77] Creating layer conv3_2_ex/bn
I0423 22:44:03.310981 21205 net.cpp:84] Creating Layer conv3_2_ex/bn
I0423 22:44:03.310984 21205 net.cpp:406] conv3_2_ex/bn <- conv3_2_ex
I0423 22:44:03.310992 21205 net.cpp:367] conv3_2_ex/bn -> conv3_2_ex (in-place)
I0423 22:44:03.311218 21205 net.cpp:122] Setting up conv3_2_ex/bn
I0423 22:44:03.311226 21205 net.cpp:129] Top shape: 128 256 14 12 (5505024)
I0423 22:44:03.311229 21205 net.cpp:137] Memory required for data: 4387506176
I0423 22:44:03.311236 21205 layer_factory.hpp:77] Creating layer conv3_2_ex/scale
I0423 22:44:03.311241 21205 net.cpp:84] Creating Layer conv3_2_ex/scale
I0423 22:44:03.311244 21205 net.cpp:406] conv3_2_ex/scale <- conv3_2_ex
I0423 22:44:03.311250 21205 net.cpp:367] conv3_2_ex/scale -> conv3_2_ex (in-place)
I0423 22:44:03.311291 21205 layer_factory.hpp:77] Creating layer conv3_2_ex/scale
I0423 22:44:03.311441 21205 net.cpp:122] Setting up conv3_2_ex/scale
I0423 22:44:03.311450 21205 net.cpp:129] Top shape: 128 256 14 12 (5505024)
I0423 22:44:03.311452 21205 net.cpp:137] Memory required for data: 4409526272
I0423 22:44:03.311458 21205 layer_factory.hpp:77] Creating layer relu3_2_ex
I0423 22:44:03.311465 21205 net.cpp:84] Creating Layer relu3_2_ex
I0423 22:44:03.311467 21205 net.cpp:406] relu3_2_ex <- conv3_2_ex
I0423 22:44:03.311471 21205 net.cpp:367] relu3_2_ex -> conv3_2_ex (in-place)
I0423 22:44:03.311596 21205 net.cpp:122] Setting up relu3_2_ex
I0423 22:44:03.311604 21205 net.cpp:129] Top shape: 128 256 14 12 (5505024)
I0423 22:44:03.311607 21205 net.cpp:137] Memory required for data: 4431546368
I0423 22:44:03.311611 21205 layer_factory.hpp:77] Creating layer conv3_2_dw
I0423 22:44:03.311619 21205 net.cpp:84] Creating Layer conv3_2_dw
I0423 22:44:03.311622 21205 net.cpp:406] conv3_2_dw <- conv3_2_ex
I0423 22:44:03.311630 21205 net.cpp:380] conv3_2_dw -> conv3_2_dw
I0423 22:44:03.311908 21205 net.cpp:122] Setting up conv3_2_dw
I0423 22:44:03.311918 21205 net.cpp:129] Top shape: 128 256 14 12 (5505024)
I0423 22:44:03.311920 21205 net.cpp:137] Memory required for data: 4453566464
I0423 22:44:03.311924 21205 layer_factory.hpp:77] Creating layer conv3_2_dw/bn
I0423 22:44:03.311929 21205 net.cpp:84] Creating Layer conv3_2_dw/bn
I0423 22:44:03.311933 21205 net.cpp:406] conv3_2_dw/bn <- conv3_2_dw
I0423 22:44:03.311939 21205 net.cpp:367] conv3_2_dw/bn -> conv3_2_dw (in-place)
I0423 22:44:03.312161 21205 net.cpp:122] Setting up conv3_2_dw/bn
I0423 22:44:03.312170 21205 net.cpp:129] Top shape: 128 256 14 12 (5505024)
I0423 22:44:03.312172 21205 net.cpp:137] Memory required for data: 4475586560
I0423 22:44:03.312178 21205 layer_factory.hpp:77] Creating layer conv3_2_dw/scale
I0423 22:44:03.312185 21205 net.cpp:84] Creating Layer conv3_2_dw/scale
I0423 22:44:03.312186 21205 net.cpp:406] conv3_2_dw/scale <- conv3_2_dw
I0423 22:44:03.312191 21205 net.cpp:367] conv3_2_dw/scale -> conv3_2_dw (in-place)
I0423 22:44:03.312232 21205 layer_factory.hpp:77] Creating layer conv3_2_dw/scale
I0423 22:44:03.312352 21205 net.cpp:122] Setting up conv3_2_dw/scale
I0423 22:44:03.312360 21205 net.cpp:129] Top shape: 128 256 14 12 (5505024)
I0423 22:44:03.312362 21205 net.cpp:137] Memory required for data: 4497606656
I0423 22:44:03.312367 21205 layer_factory.hpp:77] Creating layer relu3_2_dw
I0423 22:44:03.312371 21205 net.cpp:84] Creating Layer relu3_2_dw
I0423 22:44:03.312376 21205 net.cpp:406] relu3_2_dw <- conv3_2_dw
I0423 22:44:03.312381 21205 net.cpp:367] relu3_2_dw -> conv3_2_dw (in-place)
I0423 22:44:03.312505 21205 net.cpp:122] Setting up relu3_2_dw
I0423 22:44:03.312512 21205 net.cpp:129] Top shape: 128 256 14 12 (5505024)
I0423 22:44:03.312515 21205 net.cpp:137] Memory required for data: 4519626752
I0423 22:44:03.312520 21205 layer_factory.hpp:77] Creating layer conv3_2_em
I0423 22:44:03.312528 21205 net.cpp:84] Creating Layer conv3_2_em
I0423 22:44:03.312532 21205 net.cpp:406] conv3_2_em <- conv3_2_dw
I0423 22:44:03.312536 21205 net.cpp:380] conv3_2_em -> conv3_2_em
I0423 22:44:03.316629 21205 net.cpp:122] Setting up conv3_2_em
I0423 22:44:03.316645 21205 net.cpp:129] Top shape: 128 128 14 12 (2752512)
I0423 22:44:03.316648 21205 net.cpp:137] Memory required for data: 4530636800
I0423 22:44:03.316654 21205 layer_factory.hpp:77] Creating layer conv3_2_em/bn
I0423 22:44:03.316660 21205 net.cpp:84] Creating Layer conv3_2_em/bn
I0423 22:44:03.316664 21205 net.cpp:406] conv3_2_em/bn <- conv3_2_em
I0423 22:44:03.316670 21205 net.cpp:367] conv3_2_em/bn -> conv3_2_em (in-place)
I0423 22:44:03.316900 21205 net.cpp:122] Setting up conv3_2_em/bn
I0423 22:44:03.316910 21205 net.cpp:129] Top shape: 128 128 14 12 (2752512)
I0423 22:44:03.316911 21205 net.cpp:137] Memory required for data: 4541646848
I0423 22:44:03.316918 21205 layer_factory.hpp:77] Creating layer conv3_2_em/scale
I0423 22:44:03.316925 21205 net.cpp:84] Creating Layer conv3_2_em/scale
I0423 22:44:03.316928 21205 net.cpp:406] conv3_2_em/scale <- conv3_2_em
I0423 22:44:03.316949 21205 net.cpp:367] conv3_2_em/scale -> conv3_2_em (in-place)
I0423 22:44:03.316996 21205 layer_factory.hpp:77] Creating layer conv3_2_em/scale
I0423 22:44:03.317126 21205 net.cpp:122] Setting up conv3_2_em/scale
I0423 22:44:03.317136 21205 net.cpp:129] Top shape: 128 128 14 12 (2752512)
I0423 22:44:03.317137 21205 net.cpp:137] Memory required for data: 4552656896
I0423 22:44:03.317142 21205 layer_factory.hpp:77] Creating layer res3_2
I0423 22:44:03.317149 21205 net.cpp:84] Creating Layer res3_2
I0423 22:44:03.317153 21205 net.cpp:406] res3_2 <- res3_1_res3_1_0_split_1
I0423 22:44:03.317157 21205 net.cpp:406] res3_2 <- conv3_2_em
I0423 22:44:03.317162 21205 net.cpp:380] res3_2 -> res3_2
I0423 22:44:03.317191 21205 net.cpp:122] Setting up res3_2
I0423 22:44:03.317199 21205 net.cpp:129] Top shape: 128 128 14 12 (2752512)
I0423 22:44:03.317201 21205 net.cpp:137] Memory required for data: 4563666944
I0423 22:44:03.317204 21205 layer_factory.hpp:77] Creating layer res3_2_res3_2_0_split
I0423 22:44:03.317209 21205 net.cpp:84] Creating Layer res3_2_res3_2_0_split
I0423 22:44:03.317212 21205 net.cpp:406] res3_2_res3_2_0_split <- res3_2
I0423 22:44:03.317227 21205 net.cpp:380] res3_2_res3_2_0_split -> res3_2_res3_2_0_split_0
I0423 22:44:03.317234 21205 net.cpp:380] res3_2_res3_2_0_split -> res3_2_res3_2_0_split_1
I0423 22:44:03.317279 21205 net.cpp:122] Setting up res3_2_res3_2_0_split
I0423 22:44:03.317287 21205 net.cpp:129] Top shape: 128 128 14 12 (2752512)
I0423 22:44:03.317291 21205 net.cpp:129] Top shape: 128 128 14 12 (2752512)
I0423 22:44:03.317292 21205 net.cpp:137] Memory required for data: 4585687040
I0423 22:44:03.317296 21205 layer_factory.hpp:77] Creating layer conv3_3_ex
I0423 22:44:03.317303 21205 net.cpp:84] Creating Layer conv3_3_ex
I0423 22:44:03.317306 21205 net.cpp:406] conv3_3_ex <- res3_2_res3_2_0_split_0
I0423 22:44:03.317313 21205 net.cpp:380] conv3_3_ex -> conv3_3_ex
I0423 22:44:03.320030 21205 net.cpp:122] Setting up conv3_3_ex
I0423 22:44:03.320047 21205 net.cpp:129] Top shape: 128 256 14 12 (5505024)
I0423 22:44:03.320050 21205 net.cpp:137] Memory required for data: 4607707136
I0423 22:44:03.320055 21205 layer_factory.hpp:77] Creating layer conv3_3_ex/bn
I0423 22:44:03.320062 21205 net.cpp:84] Creating Layer conv3_3_ex/bn
I0423 22:44:03.320067 21205 net.cpp:406] conv3_3_ex/bn <- conv3_3_ex
I0423 22:44:03.320072 21205 net.cpp:367] conv3_3_ex/bn -> conv3_3_ex (in-place)
I0423 22:44:03.320302 21205 net.cpp:122] Setting up conv3_3_ex/bn
I0423 22:44:03.320312 21205 net.cpp:129] Top shape: 128 256 14 12 (5505024)
I0423 22:44:03.320314 21205 net.cpp:137] Memory required for data: 4629727232
I0423 22:44:03.320320 21205 layer_factory.hpp:77] Creating layer conv3_3_ex/scale
I0423 22:44:03.320327 21205 net.cpp:84] Creating Layer conv3_3_ex/scale
I0423 22:44:03.320329 21205 net.cpp:406] conv3_3_ex/scale <- conv3_3_ex
I0423 22:44:03.320336 21205 net.cpp:367] conv3_3_ex/scale -> conv3_3_ex (in-place)
I0423 22:44:03.320377 21205 layer_factory.hpp:77] Creating layer conv3_3_ex/scale
I0423 22:44:03.320508 21205 net.cpp:122] Setting up conv3_3_ex/scale
I0423 22:44:03.320515 21205 net.cpp:129] Top shape: 128 256 14 12 (5505024)
I0423 22:44:03.320518 21205 net.cpp:137] Memory required for data: 4651747328
I0423 22:44:03.320523 21205 layer_factory.hpp:77] Creating layer relu3_3_ex
I0423 22:44:03.320528 21205 net.cpp:84] Creating Layer relu3_3_ex
I0423 22:44:03.320530 21205 net.cpp:406] relu3_3_ex <- conv3_3_ex
I0423 22:44:03.320535 21205 net.cpp:367] relu3_3_ex -> conv3_3_ex (in-place)
I0423 22:44:03.320662 21205 net.cpp:122] Setting up relu3_3_ex
I0423 22:44:03.320672 21205 net.cpp:129] Top shape: 128 256 14 12 (5505024)
I0423 22:44:03.320673 21205 net.cpp:137] Memory required for data: 4673767424
I0423 22:44:03.320678 21205 layer_factory.hpp:77] Creating layer conv3_3_dw
I0423 22:44:03.320684 21205 net.cpp:84] Creating Layer conv3_3_dw
I0423 22:44:03.320688 21205 net.cpp:406] conv3_3_dw <- conv3_3_ex
I0423 22:44:03.320693 21205 net.cpp:380] conv3_3_dw -> conv3_3_dw
I0423 22:44:03.320986 21205 net.cpp:122] Setting up conv3_3_dw
I0423 22:44:03.321012 21205 net.cpp:129] Top shape: 128 256 14 12 (5505024)
I0423 22:44:03.321014 21205 net.cpp:137] Memory required for data: 4695787520
I0423 22:44:03.321020 21205 layer_factory.hpp:77] Creating layer conv3_3_dw/bn
I0423 22:44:03.321027 21205 net.cpp:84] Creating Layer conv3_3_dw/bn
I0423 22:44:03.321029 21205 net.cpp:406] conv3_3_dw/bn <- conv3_3_dw
I0423 22:44:03.321035 21205 net.cpp:367] conv3_3_dw/bn -> conv3_3_dw (in-place)
I0423 22:44:03.321270 21205 net.cpp:122] Setting up conv3_3_dw/bn
I0423 22:44:03.321280 21205 net.cpp:129] Top shape: 128 256 14 12 (5505024)
I0423 22:44:03.321282 21205 net.cpp:137] Memory required for data: 4717807616
I0423 22:44:03.321288 21205 layer_factory.hpp:77] Creating layer conv3_3_dw/scale
I0423 22:44:03.321293 21205 net.cpp:84] Creating Layer conv3_3_dw/scale
I0423 22:44:03.321296 21205 net.cpp:406] conv3_3_dw/scale <- conv3_3_dw
I0423 22:44:03.321302 21205 net.cpp:367] conv3_3_dw/scale -> conv3_3_dw (in-place)
I0423 22:44:03.321342 21205 layer_factory.hpp:77] Creating layer conv3_3_dw/scale
I0423 22:44:03.321470 21205 net.cpp:122] Setting up conv3_3_dw/scale
I0423 22:44:03.321478 21205 net.cpp:129] Top shape: 128 256 14 12 (5505024)
I0423 22:44:03.321481 21205 net.cpp:137] Memory required for data: 4739827712
I0423 22:44:03.321486 21205 layer_factory.hpp:77] Creating layer relu3_3_dw
I0423 22:44:03.321491 21205 net.cpp:84] Creating Layer relu3_3_dw
I0423 22:44:03.321494 21205 net.cpp:406] relu3_3_dw <- conv3_3_dw
I0423 22:44:03.321497 21205 net.cpp:367] relu3_3_dw -> conv3_3_dw (in-place)
I0423 22:44:03.322494 21205 net.cpp:122] Setting up relu3_3_dw
I0423 22:44:03.322508 21205 net.cpp:129] Top shape: 128 256 14 12 (5505024)
I0423 22:44:03.322512 21205 net.cpp:137] Memory required for data: 4761847808
I0423 22:44:03.322517 21205 layer_factory.hpp:77] Creating layer conv3_3_em
I0423 22:44:03.322526 21205 net.cpp:84] Creating Layer conv3_3_em
I0423 22:44:03.322530 21205 net.cpp:406] conv3_3_em <- conv3_3_dw
I0423 22:44:03.322537 21205 net.cpp:380] conv3_3_em -> conv3_3_em
I0423 22:44:03.325898 21205 net.cpp:122] Setting up conv3_3_em
I0423 22:44:03.325915 21205 net.cpp:129] Top shape: 128 128 14 12 (2752512)
I0423 22:44:03.325918 21205 net.cpp:137] Memory required for data: 4772857856
I0423 22:44:03.325924 21205 layer_factory.hpp:77] Creating layer conv3_3_em/bn
I0423 22:44:03.325932 21205 net.cpp:84] Creating Layer conv3_3_em/bn
I0423 22:44:03.325935 21205 net.cpp:406] conv3_3_em/bn <- conv3_3_em
I0423 22:44:03.325942 21205 net.cpp:367] conv3_3_em/bn -> conv3_3_em (in-place)
I0423 22:44:03.326179 21205 net.cpp:122] Setting up conv3_3_em/bn
I0423 22:44:03.326187 21205 net.cpp:129] Top shape: 128 128 14 12 (2752512)
I0423 22:44:03.326190 21205 net.cpp:137] Memory required for data: 4783867904
I0423 22:44:03.326197 21205 layer_factory.hpp:77] Creating layer conv3_3_em/scale
I0423 22:44:03.326203 21205 net.cpp:84] Creating Layer conv3_3_em/scale
I0423 22:44:03.326206 21205 net.cpp:406] conv3_3_em/scale <- conv3_3_em
I0423 22:44:03.326210 21205 net.cpp:367] conv3_3_em/scale -> conv3_3_em (in-place)
I0423 22:44:03.326254 21205 layer_factory.hpp:77] Creating layer conv3_3_em/scale
I0423 22:44:03.326387 21205 net.cpp:122] Setting up conv3_3_em/scale
I0423 22:44:03.326395 21205 net.cpp:129] Top shape: 128 128 14 12 (2752512)
I0423 22:44:03.326397 21205 net.cpp:137] Memory required for data: 4794877952
I0423 22:44:03.326402 21205 layer_factory.hpp:77] Creating layer res3_3
I0423 22:44:03.326407 21205 net.cpp:84] Creating Layer res3_3
I0423 22:44:03.326411 21205 net.cpp:406] res3_3 <- res3_2_res3_2_0_split_1
I0423 22:44:03.326414 21205 net.cpp:406] res3_3 <- conv3_3_em
I0423 22:44:03.326421 21205 net.cpp:380] res3_3 -> res3_3
I0423 22:44:03.326448 21205 net.cpp:122] Setting up res3_3
I0423 22:44:03.326455 21205 net.cpp:129] Top shape: 128 128 14 12 (2752512)
I0423 22:44:03.326457 21205 net.cpp:137] Memory required for data: 4805888000
I0423 22:44:03.326460 21205 layer_factory.hpp:77] Creating layer res3_3_res3_3_0_split
I0423 22:44:03.326467 21205 net.cpp:84] Creating Layer res3_3_res3_3_0_split
I0423 22:44:03.326488 21205 net.cpp:406] res3_3_res3_3_0_split <- res3_3
I0423 22:44:03.326494 21205 net.cpp:380] res3_3_res3_3_0_split -> res3_3_res3_3_0_split_0
I0423 22:44:03.326500 21205 net.cpp:380] res3_3_res3_3_0_split -> res3_3_res3_3_0_split_1
I0423 22:44:03.326547 21205 net.cpp:122] Setting up res3_3_res3_3_0_split
I0423 22:44:03.326555 21205 net.cpp:129] Top shape: 128 128 14 12 (2752512)
I0423 22:44:03.326557 21205 net.cpp:129] Top shape: 128 128 14 12 (2752512)
I0423 22:44:03.326560 21205 net.cpp:137] Memory required for data: 4827908096
I0423 22:44:03.326563 21205 layer_factory.hpp:77] Creating layer conv3_4_ex
I0423 22:44:03.326571 21205 net.cpp:84] Creating Layer conv3_4_ex
I0423 22:44:03.326575 21205 net.cpp:406] conv3_4_ex <- res3_3_res3_3_0_split_0
I0423 22:44:03.326581 21205 net.cpp:380] conv3_4_ex -> conv3_4_ex
I0423 22:44:03.329308 21205 net.cpp:122] Setting up conv3_4_ex
I0423 22:44:03.329322 21205 net.cpp:129] Top shape: 128 256 14 12 (5505024)
I0423 22:44:03.329326 21205 net.cpp:137] Memory required for data: 4849928192
I0423 22:44:03.329331 21205 layer_factory.hpp:77] Creating layer conv3_4_ex/bn
I0423 22:44:03.329339 21205 net.cpp:84] Creating Layer conv3_4_ex/bn
I0423 22:44:03.329344 21205 net.cpp:406] conv3_4_ex/bn <- conv3_4_ex
I0423 22:44:03.329349 21205 net.cpp:367] conv3_4_ex/bn -> conv3_4_ex (in-place)
I0423 22:44:03.329581 21205 net.cpp:122] Setting up conv3_4_ex/bn
I0423 22:44:03.329588 21205 net.cpp:129] Top shape: 128 256 14 12 (5505024)
I0423 22:44:03.329591 21205 net.cpp:137] Memory required for data: 4871948288
I0423 22:44:03.329597 21205 layer_factory.hpp:77] Creating layer conv3_4_ex/scale
I0423 22:44:03.329604 21205 net.cpp:84] Creating Layer conv3_4_ex/scale
I0423 22:44:03.329608 21205 net.cpp:406] conv3_4_ex/scale <- conv3_4_ex
I0423 22:44:03.329612 21205 net.cpp:367] conv3_4_ex/scale -> conv3_4_ex (in-place)
I0423 22:44:03.329654 21205 layer_factory.hpp:77] Creating layer conv3_4_ex/scale
I0423 22:44:03.329789 21205 net.cpp:122] Setting up conv3_4_ex/scale
I0423 22:44:03.329797 21205 net.cpp:129] Top shape: 128 256 14 12 (5505024)
I0423 22:44:03.329799 21205 net.cpp:137] Memory required for data: 4893968384
I0423 22:44:03.329805 21205 layer_factory.hpp:77] Creating layer relu3_4_ex
I0423 22:44:03.329809 21205 net.cpp:84] Creating Layer relu3_4_ex
I0423 22:44:03.329813 21205 net.cpp:406] relu3_4_ex <- conv3_4_ex
I0423 22:44:03.329818 21205 net.cpp:367] relu3_4_ex -> conv3_4_ex (in-place)
I0423 22:44:03.329946 21205 net.cpp:122] Setting up relu3_4_ex
I0423 22:44:03.329953 21205 net.cpp:129] Top shape: 128 256 14 12 (5505024)
I0423 22:44:03.329957 21205 net.cpp:137] Memory required for data: 4915988480
I0423 22:44:03.329962 21205 layer_factory.hpp:77] Creating layer conv3_4_dw
I0423 22:44:03.329979 21205 net.cpp:84] Creating Layer conv3_4_dw
I0423 22:44:03.329984 21205 net.cpp:406] conv3_4_dw <- conv3_4_ex
I0423 22:44:03.329990 21205 net.cpp:380] conv3_4_dw -> conv3_4_dw
I0423 22:44:03.330282 21205 net.cpp:122] Setting up conv3_4_dw
I0423 22:44:03.330291 21205 net.cpp:129] Top shape: 128 256 14 12 (5505024)
I0423 22:44:03.330293 21205 net.cpp:137] Memory required for data: 4938008576
I0423 22:44:03.330299 21205 layer_factory.hpp:77] Creating layer conv3_4_dw/bn
I0423 22:44:03.330305 21205 net.cpp:84] Creating Layer conv3_4_dw/bn
I0423 22:44:03.330308 21205 net.cpp:406] conv3_4_dw/bn <- conv3_4_dw
I0423 22:44:03.330312 21205 net.cpp:367] conv3_4_dw/bn -> conv3_4_dw (in-place)
I0423 22:44:03.330533 21205 net.cpp:122] Setting up conv3_4_dw/bn
I0423 22:44:03.330540 21205 net.cpp:129] Top shape: 128 256 14 12 (5505024)
I0423 22:44:03.330543 21205 net.cpp:137] Memory required for data: 4960028672
I0423 22:44:03.330549 21205 layer_factory.hpp:77] Creating layer conv3_4_dw/scale
I0423 22:44:03.330555 21205 net.cpp:84] Creating Layer conv3_4_dw/scale
I0423 22:44:03.330557 21205 net.cpp:406] conv3_4_dw/scale <- conv3_4_dw
I0423 22:44:03.330561 21205 net.cpp:367] conv3_4_dw/scale -> conv3_4_dw (in-place)
I0423 22:44:03.330602 21205 layer_factory.hpp:77] Creating layer conv3_4_dw/scale
I0423 22:44:03.330755 21205 net.cpp:122] Setting up conv3_4_dw/scale
I0423 22:44:03.330763 21205 net.cpp:129] Top shape: 128 256 14 12 (5505024)
I0423 22:44:03.330766 21205 net.cpp:137] Memory required for data: 4982048768
I0423 22:44:03.330771 21205 layer_factory.hpp:77] Creating layer relu3_4_dw
I0423 22:44:03.330776 21205 net.cpp:84] Creating Layer relu3_4_dw
I0423 22:44:03.330780 21205 net.cpp:406] relu3_4_dw <- conv3_4_dw
I0423 22:44:03.330785 21205 net.cpp:367] relu3_4_dw -> conv3_4_dw (in-place)
I0423 22:44:03.330909 21205 net.cpp:122] Setting up relu3_4_dw
I0423 22:44:03.330917 21205 net.cpp:129] Top shape: 128 256 14 12 (5505024)
I0423 22:44:03.330919 21205 net.cpp:137] Memory required for data: 5004068864
I0423 22:44:03.330924 21205 layer_factory.hpp:77] Creating layer conv3_4_em
I0423 22:44:03.330932 21205 net.cpp:84] Creating Layer conv3_4_em
I0423 22:44:03.330936 21205 net.cpp:406] conv3_4_em <- conv3_4_dw
I0423 22:44:03.330940 21205 net.cpp:380] conv3_4_em -> conv3_4_em
I0423 22:44:03.333709 21205 net.cpp:122] Setting up conv3_4_em
I0423 22:44:03.333725 21205 net.cpp:129] Top shape: 128 128 14 12 (2752512)
I0423 22:44:03.333729 21205 net.cpp:137] Memory required for data: 5015078912
I0423 22:44:03.333735 21205 layer_factory.hpp:77] Creating layer conv3_4_em/bn
I0423 22:44:03.333742 21205 net.cpp:84] Creating Layer conv3_4_em/bn
I0423 22:44:03.333746 21205 net.cpp:406] conv3_4_em/bn <- conv3_4_em
I0423 22:44:03.333752 21205 net.cpp:367] conv3_4_em/bn -> conv3_4_em (in-place)
I0423 22:44:03.333983 21205 net.cpp:122] Setting up conv3_4_em/bn
I0423 22:44:03.333992 21205 net.cpp:129] Top shape: 128 128 14 12 (2752512)
I0423 22:44:03.333994 21205 net.cpp:137] Memory required for data: 5026088960
I0423 22:44:03.334002 21205 layer_factory.hpp:77] Creating layer conv3_4_em/scale
I0423 22:44:03.334009 21205 net.cpp:84] Creating Layer conv3_4_em/scale
I0423 22:44:03.334015 21205 net.cpp:406] conv3_4_em/scale <- conv3_4_em
I0423 22:44:03.334020 21205 net.cpp:367] conv3_4_em/scale -> conv3_4_em (in-place)
I0423 22:44:03.334064 21205 layer_factory.hpp:77] Creating layer conv3_4_em/scale
I0423 22:44:03.334194 21205 net.cpp:122] Setting up conv3_4_em/scale
I0423 22:44:03.334201 21205 net.cpp:129] Top shape: 128 128 14 12 (2752512)
I0423 22:44:03.334204 21205 net.cpp:137] Memory required for data: 5037099008
I0423 22:44:03.334210 21205 layer_factory.hpp:77] Creating layer res3_4
I0423 22:44:03.334214 21205 net.cpp:84] Creating Layer res3_4
I0423 22:44:03.334218 21205 net.cpp:406] res3_4 <- res3_3_res3_3_0_split_1
I0423 22:44:03.334221 21205 net.cpp:406] res3_4 <- conv3_4_em
I0423 22:44:03.334228 21205 net.cpp:380] res3_4 -> res3_4
I0423 22:44:03.334257 21205 net.cpp:122] Setting up res3_4
I0423 22:44:03.334264 21205 net.cpp:129] Top shape: 128 128 14 12 (2752512)
I0423 22:44:03.334266 21205 net.cpp:137] Memory required for data: 5048109056
I0423 22:44:03.334270 21205 layer_factory.hpp:77] Creating layer res3_4_res3_4_0_split
I0423 22:44:03.334275 21205 net.cpp:84] Creating Layer res3_4_res3_4_0_split
I0423 22:44:03.334277 21205 net.cpp:406] res3_4_res3_4_0_split <- res3_4
I0423 22:44:03.334283 21205 net.cpp:380] res3_4_res3_4_0_split -> res3_4_res3_4_0_split_0
I0423 22:44:03.334290 21205 net.cpp:380] res3_4_res3_4_0_split -> res3_4_res3_4_0_split_1
I0423 22:44:03.334331 21205 net.cpp:122] Setting up res3_4_res3_4_0_split
I0423 22:44:03.334337 21205 net.cpp:129] Top shape: 128 128 14 12 (2752512)
I0423 22:44:03.334341 21205 net.cpp:129] Top shape: 128 128 14 12 (2752512)
I0423 22:44:03.334344 21205 net.cpp:137] Memory required for data: 5070129152
I0423 22:44:03.334347 21205 layer_factory.hpp:77] Creating layer conv3_5_ex
I0423 22:44:03.334357 21205 net.cpp:84] Creating Layer conv3_5_ex
I0423 22:44:03.334360 21205 net.cpp:406] conv3_5_ex <- res3_4_res3_4_0_split_0
I0423 22:44:03.334367 21205 net.cpp:380] conv3_5_ex -> conv3_5_ex
I0423 22:44:03.337852 21205 net.cpp:122] Setting up conv3_5_ex
I0423 22:44:03.337868 21205 net.cpp:129] Top shape: 128 256 14 12 (5505024)
I0423 22:44:03.337889 21205 net.cpp:137] Memory required for data: 5092149248
I0423 22:44:03.337896 21205 layer_factory.hpp:77] Creating layer conv3_5_ex/bn
I0423 22:44:03.337903 21205 net.cpp:84] Creating Layer conv3_5_ex/bn
I0423 22:44:03.337906 21205 net.cpp:406] conv3_5_ex/bn <- conv3_5_ex
I0423 22:44:03.337913 21205 net.cpp:367] conv3_5_ex/bn -> conv3_5_ex (in-place)
I0423 22:44:03.338150 21205 net.cpp:122] Setting up conv3_5_ex/bn
I0423 22:44:03.338158 21205 net.cpp:129] Top shape: 128 256 14 12 (5505024)
I0423 22:44:03.338160 21205 net.cpp:137] Memory required for data: 5114169344
I0423 22:44:03.338167 21205 layer_factory.hpp:77] Creating layer conv3_5_ex/scale
I0423 22:44:03.338173 21205 net.cpp:84] Creating Layer conv3_5_ex/scale
I0423 22:44:03.338176 21205 net.cpp:406] conv3_5_ex/scale <- conv3_5_ex
I0423 22:44:03.338181 21205 net.cpp:367] conv3_5_ex/scale -> conv3_5_ex (in-place)
I0423 22:44:03.338223 21205 layer_factory.hpp:77] Creating layer conv3_5_ex/scale
I0423 22:44:03.338354 21205 net.cpp:122] Setting up conv3_5_ex/scale
I0423 22:44:03.338363 21205 net.cpp:129] Top shape: 128 256 14 12 (5505024)
I0423 22:44:03.338366 21205 net.cpp:137] Memory required for data: 5136189440
I0423 22:44:03.338371 21205 layer_factory.hpp:77] Creating layer relu3_5_ex
I0423 22:44:03.338376 21205 net.cpp:84] Creating Layer relu3_5_ex
I0423 22:44:03.338378 21205 net.cpp:406] relu3_5_ex <- conv3_5_ex
I0423 22:44:03.338382 21205 net.cpp:367] relu3_5_ex -> conv3_5_ex (in-place)
I0423 22:44:03.338511 21205 net.cpp:122] Setting up relu3_5_ex
I0423 22:44:03.338520 21205 net.cpp:129] Top shape: 128 256 14 12 (5505024)
I0423 22:44:03.338522 21205 net.cpp:137] Memory required for data: 5158209536
I0423 22:44:03.338526 21205 layer_factory.hpp:77] Creating layer conv3_5_dw
I0423 22:44:03.338532 21205 net.cpp:84] Creating Layer conv3_5_dw
I0423 22:44:03.338536 21205 net.cpp:406] conv3_5_dw <- conv3_5_ex
I0423 22:44:03.338542 21205 net.cpp:380] conv3_5_dw -> conv3_5_dw
I0423 22:44:03.338840 21205 net.cpp:122] Setting up conv3_5_dw
I0423 22:44:03.338850 21205 net.cpp:129] Top shape: 128 256 14 12 (5505024)
I0423 22:44:03.338853 21205 net.cpp:137] Memory required for data: 5180229632
I0423 22:44:03.338858 21205 layer_factory.hpp:77] Creating layer conv3_5_dw/bn
I0423 22:44:03.338863 21205 net.cpp:84] Creating Layer conv3_5_dw/bn
I0423 22:44:03.338866 21205 net.cpp:406] conv3_5_dw/bn <- conv3_5_dw
I0423 22:44:03.338871 21205 net.cpp:367] conv3_5_dw/bn -> conv3_5_dw (in-place)
I0423 22:44:03.339098 21205 net.cpp:122] Setting up conv3_5_dw/bn
I0423 22:44:03.339107 21205 net.cpp:129] Top shape: 128 256 14 12 (5505024)
I0423 22:44:03.339108 21205 net.cpp:137] Memory required for data: 5202249728
I0423 22:44:03.339115 21205 layer_factory.hpp:77] Creating layer conv3_5_dw/scale
I0423 22:44:03.339120 21205 net.cpp:84] Creating Layer conv3_5_dw/scale
I0423 22:44:03.339123 21205 net.cpp:406] conv3_5_dw/scale <- conv3_5_dw
I0423 22:44:03.339128 21205 net.cpp:367] conv3_5_dw/scale -> conv3_5_dw (in-place)
I0423 22:44:03.339169 21205 layer_factory.hpp:77] Creating layer conv3_5_dw/scale
I0423 22:44:03.339299 21205 net.cpp:122] Setting up conv3_5_dw/scale
I0423 22:44:03.339306 21205 net.cpp:129] Top shape: 128 256 14 12 (5505024)
I0423 22:44:03.339308 21205 net.cpp:137] Memory required for data: 5224269824
I0423 22:44:03.339314 21205 layer_factory.hpp:77] Creating layer relu3_5_dw
I0423 22:44:03.339318 21205 net.cpp:84] Creating Layer relu3_5_dw
I0423 22:44:03.339321 21205 net.cpp:406] relu3_5_dw <- conv3_5_dw
I0423 22:44:03.339326 21205 net.cpp:367] relu3_5_dw -> conv3_5_dw (in-place)
I0423 22:44:03.339452 21205 net.cpp:122] Setting up relu3_5_dw
I0423 22:44:03.339458 21205 net.cpp:129] Top shape: 128 256 14 12 (5505024)
I0423 22:44:03.339462 21205 net.cpp:137] Memory required for data: 5246289920
I0423 22:44:03.339465 21205 layer_factory.hpp:77] Creating layer conv3_5_em
I0423 22:44:03.339473 21205 net.cpp:84] Creating Layer conv3_5_em
I0423 22:44:03.339476 21205 net.cpp:406] conv3_5_em <- conv3_5_dw
I0423 22:44:03.339481 21205 net.cpp:380] conv3_5_em -> conv3_5_em
I0423 22:44:03.342192 21205 net.cpp:122] Setting up conv3_5_em
I0423 22:44:03.342209 21205 net.cpp:129] Top shape: 128 128 14 12 (2752512)
I0423 22:44:03.342212 21205 net.cpp:137] Memory required for data: 5257299968
I0423 22:44:03.342217 21205 layer_factory.hpp:77] Creating layer conv3_5_em/bn
I0423 22:44:03.342226 21205 net.cpp:84] Creating Layer conv3_5_em/bn
I0423 22:44:03.342231 21205 net.cpp:406] conv3_5_em/bn <- conv3_5_em
I0423 22:44:03.342236 21205 net.cpp:367] conv3_5_em/bn -> conv3_5_em (in-place)
I0423 22:44:03.342471 21205 net.cpp:122] Setting up conv3_5_em/bn
I0423 22:44:03.342480 21205 net.cpp:129] Top shape: 128 128 14 12 (2752512)
I0423 22:44:03.342483 21205 net.cpp:137] Memory required for data: 5268310016
I0423 22:44:03.342490 21205 layer_factory.hpp:77] Creating layer conv3_5_em/scale
I0423 22:44:03.342497 21205 net.cpp:84] Creating Layer conv3_5_em/scale
I0423 22:44:03.342500 21205 net.cpp:406] conv3_5_em/scale <- conv3_5_em
I0423 22:44:03.342505 21205 net.cpp:367] conv3_5_em/scale -> conv3_5_em (in-place)
I0423 22:44:03.342547 21205 layer_factory.hpp:77] Creating layer conv3_5_em/scale
I0423 22:44:03.342681 21205 net.cpp:122] Setting up conv3_5_em/scale
I0423 22:44:03.342689 21205 net.cpp:129] Top shape: 128 128 14 12 (2752512)
I0423 22:44:03.342691 21205 net.cpp:137] Memory required for data: 5279320064
I0423 22:44:03.342696 21205 layer_factory.hpp:77] Creating layer res3_5
I0423 22:44:03.342701 21205 net.cpp:84] Creating Layer res3_5
I0423 22:44:03.342705 21205 net.cpp:406] res3_5 <- res3_4_res3_4_0_split_1
I0423 22:44:03.342710 21205 net.cpp:406] res3_5 <- conv3_5_em
I0423 22:44:03.342715 21205 net.cpp:380] res3_5 -> res3_5
I0423 22:44:03.342743 21205 net.cpp:122] Setting up res3_5
I0423 22:44:03.342751 21205 net.cpp:129] Top shape: 128 128 14 12 (2752512)
I0423 22:44:03.342754 21205 net.cpp:137] Memory required for data: 5290330112
I0423 22:44:03.342758 21205 layer_factory.hpp:77] Creating layer res3_5_res3_5_0_split
I0423 22:44:03.342763 21205 net.cpp:84] Creating Layer res3_5_res3_5_0_split
I0423 22:44:03.342766 21205 net.cpp:406] res3_5_res3_5_0_split <- res3_5
I0423 22:44:03.342770 21205 net.cpp:380] res3_5_res3_5_0_split -> res3_5_res3_5_0_split_0
I0423 22:44:03.342777 21205 net.cpp:380] res3_5_res3_5_0_split -> res3_5_res3_5_0_split_1
I0423 22:44:03.342819 21205 net.cpp:122] Setting up res3_5_res3_5_0_split
I0423 22:44:03.342825 21205 net.cpp:129] Top shape: 128 128 14 12 (2752512)
I0423 22:44:03.342829 21205 net.cpp:129] Top shape: 128 128 14 12 (2752512)
I0423 22:44:03.342831 21205 net.cpp:137] Memory required for data: 5312350208
I0423 22:44:03.342834 21205 layer_factory.hpp:77] Creating layer conv3_6_ex
I0423 22:44:03.342844 21205 net.cpp:84] Creating Layer conv3_6_ex
I0423 22:44:03.342849 21205 net.cpp:406] conv3_6_ex <- res3_5_res3_5_0_split_0
I0423 22:44:03.342854 21205 net.cpp:380] conv3_6_ex -> conv3_6_ex
I0423 22:44:03.345585 21205 net.cpp:122] Setting up conv3_6_ex
I0423 22:44:03.345602 21205 net.cpp:129] Top shape: 128 256 14 12 (5505024)
I0423 22:44:03.345605 21205 net.cpp:137] Memory required for data: 5334370304
I0423 22:44:03.345612 21205 layer_factory.hpp:77] Creating layer conv3_6_ex/bn
I0423 22:44:03.345618 21205 net.cpp:84] Creating Layer conv3_6_ex/bn
I0423 22:44:03.345621 21205 net.cpp:406] conv3_6_ex/bn <- conv3_6_ex
I0423 22:44:03.345628 21205 net.cpp:367] conv3_6_ex/bn -> conv3_6_ex (in-place)
I0423 22:44:03.345865 21205 net.cpp:122] Setting up conv3_6_ex/bn
I0423 22:44:03.345873 21205 net.cpp:129] Top shape: 128 256 14 12 (5505024)
I0423 22:44:03.345875 21205 net.cpp:137] Memory required for data: 5356390400
I0423 22:44:03.345883 21205 layer_factory.hpp:77] Creating layer conv3_6_ex/scale
I0423 22:44:03.345888 21205 net.cpp:84] Creating Layer conv3_6_ex/scale
I0423 22:44:03.345891 21205 net.cpp:406] conv3_6_ex/scale <- conv3_6_ex
I0423 22:44:03.345896 21205 net.cpp:367] conv3_6_ex/scale -> conv3_6_ex (in-place)
I0423 22:44:03.345939 21205 layer_factory.hpp:77] Creating layer conv3_6_ex/scale
I0423 22:44:03.346072 21205 net.cpp:122] Setting up conv3_6_ex/scale
I0423 22:44:03.346096 21205 net.cpp:129] Top shape: 128 256 14 12 (5505024)
I0423 22:44:03.346101 21205 net.cpp:137] Memory required for data: 5378410496
I0423 22:44:03.346107 21205 layer_factory.hpp:77] Creating layer relu3_6_ex
I0423 22:44:03.346112 21205 net.cpp:84] Creating Layer relu3_6_ex
I0423 22:44:03.346115 21205 net.cpp:406] relu3_6_ex <- conv3_6_ex
I0423 22:44:03.346119 21205 net.cpp:367] relu3_6_ex -> conv3_6_ex (in-place)
I0423 22:44:03.346251 21205 net.cpp:122] Setting up relu3_6_ex
I0423 22:44:03.346259 21205 net.cpp:129] Top shape: 128 256 14 12 (5505024)
I0423 22:44:03.346262 21205 net.cpp:137] Memory required for data: 5400430592
I0423 22:44:03.346266 21205 layer_factory.hpp:77] Creating layer conv3_6_dw
I0423 22:44:03.346274 21205 net.cpp:84] Creating Layer conv3_6_dw
I0423 22:44:03.346277 21205 net.cpp:406] conv3_6_dw <- conv3_6_ex
I0423 22:44:03.346282 21205 net.cpp:380] conv3_6_dw -> conv3_6_dw
I0423 22:44:03.346576 21205 net.cpp:122] Setting up conv3_6_dw
I0423 22:44:03.346586 21205 net.cpp:129] Top shape: 128 256 14 12 (5505024)
I0423 22:44:03.346590 21205 net.cpp:137] Memory required for data: 5422450688
I0423 22:44:03.346595 21205 layer_factory.hpp:77] Creating layer conv3_6_dw/bn
I0423 22:44:03.346599 21205 net.cpp:84] Creating Layer conv3_6_dw/bn
I0423 22:44:03.346603 21205 net.cpp:406] conv3_6_dw/bn <- conv3_6_dw
I0423 22:44:03.346607 21205 net.cpp:367] conv3_6_dw/bn -> conv3_6_dw (in-place)
I0423 22:44:03.346835 21205 net.cpp:122] Setting up conv3_6_dw/bn
I0423 22:44:03.346843 21205 net.cpp:129] Top shape: 128 256 14 12 (5505024)
I0423 22:44:03.346846 21205 net.cpp:137] Memory required for data: 5444470784
I0423 22:44:03.346873 21205 layer_factory.hpp:77] Creating layer conv3_6_dw/scale
I0423 22:44:03.346879 21205 net.cpp:84] Creating Layer conv3_6_dw/scale
I0423 22:44:03.346882 21205 net.cpp:406] conv3_6_dw/scale <- conv3_6_dw
I0423 22:44:03.346889 21205 net.cpp:367] conv3_6_dw/scale -> conv3_6_dw (in-place)
I0423 22:44:03.346935 21205 layer_factory.hpp:77] Creating layer conv3_6_dw/scale
I0423 22:44:03.347065 21205 net.cpp:122] Setting up conv3_6_dw/scale
I0423 22:44:03.347072 21205 net.cpp:129] Top shape: 128 256 14 12 (5505024)
I0423 22:44:03.347075 21205 net.cpp:137] Memory required for data: 5466490880
I0423 22:44:03.347080 21205 layer_factory.hpp:77] Creating layer relu3_6_dw
I0423 22:44:03.347084 21205 net.cpp:84] Creating Layer relu3_6_dw
I0423 22:44:03.347087 21205 net.cpp:406] relu3_6_dw <- conv3_6_dw
I0423 22:44:03.347093 21205 net.cpp:367] relu3_6_dw -> conv3_6_dw (in-place)
I0423 22:44:03.347221 21205 net.cpp:122] Setting up relu3_6_dw
I0423 22:44:03.347229 21205 net.cpp:129] Top shape: 128 256 14 12 (5505024)
I0423 22:44:03.347232 21205 net.cpp:137] Memory required for data: 5488510976
I0423 22:44:03.347236 21205 layer_factory.hpp:77] Creating layer conv3_6_em
I0423 22:44:03.347244 21205 net.cpp:84] Creating Layer conv3_6_em
I0423 22:44:03.347247 21205 net.cpp:406] conv3_6_em <- conv3_6_dw
I0423 22:44:03.347252 21205 net.cpp:380] conv3_6_em -> conv3_6_em
I0423 22:44:03.350334 21205 net.cpp:122] Setting up conv3_6_em
I0423 22:44:03.350352 21205 net.cpp:129] Top shape: 128 128 14 12 (2752512)
I0423 22:44:03.350354 21205 net.cpp:137] Memory required for data: 5499521024
I0423 22:44:03.350359 21205 layer_factory.hpp:77] Creating layer conv3_6_em/bn
I0423 22:44:03.350368 21205 net.cpp:84] Creating Layer conv3_6_em/bn
I0423 22:44:03.350371 21205 net.cpp:406] conv3_6_em/bn <- conv3_6_em
I0423 22:44:03.350376 21205 net.cpp:367] conv3_6_em/bn -> conv3_6_em (in-place)
I0423 22:44:03.350617 21205 net.cpp:122] Setting up conv3_6_em/bn
I0423 22:44:03.350626 21205 net.cpp:129] Top shape: 128 128 14 12 (2752512)
I0423 22:44:03.350630 21205 net.cpp:137] Memory required for data: 5510531072
I0423 22:44:03.350636 21205 layer_factory.hpp:77] Creating layer conv3_6_em/scale
I0423 22:44:03.350641 21205 net.cpp:84] Creating Layer conv3_6_em/scale
I0423 22:44:03.350644 21205 net.cpp:406] conv3_6_em/scale <- conv3_6_em
I0423 22:44:03.350651 21205 net.cpp:367] conv3_6_em/scale -> conv3_6_em (in-place)
I0423 22:44:03.350713 21205 layer_factory.hpp:77] Creating layer conv3_6_em/scale
I0423 22:44:03.350849 21205 net.cpp:122] Setting up conv3_6_em/scale
I0423 22:44:03.350858 21205 net.cpp:129] Top shape: 128 128 14 12 (2752512)
I0423 22:44:03.350860 21205 net.cpp:137] Memory required for data: 5521541120
I0423 22:44:03.350865 21205 layer_factory.hpp:77] Creating layer res3_6
I0423 22:44:03.350872 21205 net.cpp:84] Creating Layer res3_6
I0423 22:44:03.350875 21205 net.cpp:406] res3_6 <- res3_5_res3_5_0_split_1
I0423 22:44:03.350879 21205 net.cpp:406] res3_6 <- conv3_6_em
I0423 22:44:03.350884 21205 net.cpp:380] res3_6 -> res3_6
I0423 22:44:03.350914 21205 net.cpp:122] Setting up res3_6
I0423 22:44:03.350922 21205 net.cpp:129] Top shape: 128 128 14 12 (2752512)
I0423 22:44:03.350924 21205 net.cpp:137] Memory required for data: 5532551168
I0423 22:44:03.350927 21205 layer_factory.hpp:77] Creating layer conv4_ex
I0423 22:44:03.350934 21205 net.cpp:84] Creating Layer conv4_ex
I0423 22:44:03.350937 21205 net.cpp:406] conv4_ex <- res3_6
I0423 22:44:03.350944 21205 net.cpp:380] conv4_ex -> conv4_ex
I0423 22:44:03.355008 21205 net.cpp:122] Setting up conv4_ex
I0423 22:44:03.355024 21205 net.cpp:129] Top shape: 128 512 14 12 (11010048)
I0423 22:44:03.355028 21205 net.cpp:137] Memory required for data: 5576591360
I0423 22:44:03.355033 21205 layer_factory.hpp:77] Creating layer conv4_ex/bn
I0423 22:44:03.355041 21205 net.cpp:84] Creating Layer conv4_ex/bn
I0423 22:44:03.355044 21205 net.cpp:406] conv4_ex/bn <- conv4_ex
I0423 22:44:03.355051 21205 net.cpp:367] conv4_ex/bn -> conv4_ex (in-place)
I0423 22:44:03.355301 21205 net.cpp:122] Setting up conv4_ex/bn
I0423 22:44:03.355310 21205 net.cpp:129] Top shape: 128 512 14 12 (11010048)
I0423 22:44:03.355314 21205 net.cpp:137] Memory required for data: 5620631552
I0423 22:44:03.355320 21205 layer_factory.hpp:77] Creating layer conv4_ex/scale
I0423 22:44:03.355326 21205 net.cpp:84] Creating Layer conv4_ex/scale
I0423 22:44:03.355329 21205 net.cpp:406] conv4_ex/scale <- conv4_ex
I0423 22:44:03.355334 21205 net.cpp:367] conv4_ex/scale -> conv4_ex (in-place)
I0423 22:44:03.355373 21205 layer_factory.hpp:77] Creating layer conv4_ex/scale
I0423 22:44:03.355514 21205 net.cpp:122] Setting up conv4_ex/scale
I0423 22:44:03.355521 21205 net.cpp:129] Top shape: 128 512 14 12 (11010048)
I0423 22:44:03.355523 21205 net.cpp:137] Memory required for data: 5664671744
I0423 22:44:03.355530 21205 layer_factory.hpp:77] Creating layer relu4_ex
I0423 22:44:03.355535 21205 net.cpp:84] Creating Layer relu4_ex
I0423 22:44:03.355538 21205 net.cpp:406] relu4_ex <- conv4_ex
I0423 22:44:03.355543 21205 net.cpp:367] relu4_ex -> conv4_ex (in-place)
I0423 22:44:03.355702 21205 net.cpp:122] Setting up relu4_ex
I0423 22:44:03.355710 21205 net.cpp:129] Top shape: 128 512 14 12 (11010048)
I0423 22:44:03.355713 21205 net.cpp:137] Memory required for data: 5708711936
I0423 22:44:03.355717 21205 layer_factory.hpp:77] Creating layer conv4_dw
I0423 22:44:03.355726 21205 net.cpp:84] Creating Layer conv4_dw
I0423 22:44:03.355729 21205 net.cpp:406] conv4_dw <- conv4_ex
I0423 22:44:03.355734 21205 net.cpp:380] conv4_dw -> conv4_dw
I0423 22:44:03.356051 21205 net.cpp:122] Setting up conv4_dw
I0423 22:44:03.356060 21205 net.cpp:129] Top shape: 128 512 7 6 (2752512)
I0423 22:44:03.356063 21205 net.cpp:137] Memory required for data: 5719721984
I0423 22:44:03.356068 21205 layer_factory.hpp:77] Creating layer conv4_dw/bn
I0423 22:44:03.356075 21205 net.cpp:84] Creating Layer conv4_dw/bn
I0423 22:44:03.356078 21205 net.cpp:406] conv4_dw/bn <- conv4_dw
I0423 22:44:03.356082 21205 net.cpp:367] conv4_dw/bn -> conv4_dw (in-place)
I0423 22:44:03.356312 21205 net.cpp:122] Setting up conv4_dw/bn
I0423 22:44:03.356319 21205 net.cpp:129] Top shape: 128 512 7 6 (2752512)
I0423 22:44:03.356323 21205 net.cpp:137] Memory required for data: 5730732032
I0423 22:44:03.356330 21205 layer_factory.hpp:77] Creating layer conv4_dw/scale
I0423 22:44:03.356338 21205 net.cpp:84] Creating Layer conv4_dw/scale
I0423 22:44:03.356341 21205 net.cpp:406] conv4_dw/scale <- conv4_dw
I0423 22:44:03.356365 21205 net.cpp:367] conv4_dw/scale -> conv4_dw (in-place)
I0423 22:44:03.356406 21205 layer_factory.hpp:77] Creating layer conv4_dw/scale
I0423 22:44:03.356547 21205 net.cpp:122] Setting up conv4_dw/scale
I0423 22:44:03.356555 21205 net.cpp:129] Top shape: 128 512 7 6 (2752512)
I0423 22:44:03.356559 21205 net.cpp:137] Memory required for data: 5741742080
I0423 22:44:03.356564 21205 layer_factory.hpp:77] Creating layer relu4_dw
I0423 22:44:03.356568 21205 net.cpp:84] Creating Layer relu4_dw
I0423 22:44:03.356571 21205 net.cpp:406] relu4_dw <- conv4_dw
I0423 22:44:03.356576 21205 net.cpp:367] relu4_dw -> conv4_dw (in-place)
I0423 22:44:03.356683 21205 net.cpp:122] Setting up relu4_dw
I0423 22:44:03.356691 21205 net.cpp:129] Top shape: 128 512 7 6 (2752512)
I0423 22:44:03.356693 21205 net.cpp:137] Memory required for data: 5752752128
I0423 22:44:03.356698 21205 layer_factory.hpp:77] Creating layer conv4_em
I0423 22:44:03.356706 21205 net.cpp:84] Creating Layer conv4_em
I0423 22:44:03.356709 21205 net.cpp:406] conv4_em <- conv4_dw
I0423 22:44:03.356714 21205 net.cpp:380] conv4_em -> conv4_em
I0423 22:44:03.359663 21205 net.cpp:122] Setting up conv4_em
I0423 22:44:03.359679 21205 net.cpp:129] Top shape: 128 128 7 6 (688128)
I0423 22:44:03.359683 21205 net.cpp:137] Memory required for data: 5755504640
I0423 22:44:03.359688 21205 layer_factory.hpp:77] Creating layer conv4_em/bn
I0423 22:44:03.359694 21205 net.cpp:84] Creating Layer conv4_em/bn
I0423 22:44:03.359699 21205 net.cpp:406] conv4_em/bn <- conv4_em
I0423 22:44:03.359704 21205 net.cpp:367] conv4_em/bn -> conv4_em (in-place)
I0423 22:44:03.359946 21205 net.cpp:122] Setting up conv4_em/bn
I0423 22:44:03.359956 21205 net.cpp:129] Top shape: 128 128 7 6 (688128)
I0423 22:44:03.359957 21205 net.cpp:137] Memory required for data: 5758257152
I0423 22:44:03.359964 21205 layer_factory.hpp:77] Creating layer conv4_em/scale
I0423 22:44:03.359972 21205 net.cpp:84] Creating Layer conv4_em/scale
I0423 22:44:03.359974 21205 net.cpp:406] conv4_em/scale <- conv4_em
I0423 22:44:03.359978 21205 net.cpp:367] conv4_em/scale -> conv4_em (in-place)
I0423 22:44:03.360023 21205 layer_factory.hpp:77] Creating layer conv4_em/scale
I0423 22:44:03.360159 21205 net.cpp:122] Setting up conv4_em/scale
I0423 22:44:03.360168 21205 net.cpp:129] Top shape: 128 128 7 6 (688128)
I0423 22:44:03.360170 21205 net.cpp:137] Memory required for data: 5761009664
I0423 22:44:03.360175 21205 layer_factory.hpp:77] Creating layer conv4_em_conv4_em/scale_0_split
I0423 22:44:03.360182 21205 net.cpp:84] Creating Layer conv4_em_conv4_em/scale_0_split
I0423 22:44:03.360185 21205 net.cpp:406] conv4_em_conv4_em/scale_0_split <- conv4_em
I0423 22:44:03.360190 21205 net.cpp:380] conv4_em_conv4_em/scale_0_split -> conv4_em_conv4_em/scale_0_split_0
I0423 22:44:03.360196 21205 net.cpp:380] conv4_em_conv4_em/scale_0_split -> conv4_em_conv4_em/scale_0_split_1
I0423 22:44:03.360239 21205 net.cpp:122] Setting up conv4_em_conv4_em/scale_0_split
I0423 22:44:03.360247 21205 net.cpp:129] Top shape: 128 128 7 6 (688128)
I0423 22:44:03.360250 21205 net.cpp:129] Top shape: 128 128 7 6 (688128)
I0423 22:44:03.360254 21205 net.cpp:137] Memory required for data: 5766514688
I0423 22:44:03.360255 21205 layer_factory.hpp:77] Creating layer conv4_1_ex
I0423 22:44:03.360263 21205 net.cpp:84] Creating Layer conv4_1_ex
I0423 22:44:03.360266 21205 net.cpp:406] conv4_1_ex <- conv4_em_conv4_em/scale_0_split_0
I0423 22:44:03.360271 21205 net.cpp:380] conv4_1_ex -> conv4_1_ex
I0423 22:44:03.363003 21205 net.cpp:122] Setting up conv4_1_ex
I0423 22:44:03.363020 21205 net.cpp:129] Top shape: 128 256 7 6 (1376256)
I0423 22:44:03.363023 21205 net.cpp:137] Memory required for data: 5772019712
I0423 22:44:03.363029 21205 layer_factory.hpp:77] Creating layer conv4_1_ex/bn
I0423 22:44:03.363035 21205 net.cpp:84] Creating Layer conv4_1_ex/bn
I0423 22:44:03.363039 21205 net.cpp:406] conv4_1_ex/bn <- conv4_1_ex
I0423 22:44:03.363046 21205 net.cpp:367] conv4_1_ex/bn -> conv4_1_ex (in-place)
I0423 22:44:03.363291 21205 net.cpp:122] Setting up conv4_1_ex/bn
I0423 22:44:03.363315 21205 net.cpp:129] Top shape: 128 256 7 6 (1376256)
I0423 22:44:03.363320 21205 net.cpp:137] Memory required for data: 5777524736
I0423 22:44:03.363327 21205 layer_factory.hpp:77] Creating layer conv4_1_ex/scale
I0423 22:44:03.363332 21205 net.cpp:84] Creating Layer conv4_1_ex/scale
I0423 22:44:03.363335 21205 net.cpp:406] conv4_1_ex/scale <- conv4_1_ex
I0423 22:44:03.363343 21205 net.cpp:367] conv4_1_ex/scale -> conv4_1_ex (in-place)
I0423 22:44:03.363389 21205 layer_factory.hpp:77] Creating layer conv4_1_ex/scale
I0423 22:44:03.363524 21205 net.cpp:122] Setting up conv4_1_ex/scale
I0423 22:44:03.363533 21205 net.cpp:129] Top shape: 128 256 7 6 (1376256)
I0423 22:44:03.363536 21205 net.cpp:137] Memory required for data: 5783029760
I0423 22:44:03.363541 21205 layer_factory.hpp:77] Creating layer relu4_1_ex
I0423 22:44:03.363546 21205 net.cpp:84] Creating Layer relu4_1_ex
I0423 22:44:03.363548 21205 net.cpp:406] relu4_1_ex <- conv4_1_ex
I0423 22:44:03.363554 21205 net.cpp:367] relu4_1_ex -> conv4_1_ex (in-place)
I0423 22:44:03.363656 21205 net.cpp:122] Setting up relu4_1_ex
I0423 22:44:03.363663 21205 net.cpp:129] Top shape: 128 256 7 6 (1376256)
I0423 22:44:03.363665 21205 net.cpp:137] Memory required for data: 5788534784
I0423 22:44:03.363670 21205 layer_factory.hpp:77] Creating layer conv4_1_dw
I0423 22:44:03.363678 21205 net.cpp:84] Creating Layer conv4_1_dw
I0423 22:44:03.363682 21205 net.cpp:406] conv4_1_dw <- conv4_1_ex
I0423 22:44:03.363687 21205 net.cpp:380] conv4_1_dw -> conv4_1_dw
I0423 22:44:03.363991 21205 net.cpp:122] Setting up conv4_1_dw
I0423 22:44:03.363999 21205 net.cpp:129] Top shape: 128 256 7 6 (1376256)
I0423 22:44:03.364002 21205 net.cpp:137] Memory required for data: 5794039808
I0423 22:44:03.364007 21205 layer_factory.hpp:77] Creating layer conv4_1_dw/bn
I0423 22:44:03.364012 21205 net.cpp:84] Creating Layer conv4_1_dw/bn
I0423 22:44:03.364015 21205 net.cpp:406] conv4_1_dw/bn <- conv4_1_dw
I0423 22:44:03.364020 21205 net.cpp:367] conv4_1_dw/bn -> conv4_1_dw (in-place)
I0423 22:44:03.364255 21205 net.cpp:122] Setting up conv4_1_dw/bn
I0423 22:44:03.364264 21205 net.cpp:129] Top shape: 128 256 7 6 (1376256)
I0423 22:44:03.364265 21205 net.cpp:137] Memory required for data: 5799544832
I0423 22:44:03.364271 21205 layer_factory.hpp:77] Creating layer conv4_1_dw/scale
I0423 22:44:03.364276 21205 net.cpp:84] Creating Layer conv4_1_dw/scale
I0423 22:44:03.364280 21205 net.cpp:406] conv4_1_dw/scale <- conv4_1_dw
I0423 22:44:03.364284 21205 net.cpp:367] conv4_1_dw/scale -> conv4_1_dw (in-place)
I0423 22:44:03.364326 21205 layer_factory.hpp:77] Creating layer conv4_1_dw/scale
I0423 22:44:03.364462 21205 net.cpp:122] Setting up conv4_1_dw/scale
I0423 22:44:03.364470 21205 net.cpp:129] Top shape: 128 256 7 6 (1376256)
I0423 22:44:03.364472 21205 net.cpp:137] Memory required for data: 5805049856
I0423 22:44:03.364477 21205 layer_factory.hpp:77] Creating layer relu4_1_dw
I0423 22:44:03.364481 21205 net.cpp:84] Creating Layer relu4_1_dw
I0423 22:44:03.364485 21205 net.cpp:406] relu4_1_dw <- conv4_1_dw
I0423 22:44:03.364490 21205 net.cpp:367] relu4_1_dw -> conv4_1_dw (in-place)
I0423 22:44:03.364590 21205 net.cpp:122] Setting up relu4_1_dw
I0423 22:44:03.364598 21205 net.cpp:129] Top shape: 128 256 7 6 (1376256)
I0423 22:44:03.364601 21205 net.cpp:137] Memory required for data: 5810554880
I0423 22:44:03.364605 21205 layer_factory.hpp:77] Creating layer conv4_1_em
I0423 22:44:03.364614 21205 net.cpp:84] Creating Layer conv4_1_em
I0423 22:44:03.364616 21205 net.cpp:406] conv4_1_em <- conv4_1_dw
I0423 22:44:03.364621 21205 net.cpp:380] conv4_1_em -> conv4_1_em
I0423 22:44:03.367733 21205 net.cpp:122] Setting up conv4_1_em
I0423 22:44:03.367748 21205 net.cpp:129] Top shape: 128 128 7 6 (688128)
I0423 22:44:03.367753 21205 net.cpp:137] Memory required for data: 5813307392
I0423 22:44:03.367759 21205 layer_factory.hpp:77] Creating layer conv4_1_em/bn
I0423 22:44:03.367766 21205 net.cpp:84] Creating Layer conv4_1_em/bn
I0423 22:44:03.367770 21205 net.cpp:406] conv4_1_em/bn <- conv4_1_em
I0423 22:44:03.367795 21205 net.cpp:367] conv4_1_em/bn -> conv4_1_em (in-place)
I0423 22:44:03.368043 21205 net.cpp:122] Setting up conv4_1_em/bn
I0423 22:44:03.368052 21205 net.cpp:129] Top shape: 128 128 7 6 (688128)
I0423 22:44:03.368054 21205 net.cpp:137] Memory required for data: 5816059904
I0423 22:44:03.368062 21205 layer_factory.hpp:77] Creating layer conv4_1_em/scale
I0423 22:44:03.368070 21205 net.cpp:84] Creating Layer conv4_1_em/scale
I0423 22:44:03.368073 21205 net.cpp:406] conv4_1_em/scale <- conv4_1_em
I0423 22:44:03.368077 21205 net.cpp:367] conv4_1_em/scale -> conv4_1_em (in-place)
I0423 22:44:03.368124 21205 layer_factory.hpp:77] Creating layer conv4_1_em/scale
I0423 22:44:03.368263 21205 net.cpp:122] Setting up conv4_1_em/scale
I0423 22:44:03.368270 21205 net.cpp:129] Top shape: 128 128 7 6 (688128)
I0423 22:44:03.368273 21205 net.cpp:137] Memory required for data: 5818812416
I0423 22:44:03.368278 21205 layer_factory.hpp:77] Creating layer res4_1
I0423 22:44:03.368283 21205 net.cpp:84] Creating Layer res4_1
I0423 22:44:03.368286 21205 net.cpp:406] res4_1 <- conv4_em_conv4_em/scale_0_split_1
I0423 22:44:03.368290 21205 net.cpp:406] res4_1 <- conv4_1_em
I0423 22:44:03.368295 21205 net.cpp:380] res4_1 -> res4_1
I0423 22:44:03.368321 21205 net.cpp:122] Setting up res4_1
I0423 22:44:03.368327 21205 net.cpp:129] Top shape: 128 128 7 6 (688128)
I0423 22:44:03.368330 21205 net.cpp:137] Memory required for data: 5821564928
I0423 22:44:03.368332 21205 layer_factory.hpp:77] Creating layer res4_1_res4_1_0_split
I0423 22:44:03.368340 21205 net.cpp:84] Creating Layer res4_1_res4_1_0_split
I0423 22:44:03.368343 21205 net.cpp:406] res4_1_res4_1_0_split <- res4_1
I0423 22:44:03.368347 21205 net.cpp:380] res4_1_res4_1_0_split -> res4_1_res4_1_0_split_0
I0423 22:44:03.368353 21205 net.cpp:380] res4_1_res4_1_0_split -> res4_1_res4_1_0_split_1
I0423 22:44:03.368398 21205 net.cpp:122] Setting up res4_1_res4_1_0_split
I0423 22:44:03.368405 21205 net.cpp:129] Top shape: 128 128 7 6 (688128)
I0423 22:44:03.368408 21205 net.cpp:129] Top shape: 128 128 7 6 (688128)
I0423 22:44:03.368410 21205 net.cpp:137] Memory required for data: 5827069952
I0423 22:44:03.368414 21205 layer_factory.hpp:77] Creating layer conv4_2_ex
I0423 22:44:03.368422 21205 net.cpp:84] Creating Layer conv4_2_ex
I0423 22:44:03.368427 21205 net.cpp:406] conv4_2_ex <- res4_1_res4_1_0_split_0
I0423 22:44:03.368432 21205 net.cpp:380] conv4_2_ex -> conv4_2_ex
I0423 22:44:03.371198 21205 net.cpp:122] Setting up conv4_2_ex
I0423 22:44:03.371214 21205 net.cpp:129] Top shape: 128 256 7 6 (1376256)
I0423 22:44:03.371217 21205 net.cpp:137] Memory required for data: 5832574976
I0423 22:44:03.371224 21205 layer_factory.hpp:77] Creating layer conv4_2_ex/bn
I0423 22:44:03.371232 21205 net.cpp:84] Creating Layer conv4_2_ex/bn
I0423 22:44:03.371237 21205 net.cpp:406] conv4_2_ex/bn <- conv4_2_ex
I0423 22:44:03.371242 21205 net.cpp:367] conv4_2_ex/bn -> conv4_2_ex (in-place)
I0423 22:44:03.371487 21205 net.cpp:122] Setting up conv4_2_ex/bn
I0423 22:44:03.371496 21205 net.cpp:129] Top shape: 128 256 7 6 (1376256)
I0423 22:44:03.371500 21205 net.cpp:137] Memory required for data: 5838080000
I0423 22:44:03.371505 21205 layer_factory.hpp:77] Creating layer conv4_2_ex/scale
I0423 22:44:03.371511 21205 net.cpp:84] Creating Layer conv4_2_ex/scale
I0423 22:44:03.371515 21205 net.cpp:406] conv4_2_ex/scale <- conv4_2_ex
I0423 22:44:03.371520 21205 net.cpp:367] conv4_2_ex/scale -> conv4_2_ex (in-place)
I0423 22:44:03.371567 21205 layer_factory.hpp:77] Creating layer conv4_2_ex/scale
I0423 22:44:03.371707 21205 net.cpp:122] Setting up conv4_2_ex/scale
I0423 22:44:03.371716 21205 net.cpp:129] Top shape: 128 256 7 6 (1376256)
I0423 22:44:03.371718 21205 net.cpp:137] Memory required for data: 5843585024
I0423 22:44:03.371723 21205 layer_factory.hpp:77] Creating layer relu4_2_ex
I0423 22:44:03.371728 21205 net.cpp:84] Creating Layer relu4_2_ex
I0423 22:44:03.371731 21205 net.cpp:406] relu4_2_ex <- conv4_2_ex
I0423 22:44:03.371737 21205 net.cpp:367] relu4_2_ex -> conv4_2_ex (in-place)
I0423 22:44:03.371863 21205 net.cpp:122] Setting up relu4_2_ex
I0423 22:44:03.371872 21205 net.cpp:129] Top shape: 128 256 7 6 (1376256)
I0423 22:44:03.371876 21205 net.cpp:137] Memory required for data: 5849090048
I0423 22:44:03.371879 21205 layer_factory.hpp:77] Creating layer conv4_2_dw
I0423 22:44:03.371887 21205 net.cpp:84] Creating Layer conv4_2_dw
I0423 22:44:03.371891 21205 net.cpp:406] conv4_2_dw <- conv4_2_ex
I0423 22:44:03.371896 21205 net.cpp:380] conv4_2_dw -> conv4_2_dw
I0423 22:44:03.372198 21205 net.cpp:122] Setting up conv4_2_dw
I0423 22:44:03.372206 21205 net.cpp:129] Top shape: 128 256 7 6 (1376256)
I0423 22:44:03.372210 21205 net.cpp:137] Memory required for data: 5854595072
I0423 22:44:03.372215 21205 layer_factory.hpp:77] Creating layer conv4_2_dw/bn
I0423 22:44:03.372220 21205 net.cpp:84] Creating Layer conv4_2_dw/bn
I0423 22:44:03.372222 21205 net.cpp:406] conv4_2_dw/bn <- conv4_2_dw
I0423 22:44:03.372227 21205 net.cpp:367] conv4_2_dw/bn -> conv4_2_dw (in-place)
I0423 22:44:03.372463 21205 net.cpp:122] Setting up conv4_2_dw/bn
I0423 22:44:03.372472 21205 net.cpp:129] Top shape: 128 256 7 6 (1376256)
I0423 22:44:03.372473 21205 net.cpp:137] Memory required for data: 5860100096
I0423 22:44:03.372480 21205 layer_factory.hpp:77] Creating layer conv4_2_dw/scale
I0423 22:44:03.372486 21205 net.cpp:84] Creating Layer conv4_2_dw/scale
I0423 22:44:03.372489 21205 net.cpp:406] conv4_2_dw/scale <- conv4_2_dw
I0423 22:44:03.372493 21205 net.cpp:367] conv4_2_dw/scale -> conv4_2_dw (in-place)
I0423 22:44:03.372535 21205 layer_factory.hpp:77] Creating layer conv4_2_dw/scale
I0423 22:44:03.372674 21205 net.cpp:122] Setting up conv4_2_dw/scale
I0423 22:44:03.372681 21205 net.cpp:129] Top shape: 128 256 7 6 (1376256)
I0423 22:44:03.372684 21205 net.cpp:137] Memory required for data: 5865605120
I0423 22:44:03.372689 21205 layer_factory.hpp:77] Creating layer relu4_2_dw
I0423 22:44:03.372694 21205 net.cpp:84] Creating Layer relu4_2_dw
I0423 22:44:03.372697 21205 net.cpp:406] relu4_2_dw <- conv4_2_dw
I0423 22:44:03.372701 21205 net.cpp:367] relu4_2_dw -> conv4_2_dw (in-place)
I0423 22:44:03.372802 21205 net.cpp:122] Setting up relu4_2_dw
I0423 22:44:03.372812 21205 net.cpp:129] Top shape: 128 256 7 6 (1376256)
I0423 22:44:03.372814 21205 net.cpp:137] Memory required for data: 5871110144
I0423 22:44:03.372818 21205 layer_factory.hpp:77] Creating layer conv4_2_em
I0423 22:44:03.372828 21205 net.cpp:84] Creating Layer conv4_2_em
I0423 22:44:03.372831 21205 net.cpp:406] conv4_2_em <- conv4_2_dw
I0423 22:44:03.372835 21205 net.cpp:380] conv4_2_em -> conv4_2_em
I0423 22:44:03.375566 21205 net.cpp:122] Setting up conv4_2_em
I0423 22:44:03.375581 21205 net.cpp:129] Top shape: 128 128 7 6 (688128)
I0423 22:44:03.375586 21205 net.cpp:137] Memory required for data: 5873862656
I0423 22:44:03.375591 21205 layer_factory.hpp:77] Creating layer conv4_2_em/bn
I0423 22:44:03.375598 21205 net.cpp:84] Creating Layer conv4_2_em/bn
I0423 22:44:03.375602 21205 net.cpp:406] conv4_2_em/bn <- conv4_2_em
I0423 22:44:03.375608 21205 net.cpp:367] conv4_2_em/bn -> conv4_2_em (in-place)
I0423 22:44:03.375856 21205 net.cpp:122] Setting up conv4_2_em/bn
I0423 22:44:03.375864 21205 net.cpp:129] Top shape: 128 128 7 6 (688128)
I0423 22:44:03.375867 21205 net.cpp:137] Memory required for data: 5876615168
I0423 22:44:03.375874 21205 layer_factory.hpp:77] Creating layer conv4_2_em/scale
I0423 22:44:03.375880 21205 net.cpp:84] Creating Layer conv4_2_em/scale
I0423 22:44:03.375883 21205 net.cpp:406] conv4_2_em/scale <- conv4_2_em
I0423 22:44:03.375887 21205 net.cpp:367] conv4_2_em/scale -> conv4_2_em (in-place)
I0423 22:44:03.375933 21205 layer_factory.hpp:77] Creating layer conv4_2_em/scale
I0423 22:44:03.376075 21205 net.cpp:122] Setting up conv4_2_em/scale
I0423 22:44:03.376083 21205 net.cpp:129] Top shape: 128 128 7 6 (688128)
I0423 22:44:03.376085 21205 net.cpp:137] Memory required for data: 5879367680
I0423 22:44:03.376092 21205 layer_factory.hpp:77] Creating layer res4_2
I0423 22:44:03.376096 21205 net.cpp:84] Creating Layer res4_2
I0423 22:44:03.376118 21205 net.cpp:406] res4_2 <- res4_1_res4_1_0_split_1
I0423 22:44:03.376123 21205 net.cpp:406] res4_2 <- conv4_2_em
I0423 22:44:03.376130 21205 net.cpp:380] res4_2 -> res4_2
I0423 22:44:03.376158 21205 net.cpp:122] Setting up res4_2
I0423 22:44:03.376165 21205 net.cpp:129] Top shape: 128 128 7 6 (688128)
I0423 22:44:03.376168 21205 net.cpp:137] Memory required for data: 5882120192
I0423 22:44:03.376171 21205 layer_factory.hpp:77] Creating layer conv5_ex
I0423 22:44:03.376179 21205 net.cpp:84] Creating Layer conv5_ex
I0423 22:44:03.376183 21205 net.cpp:406] conv5_ex <- res4_2
I0423 22:44:03.376188 21205 net.cpp:380] conv5_ex -> conv5_ex
I0423 22:44:03.379798 21205 net.cpp:122] Setting up conv5_ex
I0423 22:44:03.379814 21205 net.cpp:129] Top shape: 128 512 7 6 (2752512)
I0423 22:44:03.379818 21205 net.cpp:137] Memory required for data: 5893130240
I0423 22:44:03.379823 21205 layer_factory.hpp:77] Creating layer conv5_ex/bn
I0423 22:44:03.379830 21205 net.cpp:84] Creating Layer conv5_ex/bn
I0423 22:44:03.379834 21205 net.cpp:406] conv5_ex/bn <- conv5_ex
I0423 22:44:03.379842 21205 net.cpp:367] conv5_ex/bn -> conv5_ex (in-place)
I0423 22:44:03.380093 21205 net.cpp:122] Setting up conv5_ex/bn
I0423 22:44:03.380102 21205 net.cpp:129] Top shape: 128 512 7 6 (2752512)
I0423 22:44:03.380105 21205 net.cpp:137] Memory required for data: 5904140288
I0423 22:44:03.380111 21205 layer_factory.hpp:77] Creating layer conv5_ex/scale
I0423 22:44:03.380117 21205 net.cpp:84] Creating Layer conv5_ex/scale
I0423 22:44:03.380120 21205 net.cpp:406] conv5_ex/scale <- conv5_ex
I0423 22:44:03.380126 21205 net.cpp:367] conv5_ex/scale -> conv5_ex (in-place)
I0423 22:44:03.380165 21205 layer_factory.hpp:77] Creating layer conv5_ex/scale
I0423 22:44:03.380312 21205 net.cpp:122] Setting up conv5_ex/scale
I0423 22:44:03.380322 21205 net.cpp:129] Top shape: 128 512 7 6 (2752512)
I0423 22:44:03.380326 21205 net.cpp:137] Memory required for data: 5915150336
I0423 22:44:03.380331 21205 layer_factory.hpp:77] Creating layer relu5_ex
I0423 22:44:03.380336 21205 net.cpp:84] Creating Layer relu5_ex
I0423 22:44:03.380339 21205 net.cpp:406] relu5_ex <- conv5_ex
I0423 22:44:03.380343 21205 net.cpp:367] relu5_ex -> conv5_ex (in-place)
I0423 22:44:03.380455 21205 net.cpp:122] Setting up relu5_ex
I0423 22:44:03.380463 21205 net.cpp:129] Top shape: 128 512 7 6 (2752512)
I0423 22:44:03.380466 21205 net.cpp:137] Memory required for data: 5926160384
I0423 22:44:03.380470 21205 layer_factory.hpp:77] Creating layer conv5_dw
I0423 22:44:03.380478 21205 net.cpp:84] Creating Layer conv5_dw
I0423 22:44:03.380481 21205 net.cpp:406] conv5_dw <- conv5_ex
I0423 22:44:03.380486 21205 net.cpp:380] conv5_dw -> conv5_dw
I0423 22:44:03.380895 21205 net.cpp:122] Setting up conv5_dw
I0423 22:44:03.380904 21205 net.cpp:129] Top shape: 128 512 1 1 (65536)
I0423 22:44:03.380906 21205 net.cpp:137] Memory required for data: 5926422528
I0423 22:44:03.380913 21205 layer_factory.hpp:77] Creating layer conv5_dw/bn
I0423 22:44:03.380919 21205 net.cpp:84] Creating Layer conv5_dw/bn
I0423 22:44:03.380923 21205 net.cpp:406] conv5_dw/bn <- conv5_dw
I0423 22:44:03.380926 21205 net.cpp:367] conv5_dw/bn -> conv5_dw (in-place)
I0423 22:44:03.381156 21205 net.cpp:122] Setting up conv5_dw/bn
I0423 22:44:03.381163 21205 net.cpp:129] Top shape: 128 512 1 1 (65536)
I0423 22:44:03.381166 21205 net.cpp:137] Memory required for data: 5926684672
I0423 22:44:03.381172 21205 layer_factory.hpp:77] Creating layer conv5_dw/scale
I0423 22:44:03.381178 21205 net.cpp:84] Creating Layer conv5_dw/scale
I0423 22:44:03.381181 21205 net.cpp:406] conv5_dw/scale <- conv5_dw
I0423 22:44:03.381184 21205 net.cpp:367] conv5_dw/scale -> conv5_dw (in-place)
I0423 22:44:03.381232 21205 layer_factory.hpp:77] Creating layer conv5_dw/scale
I0423 22:44:03.381377 21205 net.cpp:122] Setting up conv5_dw/scale
I0423 22:44:03.381386 21205 net.cpp:129] Top shape: 128 512 1 1 (65536)
I0423 22:44:03.381387 21205 net.cpp:137] Memory required for data: 5926946816
I0423 22:44:03.381392 21205 layer_factory.hpp:77] Creating layer fc5
I0423 22:44:03.381417 21205 net.cpp:84] Creating Layer fc5
I0423 22:44:03.381422 21205 net.cpp:406] fc5 <- conv5_dw
I0423 22:44:03.381428 21205 net.cpp:380] fc5 -> fc5
I0423 22:44:03.381848 21205 net.cpp:122] Setting up fc5
I0423 22:44:03.381856 21205 net.cpp:129] Top shape: 128 128 (16384)
I0423 22:44:03.381860 21205 net.cpp:137] Memory required for data: 5927012352
I0423 22:44:03.381863 21205 layer_factory.hpp:77] Creating layer norm1
I0423 22:44:03.381868 21205 net.cpp:84] Creating Layer norm1
I0423 22:44:03.381871 21205 net.cpp:406] norm1 <- fc5
I0423 22:44:03.381877 21205 net.cpp:380] norm1 -> norm1
I0423 22:44:03.381943 21205 net.cpp:122] Setting up norm1
I0423 22:44:03.381950 21205 net.cpp:129] Top shape: 128 128 1 1 (16384)
I0423 22:44:03.381953 21205 net.cpp:137] Memory required for data: 5927077888
I0423 22:44:03.381956 21205 layer_factory.hpp:77] Creating layer fc6_l2
I0423 22:44:03.381960 21205 net.cpp:84] Creating Layer fc6_l2
I0423 22:44:03.381963 21205 net.cpp:406] fc6_l2 <- norm1
I0423 22:44:03.381970 21205 net.cpp:380] fc6_l2 -> fc6
I0423 22:44:03.390942 21205 net.cpp:122] Setting up fc6_l2
I0423 22:44:03.390957 21205 net.cpp:129] Top shape: 128 10575 (1353600)
I0423 22:44:03.390960 21205 net.cpp:137] Memory required for data: 5932492288
I0423 22:44:03.390966 21205 layer_factory.hpp:77] Creating layer label_specific_margin
I0423 22:44:03.390974 21205 net.cpp:84] Creating Layer label_specific_margin
I0423 22:44:03.390977 21205 net.cpp:406] label_specific_margin <- fc6
I0423 22:44:03.390982 21205 net.cpp:406] label_specific_margin <- label_data_1_split_0
I0423 22:44:03.390987 21205 net.cpp:380] label_specific_margin -> fc6_margin
I0423 22:44:03.391026 21205 net.cpp:122] Setting up label_specific_margin
I0423 22:44:03.391034 21205 net.cpp:129] Top shape: 128 10575 (1353600)
I0423 22:44:03.391037 21205 net.cpp:137] Memory required for data: 5937906688
I0423 22:44:03.391041 21205 layer_factory.hpp:77] Creating layer fc6_margin_label_specific_margin_0_split
I0423 22:44:03.391046 21205 net.cpp:84] Creating Layer fc6_margin_label_specific_margin_0_split
I0423 22:44:03.391048 21205 net.cpp:406] fc6_margin_label_specific_margin_0_split <- fc6_margin
I0423 22:44:03.391053 21205 net.cpp:380] fc6_margin_label_specific_margin_0_split -> fc6_margin_label_specific_margin_0_split_0
I0423 22:44:03.391060 21205 net.cpp:380] fc6_margin_label_specific_margin_0_split -> fc6_margin_label_specific_margin_0_split_1
I0423 22:44:03.391108 21205 net.cpp:122] Setting up fc6_margin_label_specific_margin_0_split
I0423 22:44:03.391114 21205 net.cpp:129] Top shape: 128 10575 (1353600)
I0423 22:44:03.391118 21205 net.cpp:129] Top shape: 128 10575 (1353600)
I0423 22:44:03.391121 21205 net.cpp:137] Memory required for data: 5948735488
I0423 22:44:03.391124 21205 layer_factory.hpp:77] Creating layer fc6_margin_scale
I0423 22:44:03.391132 21205 net.cpp:84] Creating Layer fc6_margin_scale
I0423 22:44:03.391135 21205 net.cpp:406] fc6_margin_scale <- fc6_margin_label_specific_margin_0_split_0
I0423 22:44:03.391141 21205 net.cpp:380] fc6_margin_scale -> fc6_margin_scale
I0423 22:44:03.391266 21205 net.cpp:122] Setting up fc6_margin_scale
I0423 22:44:03.391273 21205 net.cpp:129] Top shape: 128 10575 (1353600)
I0423 22:44:03.391276 21205 net.cpp:137] Memory required for data: 5954149888
I0423 22:44:03.391281 21205 layer_factory.hpp:77] Creating layer softmax_loss
I0423 22:44:03.391288 21205 net.cpp:84] Creating Layer softmax_loss
I0423 22:44:03.391290 21205 net.cpp:406] softmax_loss <- fc6_margin_scale
I0423 22:44:03.391294 21205 net.cpp:406] softmax_loss <- label_data_1_split_1
I0423 22:44:03.391300 21205 net.cpp:380] softmax_loss -> softmax_loss
I0423 22:44:03.391307 21205 layer_factory.hpp:77] Creating layer softmax_loss
I0423 22:44:03.395000 21205 net.cpp:122] Setting up softmax_loss
I0423 22:44:03.395017 21205 net.cpp:129] Top shape: (1)
I0423 22:44:03.395021 21205 net.cpp:132]     with loss weight 1
I0423 22:44:03.395037 21205 net.cpp:137] Memory required for data: 5954149892
I0423 22:44:03.395041 21205 layer_factory.hpp:77] Creating layer Accuracy
I0423 22:44:03.395066 21205 net.cpp:84] Creating Layer Accuracy
I0423 22:44:03.395071 21205 net.cpp:406] Accuracy <- fc6_margin_label_specific_margin_0_split_1
I0423 22:44:03.395076 21205 net.cpp:406] Accuracy <- label_data_1_split_2
I0423 22:44:03.395081 21205 net.cpp:380] Accuracy -> accuracy
I0423 22:44:03.395089 21205 net.cpp:122] Setting up Accuracy
I0423 22:44:03.395094 21205 net.cpp:129] Top shape: (1)
I0423 22:44:03.395097 21205 net.cpp:137] Memory required for data: 5954149896
I0423 22:44:03.395099 21205 net.cpp:200] Accuracy does not need backward computation.
I0423 22:44:03.395105 21205 net.cpp:198] softmax_loss needs backward computation.
I0423 22:44:03.395110 21205 net.cpp:198] fc6_margin_scale needs backward computation.
I0423 22:44:03.395113 21205 net.cpp:198] fc6_margin_label_specific_margin_0_split needs backward computation.
I0423 22:44:03.395117 21205 net.cpp:198] label_specific_margin needs backward computation.
I0423 22:44:03.395120 21205 net.cpp:198] fc6_l2 needs backward computation.
I0423 22:44:03.395124 21205 net.cpp:198] norm1 needs backward computation.
I0423 22:44:03.395128 21205 net.cpp:198] fc5 needs backward computation.
I0423 22:44:03.395131 21205 net.cpp:198] conv5_dw/scale needs backward computation.
I0423 22:44:03.395134 21205 net.cpp:198] conv5_dw/bn needs backward computation.
I0423 22:44:03.395138 21205 net.cpp:198] conv5_dw needs backward computation.
I0423 22:44:03.395140 21205 net.cpp:198] relu5_ex needs backward computation.
I0423 22:44:03.395143 21205 net.cpp:198] conv5_ex/scale needs backward computation.
I0423 22:44:03.395145 21205 net.cpp:198] conv5_ex/bn needs backward computation.
I0423 22:44:03.395148 21205 net.cpp:198] conv5_ex needs backward computation.
I0423 22:44:03.395151 21205 net.cpp:198] res4_2 needs backward computation.
I0423 22:44:03.395154 21205 net.cpp:198] conv4_2_em/scale needs backward computation.
I0423 22:44:03.395157 21205 net.cpp:198] conv4_2_em/bn needs backward computation.
I0423 22:44:03.395160 21205 net.cpp:198] conv4_2_em needs backward computation.
I0423 22:44:03.395164 21205 net.cpp:198] relu4_2_dw needs backward computation.
I0423 22:44:03.395165 21205 net.cpp:198] conv4_2_dw/scale needs backward computation.
I0423 22:44:03.395169 21205 net.cpp:198] conv4_2_dw/bn needs backward computation.
I0423 22:44:03.395171 21205 net.cpp:198] conv4_2_dw needs backward computation.
I0423 22:44:03.395174 21205 net.cpp:198] relu4_2_ex needs backward computation.
I0423 22:44:03.395176 21205 net.cpp:198] conv4_2_ex/scale needs backward computation.
I0423 22:44:03.395179 21205 net.cpp:198] conv4_2_ex/bn needs backward computation.
I0423 22:44:03.395182 21205 net.cpp:198] conv4_2_ex needs backward computation.
I0423 22:44:03.395185 21205 net.cpp:198] res4_1_res4_1_0_split needs backward computation.
I0423 22:44:03.395189 21205 net.cpp:198] res4_1 needs backward computation.
I0423 22:44:03.395191 21205 net.cpp:198] conv4_1_em/scale needs backward computation.
I0423 22:44:03.395195 21205 net.cpp:198] conv4_1_em/bn needs backward computation.
I0423 22:44:03.395197 21205 net.cpp:198] conv4_1_em needs backward computation.
I0423 22:44:03.395200 21205 net.cpp:198] relu4_1_dw needs backward computation.
I0423 22:44:03.395202 21205 net.cpp:198] conv4_1_dw/scale needs backward computation.
I0423 22:44:03.395206 21205 net.cpp:198] conv4_1_dw/bn needs backward computation.
I0423 22:44:03.395208 21205 net.cpp:198] conv4_1_dw needs backward computation.
I0423 22:44:03.395211 21205 net.cpp:198] relu4_1_ex needs backward computation.
I0423 22:44:03.395213 21205 net.cpp:198] conv4_1_ex/scale needs backward computation.
I0423 22:44:03.395216 21205 net.cpp:198] conv4_1_ex/bn needs backward computation.
I0423 22:44:03.395220 21205 net.cpp:198] conv4_1_ex needs backward computation.
I0423 22:44:03.395222 21205 net.cpp:198] conv4_em_conv4_em/scale_0_split needs backward computation.
I0423 22:44:03.395226 21205 net.cpp:198] conv4_em/scale needs backward computation.
I0423 22:44:03.395228 21205 net.cpp:198] conv4_em/bn needs backward computation.
I0423 22:44:03.395231 21205 net.cpp:198] conv4_em needs backward computation.
I0423 22:44:03.395244 21205 net.cpp:198] relu4_dw needs backward computation.
I0423 22:44:03.395247 21205 net.cpp:198] conv4_dw/scale needs backward computation.
I0423 22:44:03.395251 21205 net.cpp:198] conv4_dw/bn needs backward computation.
I0423 22:44:03.395253 21205 net.cpp:198] conv4_dw needs backward computation.
I0423 22:44:03.395256 21205 net.cpp:198] relu4_ex needs backward computation.
I0423 22:44:03.395259 21205 net.cpp:198] conv4_ex/scale needs backward computation.
I0423 22:44:03.395262 21205 net.cpp:198] conv4_ex/bn needs backward computation.
I0423 22:44:03.395264 21205 net.cpp:198] conv4_ex needs backward computation.
I0423 22:44:03.395267 21205 net.cpp:198] res3_6 needs backward computation.
I0423 22:44:03.395270 21205 net.cpp:198] conv3_6_em/scale needs backward computation.
I0423 22:44:03.395275 21205 net.cpp:198] conv3_6_em/bn needs backward computation.
I0423 22:44:03.395278 21205 net.cpp:198] conv3_6_em needs backward computation.
I0423 22:44:03.395282 21205 net.cpp:198] relu3_6_dw needs backward computation.
I0423 22:44:03.395284 21205 net.cpp:198] conv3_6_dw/scale needs backward computation.
I0423 22:44:03.395287 21205 net.cpp:198] conv3_6_dw/bn needs backward computation.
I0423 22:44:03.395289 21205 net.cpp:198] conv3_6_dw needs backward computation.
I0423 22:44:03.395292 21205 net.cpp:198] relu3_6_ex needs backward computation.
I0423 22:44:03.395295 21205 net.cpp:198] conv3_6_ex/scale needs backward computation.
I0423 22:44:03.395298 21205 net.cpp:198] conv3_6_ex/bn needs backward computation.
I0423 22:44:03.395300 21205 net.cpp:198] conv3_6_ex needs backward computation.
I0423 22:44:03.395303 21205 net.cpp:198] res3_5_res3_5_0_split needs backward computation.
I0423 22:44:03.395306 21205 net.cpp:198] res3_5 needs backward computation.
I0423 22:44:03.395310 21205 net.cpp:198] conv3_5_em/scale needs backward computation.
I0423 22:44:03.395313 21205 net.cpp:198] conv3_5_em/bn needs backward computation.
I0423 22:44:03.395316 21205 net.cpp:198] conv3_5_em needs backward computation.
I0423 22:44:03.395319 21205 net.cpp:198] relu3_5_dw needs backward computation.
I0423 22:44:03.395323 21205 net.cpp:198] conv3_5_dw/scale needs backward computation.
I0423 22:44:03.395324 21205 net.cpp:198] conv3_5_dw/bn needs backward computation.
I0423 22:44:03.395328 21205 net.cpp:198] conv3_5_dw needs backward computation.
I0423 22:44:03.395330 21205 net.cpp:198] relu3_5_ex needs backward computation.
I0423 22:44:03.395334 21205 net.cpp:198] conv3_5_ex/scale needs backward computation.
I0423 22:44:03.395335 21205 net.cpp:198] conv3_5_ex/bn needs backward computation.
I0423 22:44:03.395339 21205 net.cpp:198] conv3_5_ex needs backward computation.
I0423 22:44:03.395341 21205 net.cpp:198] res3_4_res3_4_0_split needs backward computation.
I0423 22:44:03.395345 21205 net.cpp:198] res3_4 needs backward computation.
I0423 22:44:03.395349 21205 net.cpp:198] conv3_4_em/scale needs backward computation.
I0423 22:44:03.395350 21205 net.cpp:198] conv3_4_em/bn needs backward computation.
I0423 22:44:03.395354 21205 net.cpp:198] conv3_4_em needs backward computation.
I0423 22:44:03.395356 21205 net.cpp:198] relu3_4_dw needs backward computation.
I0423 22:44:03.395359 21205 net.cpp:198] conv3_4_dw/scale needs backward computation.
I0423 22:44:03.395361 21205 net.cpp:198] conv3_4_dw/bn needs backward computation.
I0423 22:44:03.395364 21205 net.cpp:198] conv3_4_dw needs backward computation.
I0423 22:44:03.395367 21205 net.cpp:198] relu3_4_ex needs backward computation.
I0423 22:44:03.395370 21205 net.cpp:198] conv3_4_ex/scale needs backward computation.
I0423 22:44:03.395372 21205 net.cpp:198] conv3_4_ex/bn needs backward computation.
I0423 22:44:03.395375 21205 net.cpp:198] conv3_4_ex needs backward computation.
I0423 22:44:03.395378 21205 net.cpp:198] res3_3_res3_3_0_split needs backward computation.
I0423 22:44:03.395381 21205 net.cpp:198] res3_3 needs backward computation.
I0423 22:44:03.395385 21205 net.cpp:198] conv3_3_em/scale needs backward computation.
I0423 22:44:03.395387 21205 net.cpp:198] conv3_3_em/bn needs backward computation.
I0423 22:44:03.395397 21205 net.cpp:198] conv3_3_em needs backward computation.
I0423 22:44:03.395401 21205 net.cpp:198] relu3_3_dw needs backward computation.
I0423 22:44:03.395404 21205 net.cpp:198] conv3_3_dw/scale needs backward computation.
I0423 22:44:03.395406 21205 net.cpp:198] conv3_3_dw/bn needs backward computation.
I0423 22:44:03.395409 21205 net.cpp:198] conv3_3_dw needs backward computation.
I0423 22:44:03.395412 21205 net.cpp:198] relu3_3_ex needs backward computation.
I0423 22:44:03.395416 21205 net.cpp:198] conv3_3_ex/scale needs backward computation.
I0423 22:44:03.395417 21205 net.cpp:198] conv3_3_ex/bn needs backward computation.
I0423 22:44:03.395421 21205 net.cpp:198] conv3_3_ex needs backward computation.
I0423 22:44:03.395423 21205 net.cpp:198] res3_2_res3_2_0_split needs backward computation.
I0423 22:44:03.395426 21205 net.cpp:198] res3_2 needs backward computation.
I0423 22:44:03.395429 21205 net.cpp:198] conv3_2_em/scale needs backward computation.
I0423 22:44:03.395432 21205 net.cpp:198] conv3_2_em/bn needs backward computation.
I0423 22:44:03.395436 21205 net.cpp:198] conv3_2_em needs backward computation.
I0423 22:44:03.395437 21205 net.cpp:198] relu3_2_dw needs backward computation.
I0423 22:44:03.395440 21205 net.cpp:198] conv3_2_dw/scale needs backward computation.
I0423 22:44:03.395443 21205 net.cpp:198] conv3_2_dw/bn needs backward computation.
I0423 22:44:03.395447 21205 net.cpp:198] conv3_2_dw needs backward computation.
I0423 22:44:03.395449 21205 net.cpp:198] relu3_2_ex needs backward computation.
I0423 22:44:03.395452 21205 net.cpp:198] conv3_2_ex/scale needs backward computation.
I0423 22:44:03.395455 21205 net.cpp:198] conv3_2_ex/bn needs backward computation.
I0423 22:44:03.395458 21205 net.cpp:198] conv3_2_ex needs backward computation.
I0423 22:44:03.395462 21205 net.cpp:198] res3_1_res3_1_0_split needs backward computation.
I0423 22:44:03.395464 21205 net.cpp:198] res3_1 needs backward computation.
I0423 22:44:03.395468 21205 net.cpp:198] conv3_1_em/scale needs backward computation.
I0423 22:44:03.395470 21205 net.cpp:198] conv3_1_em/bn needs backward computation.
I0423 22:44:03.395473 21205 net.cpp:198] conv3_1_em needs backward computation.
I0423 22:44:03.395476 21205 net.cpp:198] relu3_1_dw needs backward computation.
I0423 22:44:03.395479 21205 net.cpp:198] conv3_1_dw/scale needs backward computation.
I0423 22:44:03.395483 21205 net.cpp:198] conv3_1_dw/bn needs backward computation.
I0423 22:44:03.395485 21205 net.cpp:198] conv3_1_dw needs backward computation.
I0423 22:44:03.395488 21205 net.cpp:198] relu3_1_ex needs backward computation.
I0423 22:44:03.395491 21205 net.cpp:198] conv3_1_ex/scale needs backward computation.
I0423 22:44:03.395493 21205 net.cpp:198] conv3_1_ex/bn needs backward computation.
I0423 22:44:03.395496 21205 net.cpp:198] conv3_1_ex needs backward computation.
I0423 22:44:03.395499 21205 net.cpp:198] conv3_em_conv3_em/scale_0_split needs backward computation.
I0423 22:44:03.395503 21205 net.cpp:198] conv3_em/scale needs backward computation.
I0423 22:44:03.395505 21205 net.cpp:198] conv3_em/bn needs backward computation.
I0423 22:44:03.395509 21205 net.cpp:198] conv3_em needs backward computation.
I0423 22:44:03.395510 21205 net.cpp:198] relu3_dw needs backward computation.
I0423 22:44:03.395514 21205 net.cpp:198] conv3_dw/scale needs backward computation.
I0423 22:44:03.395516 21205 net.cpp:198] conv3_dw/bn needs backward computation.
I0423 22:44:03.395519 21205 net.cpp:198] conv3_dw needs backward computation.
I0423 22:44:03.395522 21205 net.cpp:198] relu3_ex needs backward computation.
I0423 22:44:03.395526 21205 net.cpp:198] conv3_ex/scale needs backward computation.
I0423 22:44:03.395529 21205 net.cpp:198] conv3_ex/bn needs backward computation.
I0423 22:44:03.395531 21205 net.cpp:198] conv3_ex needs backward computation.
I0423 22:44:03.395534 21205 net.cpp:198] res2_4 needs backward computation.
I0423 22:44:03.395539 21205 net.cpp:198] conv2_4_em/scale needs backward computation.
I0423 22:44:03.395540 21205 net.cpp:198] conv2_4_em/bn needs backward computation.
I0423 22:44:03.395553 21205 net.cpp:198] conv2_4_em needs backward computation.
I0423 22:44:03.395556 21205 net.cpp:198] relu2_4_dw needs backward computation.
I0423 22:44:03.395560 21205 net.cpp:198] conv2_4_dw/scale needs backward computation.
I0423 22:44:03.395562 21205 net.cpp:198] conv2_4_dw/bn needs backward computation.
I0423 22:44:03.395565 21205 net.cpp:198] conv2_4_dw needs backward computation.
I0423 22:44:03.395568 21205 net.cpp:198] relu2_4_ex needs backward computation.
I0423 22:44:03.395571 21205 net.cpp:198] conv2_4_ex/scale needs backward computation.
I0423 22:44:03.395575 21205 net.cpp:198] conv2_4_ex/bn needs backward computation.
I0423 22:44:03.395577 21205 net.cpp:198] conv2_4_ex needs backward computation.
I0423 22:44:03.395579 21205 net.cpp:198] res2_3_res2_3_0_split needs backward computation.
I0423 22:44:03.395583 21205 net.cpp:198] res2_3 needs backward computation.
I0423 22:44:03.395586 21205 net.cpp:198] conv2_3_em/scale needs backward computation.
I0423 22:44:03.395591 21205 net.cpp:198] conv2_3_em/bn needs backward computation.
I0423 22:44:03.395593 21205 net.cpp:198] conv2_3_em needs backward computation.
I0423 22:44:03.395597 21205 net.cpp:198] relu2_3_dw needs backward computation.
I0423 22:44:03.395599 21205 net.cpp:198] conv2_3_dw/scale needs backward computation.
I0423 22:44:03.395602 21205 net.cpp:198] conv2_3_dw/bn needs backward computation.
I0423 22:44:03.395606 21205 net.cpp:198] conv2_3_dw needs backward computation.
I0423 22:44:03.395608 21205 net.cpp:198] relu2_3_ex needs backward computation.
I0423 22:44:03.395612 21205 net.cpp:198] conv2_3_ex/scale needs backward computation.
I0423 22:44:03.395614 21205 net.cpp:198] conv2_3_ex/bn needs backward computation.
I0423 22:44:03.395617 21205 net.cpp:198] conv2_3_ex needs backward computation.
I0423 22:44:03.395620 21205 net.cpp:198] res2_2_res2_2_0_split needs backward computation.
I0423 22:44:03.395623 21205 net.cpp:198] res2_2 needs backward computation.
I0423 22:44:03.395627 21205 net.cpp:198] conv2_2_em/scale needs backward computation.
I0423 22:44:03.395629 21205 net.cpp:198] conv2_2_em/bn needs backward computation.
I0423 22:44:03.395632 21205 net.cpp:198] conv2_2_em needs backward computation.
I0423 22:44:03.395635 21205 net.cpp:198] relu2_2_dw needs backward computation.
I0423 22:44:03.395637 21205 net.cpp:198] conv2_2_dw/scale needs backward computation.
I0423 22:44:03.395640 21205 net.cpp:198] conv2_2_dw/bn needs backward computation.
I0423 22:44:03.395643 21205 net.cpp:198] conv2_2_dw needs backward computation.
I0423 22:44:03.395647 21205 net.cpp:198] relu2_2_ex needs backward computation.
I0423 22:44:03.395649 21205 net.cpp:198] conv2_2_ex/scale needs backward computation.
I0423 22:44:03.395651 21205 net.cpp:198] conv2_2_ex/bn needs backward computation.
I0423 22:44:03.395655 21205 net.cpp:198] conv2_2_ex needs backward computation.
I0423 22:44:03.395658 21205 net.cpp:198] res2_1_res2_1_0_split needs backward computation.
I0423 22:44:03.395660 21205 net.cpp:198] res2_1 needs backward computation.
I0423 22:44:03.395664 21205 net.cpp:198] conv2_1_em/scale needs backward computation.
I0423 22:44:03.395668 21205 net.cpp:198] conv2_1_em/bn needs backward computation.
I0423 22:44:03.395670 21205 net.cpp:198] conv2_1_em needs backward computation.
I0423 22:44:03.395673 21205 net.cpp:198] relu2_1_dw needs backward computation.
I0423 22:44:03.395675 21205 net.cpp:198] conv2_1_dw/scale needs backward computation.
I0423 22:44:03.395679 21205 net.cpp:198] conv2_1_dw/bn needs backward computation.
I0423 22:44:03.395681 21205 net.cpp:198] conv2_1_dw needs backward computation.
I0423 22:44:03.395684 21205 net.cpp:198] relu2_1_ex needs backward computation.
I0423 22:44:03.395687 21205 net.cpp:198] conv2_1_ex/scale needs backward computation.
I0423 22:44:03.395690 21205 net.cpp:198] conv2_1_ex/bn needs backward computation.
I0423 22:44:03.395694 21205 net.cpp:198] conv2_1_ex needs backward computation.
I0423 22:44:03.395696 21205 net.cpp:198] conv2_em_conv2_em/scale_0_split needs backward computation.
I0423 22:44:03.395707 21205 net.cpp:198] conv2_em/scale needs backward computation.
I0423 22:44:03.395711 21205 net.cpp:198] conv2_em/bn needs backward computation.
I0423 22:44:03.395714 21205 net.cpp:198] conv2_em needs backward computation.
I0423 22:44:03.395716 21205 net.cpp:198] relu2_dw needs backward computation.
I0423 22:44:03.395720 21205 net.cpp:198] conv2_dw/scale needs backward computation.
I0423 22:44:03.395723 21205 net.cpp:198] conv2_dw/bn needs backward computation.
I0423 22:44:03.395725 21205 net.cpp:198] conv2_dw needs backward computation.
I0423 22:44:03.395728 21205 net.cpp:198] relu2_ex needs backward computation.
I0423 22:44:03.395731 21205 net.cpp:198] conv2_ex/scale needs backward computation.
I0423 22:44:03.395735 21205 net.cpp:198] conv2_ex/bn needs backward computation.
I0423 22:44:03.395737 21205 net.cpp:198] conv2_ex needs backward computation.
I0423 22:44:03.395740 21205 net.cpp:198] relu1_dw needs backward computation.
I0423 22:44:03.395742 21205 net.cpp:198] conv1_dw/scale needs backward computation.
I0423 22:44:03.395746 21205 net.cpp:198] conv1_dw/bn needs backward computation.
I0423 22:44:03.395748 21205 net.cpp:198] conv1_dw needs backward computation.
I0423 22:44:03.395751 21205 net.cpp:198] relu1 needs backward computation.
I0423 22:44:03.395754 21205 net.cpp:198] conv1/scale needs backward computation.
I0423 22:44:03.395758 21205 net.cpp:198] conv1/bn needs backward computation.
I0423 22:44:03.395761 21205 net.cpp:198] conv1 needs backward computation.
I0423 22:44:03.395766 21205 net.cpp:200] label_data_1_split does not need backward computation.
I0423 22:44:03.395769 21205 net.cpp:200] data does not need backward computation.
I0423 22:44:03.395772 21205 net.cpp:242] This network produces output accuracy
I0423 22:44:03.395776 21205 net.cpp:242] This network produces output softmax_loss
I0423 22:44:03.395889 21205 net.cpp:255] Network initialization done.
I0423 22:44:03.396313 21205 solver.cpp:57] Solver scaffolding done.
I0423 22:44:03.411953 21205 caffe.cpp:239] Starting Optimization
I0423 22:44:04.948556 21210 upgrade_proto.cpp:79] Attempting to upgrade batch norm layers using deprecated params: model1.prototxt
I0423 22:44:04.948587 21210 upgrade_proto.cpp:82] Successfully upgraded batch norm layers using deprecated params.
I0423 22:44:05.011910 21212 upgrade_proto.cpp:79] Attempting to upgrade batch norm layers using deprecated params: model1.prototxt
I0423 22:44:05.011940 21212 upgrade_proto.cpp:82] Successfully upgraded batch norm layers using deprecated params.
I0423 22:44:05.113169 21211 upgrade_proto.cpp:79] Attempting to upgrade batch norm layers using deprecated params: model1.prototxt
I0423 22:44:05.113200 21211 upgrade_proto.cpp:82] Successfully upgraded batch norm layers using deprecated params.
I0423 22:44:08.959447 21205 solver.cpp:293] Solving MobileFaceNet
I0423 22:44:08.959473 21205 solver.cpp:294] Learning Rate Policy: multistep
I0423 22:44:11.187355 21205 solver.cpp:239] Iteration 0 (-8.07886e+15 iter/s, 2.22774s/100 iters), loss = 12.5129
I0423 22:44:11.187391 21205 solver.cpp:258]     Train net output #0: accuracy = 0
I0423 22:44:11.187399 21205 solver.cpp:258]     Train net output #1: softmax_loss = 12.5129 (* 1 = 12.5129 loss)
I0423 22:44:11.187410 21205 sgd_solver.cpp:112] Iteration 0, lr = 0.1
I0423 22:44:43.204911 21205 solver.cpp:239] Iteration 100 (3.12328 iter/s, 32.0176s/100 iters), loss = 9.20626
I0423 22:44:43.205008 21205 solver.cpp:258]     Train net output #0: accuracy = 0.0078125
I0423 22:44:43.205020 21205 solver.cpp:258]     Train net output #1: softmax_loss = 9.20626 (* 1 = 9.20626 loss)
I0423 22:44:43.205030 21205 sgd_solver.cpp:112] Iteration 100, lr = 0.1
I0423 22:45:14.749655 21205 solver.cpp:239] Iteration 200 (3.1701 iter/s, 31.5447s/100 iters), loss = 9.02914
I0423 22:45:14.749771 21205 solver.cpp:258]     Train net output #0: accuracy = 0.015625
I0423 22:45:14.749783 21205 solver.cpp:258]     Train net output #1: softmax_loss = 9.02914 (* 1 = 9.02914 loss)
I0423 22:45:14.749794 21205 sgd_solver.cpp:112] Iteration 200, lr = 0.1
I0423 22:45:46.329871 21205 solver.cpp:239] Iteration 300 (3.16654 iter/s, 31.5802s/100 iters), loss = 8.20276
I0423 22:45:46.329972 21205 solver.cpp:258]     Train net output #0: accuracy = 0.0234375
I0423 22:45:46.329985 21205 solver.cpp:258]     Train net output #1: softmax_loss = 8.20276 (* 1 = 8.20276 loss)
I0423 22:45:46.329996 21205 sgd_solver.cpp:112] Iteration 300, lr = 0.1
I0423 22:46:17.928683 21205 solver.cpp:239] Iteration 400 (3.16468 iter/s, 31.5988s/100 iters), loss = 7.63113
I0423 22:46:17.928791 21205 solver.cpp:258]     Train net output #0: accuracy = 0.015625
I0423 22:46:17.928802 21205 solver.cpp:258]     Train net output #1: softmax_loss = 7.63113 (* 1 = 7.63113 loss)
I0423 22:46:17.928813 21205 sgd_solver.cpp:112] Iteration 400, lr = 0.1
I0423 22:46:49.533177 21205 solver.cpp:239] Iteration 500 (3.16411 iter/s, 31.6045s/100 iters), loss = 7.84097
I0423 22:46:49.533272 21205 solver.cpp:258]     Train net output #0: accuracy = 0.03125
I0423 22:46:49.533283 21205 solver.cpp:258]     Train net output #1: softmax_loss = 7.84097 (* 1 = 7.84097 loss)
I0423 22:46:49.533293 21205 sgd_solver.cpp:112] Iteration 500, lr = 0.1
I0423 22:47:21.134536 21205 solver.cpp:239] Iteration 600 (3.16442 iter/s, 31.6014s/100 iters), loss = 8.24407
I0423 22:47:21.134639 21205 solver.cpp:258]     Train net output #0: accuracy = 0.0234375
I0423 22:47:21.134650 21205 solver.cpp:258]     Train net output #1: softmax_loss = 8.24407 (* 1 = 8.24407 loss)
I0423 22:47:21.134660 21205 sgd_solver.cpp:112] Iteration 600, lr = 0.1
I0423 22:47:52.730811 21205 solver.cpp:239] Iteration 700 (3.16493 iter/s, 31.5963s/100 iters), loss = 8.3861
I0423 22:47:52.730902 21205 solver.cpp:258]     Train net output #0: accuracy = 0.0234375
I0423 22:47:52.730913 21205 solver.cpp:258]     Train net output #1: softmax_loss = 8.3861 (* 1 = 8.3861 loss)
I0423 22:47:52.730924 21205 sgd_solver.cpp:112] Iteration 700, lr = 0.1
I0423 22:48:07.284876 21209 data_layer.cpp:73] Restarting data prefetching from start.
I0423 22:48:24.322542 21205 solver.cpp:239] Iteration 800 (3.16539 iter/s, 31.5917s/100 iters), loss = 8.49026
I0423 22:48:24.322618 21205 solver.cpp:258]     Train net output #0: accuracy = 0.015625
I0423 22:48:24.322630 21205 solver.cpp:258]     Train net output #1: softmax_loss = 8.49026 (* 1 = 8.49026 loss)
I0423 22:48:24.322640 21205 sgd_solver.cpp:112] Iteration 800, lr = 0.1
I0423 22:48:55.910203 21205 solver.cpp:239] Iteration 900 (3.16579 iter/s, 31.5877s/100 iters), loss = 8.03672
I0423 22:48:55.910290 21205 solver.cpp:258]     Train net output #0: accuracy = 0.015625
I0423 22:48:55.910302 21205 solver.cpp:258]     Train net output #1: softmax_loss = 8.03672 (* 1 = 8.03672 loss)
I0423 22:48:55.910311 21205 sgd_solver.cpp:112] Iteration 900, lr = 0.1
I0423 22:49:27.497195 21205 solver.cpp:239] Iteration 1000 (3.16586 iter/s, 31.587s/100 iters), loss = 8.3791
I0423 22:49:27.497274 21205 solver.cpp:258]     Train net output #0: accuracy = 0
I0423 22:49:27.497287 21205 solver.cpp:258]     Train net output #1: softmax_loss = 8.3791 (* 1 = 8.3791 loss)
I0423 22:49:27.497297 21205 sgd_solver.cpp:112] Iteration 1000, lr = 0.1
I0423 22:49:59.092545 21205 solver.cpp:239] Iteration 1100 (3.16502 iter/s, 31.5954s/100 iters), loss = 8.42149
I0423 22:49:59.092628 21205 solver.cpp:258]     Train net output #0: accuracy = 0.0234375
I0423 22:49:59.092640 21205 solver.cpp:258]     Train net output #1: softmax_loss = 8.42149 (* 1 = 8.42149 loss)
I0423 22:49:59.092650 21205 sgd_solver.cpp:112] Iteration 1100, lr = 0.1
I0423 22:50:30.690903 21205 solver.cpp:239] Iteration 1200 (3.16472 iter/s, 31.5984s/100 iters), loss = 8.46171
I0423 22:50:30.691023 21205 solver.cpp:258]     Train net output #0: accuracy = 0.0390625
I0423 22:50:30.691036 21205 solver.cpp:258]     Train net output #1: softmax_loss = 8.46171 (* 1 = 8.46171 loss)
I0423 22:50:30.691046 21205 sgd_solver.cpp:112] Iteration 1200, lr = 0.1
I0423 22:51:02.294669 21205 solver.cpp:239] Iteration 1300 (3.16418 iter/s, 31.6037s/100 iters), loss = 8.68192
I0423 22:51:02.294811 21205 solver.cpp:258]     Train net output #0: accuracy = 0.015625
I0423 22:51:02.294826 21205 solver.cpp:258]     Train net output #1: softmax_loss = 8.68192 (* 1 = 8.68192 loss)
I0423 22:51:02.294836 21205 sgd_solver.cpp:112] Iteration 1300, lr = 0.1
I0423 22:51:33.891960 21205 solver.cpp:239] Iteration 1400 (3.16483 iter/s, 31.5972s/100 iters), loss = 8.54793
I0423 22:51:33.892069 21205 solver.cpp:258]     Train net output #0: accuracy = 0.015625
I0423 22:51:33.892082 21205 solver.cpp:258]     Train net output #1: softmax_loss = 8.54793 (* 1 = 8.54793 loss)
I0423 22:51:33.892092 21205 sgd_solver.cpp:112] Iteration 1400, lr = 0.1
I0423 22:52:04.261176 21209 data_layer.cpp:73] Restarting data prefetching from start.
I0423 22:52:05.494930 21205 solver.cpp:239] Iteration 1500 (3.16426 iter/s, 31.6029s/100 iters), loss = 8.55551
I0423 22:52:05.494961 21205 solver.cpp:258]     Train net output #0: accuracy = 0.03125
I0423 22:52:05.494971 21205 solver.cpp:258]     Train net output #1: softmax_loss = 8.55551 (* 1 = 8.55551 loss)
I0423 22:52:05.494982 21205 sgd_solver.cpp:112] Iteration 1500, lr = 0.1
I0423 22:52:37.106770 21205 solver.cpp:239] Iteration 1600 (3.16337 iter/s, 31.6119s/100 iters), loss = 8.89188
I0423 22:52:37.106842 21205 solver.cpp:258]     Train net output #0: accuracy = 0.0390625
I0423 22:52:37.106853 21205 solver.cpp:258]     Train net output #1: softmax_loss = 8.89188 (* 1 = 8.89188 loss)
I0423 22:52:37.106863 21205 sgd_solver.cpp:112] Iteration 1600, lr = 0.1
I0423 22:53:08.728835 21205 solver.cpp:239] Iteration 1700 (3.16235 iter/s, 31.6221s/100 iters), loss = 8.39836
I0423 22:53:08.728931 21205 solver.cpp:258]     Train net output #0: accuracy = 0.03125
I0423 22:53:08.728943 21205 solver.cpp:258]     Train net output #1: softmax_loss = 8.39836 (* 1 = 8.39836 loss)
I0423 22:53:08.728953 21205 sgd_solver.cpp:112] Iteration 1700, lr = 0.1
I0423 22:53:40.358983 21205 solver.cpp:239] Iteration 1800 (3.16154 iter/s, 31.6301s/100 iters), loss = 8.30381
I0423 22:53:40.359056 21205 solver.cpp:258]     Train net output #0: accuracy = 0.03125
I0423 22:53:40.359068 21205 solver.cpp:258]     Train net output #1: softmax_loss = 8.30381 (* 1 = 8.30381 loss)
I0423 22:53:40.359078 21205 sgd_solver.cpp:112] Iteration 1800, lr = 0.1
I0423 22:54:11.994267 21205 solver.cpp:239] Iteration 1900 (3.16103 iter/s, 31.6353s/100 iters), loss = 8.69258
I0423 22:54:11.994354 21205 solver.cpp:258]     Train net output #0: accuracy = 0.03125
I0423 22:54:11.994366 21205 solver.cpp:258]     Train net output #1: softmax_loss = 8.69258 (* 1 = 8.69258 loss)
I0423 22:54:11.994376 21205 sgd_solver.cpp:112] Iteration 1900, lr = 0.1
I0423 22:54:43.636374 21205 solver.cpp:239] Iteration 2000 (3.16035 iter/s, 31.6421s/100 iters), loss = 8.53956
I0423 22:54:43.636469 21205 solver.cpp:258]     Train net output #0: accuracy = 0.0390625
I0423 22:54:43.636482 21205 solver.cpp:258]     Train net output #1: softmax_loss = 8.53956 (* 1 = 8.53956 loss)
I0423 22:54:43.636492 21205 sgd_solver.cpp:112] Iteration 2000, lr = 0.1
I0423 22:55:15.299667 21205 solver.cpp:239] Iteration 2100 (3.15823 iter/s, 31.6633s/100 iters), loss = 8.04495
I0423 22:55:15.299758 21205 solver.cpp:258]     Train net output #0: accuracy = 0.09375
I0423 22:55:15.299770 21205 solver.cpp:258]     Train net output #1: softmax_loss = 8.04495 (* 1 = 8.04495 loss)
I0423 22:55:15.299780 21205 sgd_solver.cpp:112] Iteration 2100, lr = 0.1
I0423 22:55:46.959836 21205 solver.cpp:239] Iteration 2200 (3.15854 iter/s, 31.6602s/100 iters), loss = 8.81162
I0423 22:55:46.959906 21205 solver.cpp:258]     Train net output #0: accuracy = 0.0546875
I0423 22:55:46.959918 21205 solver.cpp:258]     Train net output #1: softmax_loss = 8.81162 (* 1 = 8.81162 loss)
I0423 22:55:46.959928 21205 sgd_solver.cpp:112] Iteration 2200, lr = 0.1
I0423 22:56:01.562610 21209 data_layer.cpp:73] Restarting data prefetching from start.
I0423 22:56:18.628149 21205 solver.cpp:239] Iteration 2300 (3.15773 iter/s, 31.6683s/100 iters), loss = 8.39638
I0423 22:56:18.628242 21205 solver.cpp:258]     Train net output #0: accuracy = 0.046875
I0423 22:56:18.628254 21205 solver.cpp:258]     Train net output #1: softmax_loss = 8.39638 (* 1 = 8.39638 loss)
I0423 22:56:18.628263 21205 sgd_solver.cpp:112] Iteration 2300, lr = 0.1
I0423 22:56:50.298321 21205 solver.cpp:239] Iteration 2400 (3.15755 iter/s, 31.6702s/100 iters), loss = 8.34664
I0423 22:56:50.298436 21205 solver.cpp:258]     Train net output #0: accuracy = 0.0703125
I0423 22:56:50.298449 21205 solver.cpp:258]     Train net output #1: softmax_loss = 8.34664 (* 1 = 8.34664 loss)
I0423 22:56:50.298458 21205 sgd_solver.cpp:112] Iteration 2400, lr = 0.1
I0423 22:57:21.973453 21205 solver.cpp:239] Iteration 2500 (3.15705 iter/s, 31.6751s/100 iters), loss = 8.2605
I0423 22:57:21.973543 21205 solver.cpp:258]     Train net output #0: accuracy = 0.0625
I0423 22:57:21.973556 21205 solver.cpp:258]     Train net output #1: softmax_loss = 8.2605 (* 1 = 8.2605 loss)
I0423 22:57:21.973564 21205 sgd_solver.cpp:112] Iteration 2500, lr = 0.1
I0423 22:57:53.650665 21205 solver.cpp:239] Iteration 2600 (3.15684 iter/s, 31.6772s/100 iters), loss = 7.6324
I0423 22:57:53.650760 21205 solver.cpp:258]     Train net output #0: accuracy = 0.117188
I0423 22:57:53.650773 21205 solver.cpp:258]     Train net output #1: softmax_loss = 7.6324 (* 1 = 7.6324 loss)
I0423 22:57:53.650781 21205 sgd_solver.cpp:112] Iteration 2600, lr = 0.1
I0423 22:58:25.334084 21205 solver.cpp:239] Iteration 2700 (3.15623 iter/s, 31.6834s/100 iters), loss = 7.33057
I0423 22:58:25.334157 21205 solver.cpp:258]     Train net output #0: accuracy = 0.078125
I0423 22:58:25.334168 21205 solver.cpp:258]     Train net output #1: softmax_loss = 7.33057 (* 1 = 7.33057 loss)
I0423 22:58:25.334178 21205 sgd_solver.cpp:112] Iteration 2700, lr = 0.1
I0423 22:58:57.029011 21205 solver.cpp:239] Iteration 2800 (3.15508 iter/s, 31.6949s/100 iters), loss = 7.35331
I0423 22:58:57.029091 21205 solver.cpp:258]     Train net output #0: accuracy = 0.117188
I0423 22:58:57.029103 21205 solver.cpp:258]     Train net output #1: softmax_loss = 7.35331 (* 1 = 7.35331 loss)
I0423 22:58:57.029114 21205 sgd_solver.cpp:112] Iteration 2800, lr = 0.1
I0423 22:59:28.720165 21205 solver.cpp:239] Iteration 2900 (3.15545 iter/s, 31.6912s/100 iters), loss = 7.71259
I0423 22:59:28.720268 21205 solver.cpp:258]     Train net output #0: accuracy = 0.0703125
I0423 22:59:28.720279 21205 solver.cpp:258]     Train net output #1: softmax_loss = 7.71259 (* 1 = 7.71259 loss)
I0423 22:59:28.720289 21205 sgd_solver.cpp:112] Iteration 2900, lr = 0.1
I0423 22:59:59.486044 21209 data_layer.cpp:73] Restarting data prefetching from start.
I0423 23:00:00.418001 21205 solver.cpp:239] Iteration 3000 (3.15479 iter/s, 31.6978s/100 iters), loss = 7.31141
I0423 23:00:00.418033 21205 solver.cpp:258]     Train net output #0: accuracy = 0.09375
I0423 23:00:00.418042 21205 solver.cpp:258]     Train net output #1: softmax_loss = 7.31141 (* 1 = 7.31141 loss)
I0423 23:00:00.418051 21205 sgd_solver.cpp:112] Iteration 3000, lr = 0.1
I0423 23:00:32.114326 21205 solver.cpp:239] Iteration 3100 (3.15493 iter/s, 31.6964s/100 iters), loss = 7.32313
I0423 23:00:32.114393 21205 solver.cpp:258]     Train net output #0: accuracy = 0.101562
I0423 23:00:32.114404 21205 solver.cpp:258]     Train net output #1: softmax_loss = 7.32313 (* 1 = 7.32313 loss)
I0423 23:00:32.114414 21205 sgd_solver.cpp:112] Iteration 3100, lr = 0.1
I0423 23:01:03.815897 21205 solver.cpp:239] Iteration 3200 (3.15442 iter/s, 31.7016s/100 iters), loss = 6.66688
I0423 23:01:03.815980 21205 solver.cpp:258]     Train net output #0: accuracy = 0.101562
I0423 23:01:03.815992 21205 solver.cpp:258]     Train net output #1: softmax_loss = 6.66688 (* 1 = 6.66688 loss)
I0423 23:01:03.816002 21205 sgd_solver.cpp:112] Iteration 3200, lr = 0.1
I0423 23:01:35.522212 21205 solver.cpp:239] Iteration 3300 (3.15395 iter/s, 31.7063s/100 iters), loss = 6.24951
I0423 23:01:35.522270 21205 solver.cpp:258]     Train net output #0: accuracy = 0.148438
I0423 23:01:35.522281 21205 solver.cpp:258]     Train net output #1: softmax_loss = 6.24951 (* 1 = 6.24951 loss)
I0423 23:01:35.522290 21205 sgd_solver.cpp:112] Iteration 3300, lr = 0.1
I0423 23:02:07.229236 21205 solver.cpp:239] Iteration 3400 (3.15387 iter/s, 31.707s/100 iters), loss = 6.77249
I0423 23:02:07.229349 21205 solver.cpp:258]     Train net output #0: accuracy = 0.109375
I0423 23:02:07.229362 21205 solver.cpp:258]     Train net output #1: softmax_loss = 6.77249 (* 1 = 6.77249 loss)
I0423 23:02:07.229372 21205 sgd_solver.cpp:112] Iteration 3400, lr = 0.1
I0423 23:02:38.939280 21205 solver.cpp:239] Iteration 3500 (3.15358 iter/s, 31.71s/100 iters), loss = 6.79375
I0423 23:02:38.939355 21205 solver.cpp:258]     Train net output #0: accuracy = 0.109375
I0423 23:02:38.939368 21205 solver.cpp:258]     Train net output #1: softmax_loss = 6.79375 (* 1 = 6.79375 loss)
I0423 23:02:38.939378 21205 sgd_solver.cpp:112] Iteration 3500, lr = 0.1
I0423 23:03:10.663702 21205 solver.cpp:239] Iteration 3600 (3.15213 iter/s, 31.7246s/100 iters), loss = 6.68921
I0423 23:03:10.663800 21205 solver.cpp:258]     Train net output #0: accuracy = 0.125
I0423 23:03:10.663810 21205 solver.cpp:258]     Train net output #1: softmax_loss = 6.68921 (* 1 = 6.68921 loss)
I0423 23:03:10.663820 21205 sgd_solver.cpp:112] Iteration 3600, lr = 0.1
I0423 23:03:42.390537 21205 solver.cpp:239] Iteration 3700 (3.15189 iter/s, 31.727s/100 iters), loss = 6.50303
I0423 23:03:42.390609 21205 solver.cpp:258]     Train net output #0: accuracy = 0.125
I0423 23:03:42.390620 21205 solver.cpp:258]     Train net output #1: softmax_loss = 6.50303 (* 1 = 6.50303 loss)
I0423 23:03:42.390630 21205 sgd_solver.cpp:112] Iteration 3700, lr = 0.1
I0423 23:03:57.333981 21209 data_layer.cpp:73] Restarting data prefetching from start.
I0423 23:04:14.122730 21205 solver.cpp:239] Iteration 3800 (3.15135 iter/s, 31.7324s/100 iters), loss = 7.08941
I0423 23:04:14.122812 21205 solver.cpp:258]     Train net output #0: accuracy = 0.09375
I0423 23:04:14.122823 21205 solver.cpp:258]     Train net output #1: softmax_loss = 7.08941 (* 1 = 7.08941 loss)
I0423 23:04:14.122834 21205 sgd_solver.cpp:112] Iteration 3800, lr = 0.1
I0423 23:04:45.851276 21205 solver.cpp:239] Iteration 3900 (3.15172 iter/s, 31.7287s/100 iters), loss = 7.44084
I0423 23:04:45.851332 21205 solver.cpp:258]     Train net output #0: accuracy = 0.125
I0423 23:04:45.851343 21205 solver.cpp:258]     Train net output #1: softmax_loss = 7.44084 (* 1 = 7.44084 loss)
I0423 23:04:45.851353 21205 sgd_solver.cpp:112] Iteration 3900, lr = 0.1
I0423 23:05:17.271723 21205 solver.cpp:468] Snapshotting to binary proto file result/model_iter_4000.caffemodel
I0423 23:05:17.495383 21205 sgd_solver.cpp:280] Snapshotting solver state to binary proto file result/model_iter_4000.solverstate
I0423 23:05:17.828857 21205 solver.cpp:239] Iteration 4000 (3.12717 iter/s, 31.9778s/100 iters), loss = 6.86306
I0423 23:05:17.828888 21205 solver.cpp:258]     Train net output #0: accuracy = 0.132812
I0423 23:05:17.828897 21205 solver.cpp:258]     Train net output #1: softmax_loss = 6.86306 (* 1 = 6.86306 loss)
I0423 23:05:17.828907 21205 sgd_solver.cpp:112] Iteration 4000, lr = 0.1
I0423 23:05:49.566355 21205 solver.cpp:239] Iteration 4100 (3.15083 iter/s, 31.7377s/100 iters), loss = 6.49546
I0423 23:05:49.566437 21205 solver.cpp:258]     Train net output #0: accuracy = 0.140625
I0423 23:05:49.566447 21205 solver.cpp:258]     Train net output #1: softmax_loss = 6.49546 (* 1 = 6.49546 loss)
I0423 23:05:49.566457 21205 sgd_solver.cpp:112] Iteration 4100, lr = 0.1
I0423 23:06:21.290499 21205 solver.cpp:239] Iteration 4200 (3.15216 iter/s, 31.7243s/100 iters), loss = 6.10908
I0423 23:06:21.290557 21205 solver.cpp:258]     Train net output #0: accuracy = 0.132812
I0423 23:06:21.290568 21205 solver.cpp:258]     Train net output #1: softmax_loss = 6.10908 (* 1 = 6.10908 loss)
I0423 23:06:21.290578 21205 sgd_solver.cpp:112] Iteration 4200, lr = 0.1
I0423 23:06:53.026479 21205 solver.cpp:239] Iteration 4300 (3.15098 iter/s, 31.7361s/100 iters), loss = 6.3348
I0423 23:06:53.026585 21205 solver.cpp:258]     Train net output #0: accuracy = 0.171875
I0423 23:06:53.026597 21205 solver.cpp:258]     Train net output #1: softmax_loss = 6.3348 (* 1 = 6.3348 loss)
I0423 23:06:53.026607 21205 sgd_solver.cpp:112] Iteration 4300, lr = 0.1
I0423 23:07:24.761967 21205 solver.cpp:239] Iteration 4400 (3.15104 iter/s, 31.7356s/100 iters), loss = 6.01106
I0423 23:07:24.762063 21205 solver.cpp:258]     Train net output #0: accuracy = 0.195312
I0423 23:07:24.762075 21205 solver.cpp:258]     Train net output #1: softmax_loss = 6.01106 (* 1 = 6.01106 loss)
I0423 23:07:24.762085 21205 sgd_solver.cpp:112] Iteration 4400, lr = 0.1
I0423 23:07:55.586688 21209 data_layer.cpp:73] Restarting data prefetching from start.
I0423 23:07:56.500665 21205 solver.cpp:239] Iteration 4500 (3.15072 iter/s, 31.7388s/100 iters), loss = 6.6192
I0423 23:07:56.500699 21205 solver.cpp:258]     Train net output #0: accuracy = 0.125
I0423 23:07:56.500707 21205 solver.cpp:258]     Train net output #1: softmax_loss = 6.6192 (* 1 = 6.6192 loss)
I0423 23:07:56.500717 21205 sgd_solver.cpp:112] Iteration 4500, lr = 0.1
I0423 23:08:28.244809 21205 solver.cpp:239] Iteration 4600 (3.15017 iter/s, 31.7443s/100 iters), loss = 5.35577
I0423 23:08:28.244910 21205 solver.cpp:258]     Train net output #0: accuracy = 0.1875
I0423 23:08:28.244922 21205 solver.cpp:258]     Train net output #1: softmax_loss = 5.35577 (* 1 = 5.35577 loss)
I0423 23:08:28.244933 21205 sgd_solver.cpp:112] Iteration 4600, lr = 0.1
I0423 23:08:59.990085 21205 solver.cpp:239] Iteration 4700 (3.15007 iter/s, 31.7454s/100 iters), loss = 5.83249
I0423 23:08:59.990166 21205 solver.cpp:258]     Train net output #0: accuracy = 0.203125
I0423 23:08:59.990178 21205 solver.cpp:258]     Train net output #1: softmax_loss = 5.83249 (* 1 = 5.83249 loss)
I0423 23:08:59.990188 21205 sgd_solver.cpp:112] Iteration 4700, lr = 0.1
I0423 23:09:31.731592 21205 solver.cpp:239] Iteration 4800 (3.15044 iter/s, 31.7416s/100 iters), loss = 6.04591
I0423 23:09:31.731662 21205 solver.cpp:258]     Train net output #0: accuracy = 0.148438
I0423 23:09:31.731673 21205 solver.cpp:258]     Train net output #1: softmax_loss = 6.04591 (* 1 = 6.04591 loss)
I0423 23:09:31.731683 21205 sgd_solver.cpp:112] Iteration 4800, lr = 0.1
I0423 23:10:03.476769 21205 solver.cpp:239] Iteration 4900 (3.15007 iter/s, 31.7453s/100 iters), loss = 6.22823
I0423 23:10:03.476847 21205 solver.cpp:258]     Train net output #0: accuracy = 0.21875
I0423 23:10:03.476858 21205 solver.cpp:258]     Train net output #1: softmax_loss = 6.22823 (* 1 = 6.22823 loss)
I0423 23:10:03.476868 21205 sgd_solver.cpp:112] Iteration 4900, lr = 0.1
I0423 23:10:35.219275 21205 solver.cpp:239] Iteration 5000 (3.15034 iter/s, 31.7426s/100 iters), loss = 5.87587
I0423 23:10:35.219346 21205 solver.cpp:258]     Train net output #0: accuracy = 0.171875
I0423 23:10:35.219357 21205 solver.cpp:258]     Train net output #1: softmax_loss = 5.87587 (* 1 = 5.87587 loss)
I0423 23:10:35.219367 21205 sgd_solver.cpp:112] Iteration 5000, lr = 0.1
I0423 23:11:06.970530 21205 solver.cpp:239] Iteration 5100 (3.14947 iter/s, 31.7514s/100 iters), loss = 6.16859
I0423 23:11:06.970608 21205 solver.cpp:258]     Train net output #0: accuracy = 0.171875
I0423 23:11:06.970619 21205 solver.cpp:258]     Train net output #1: softmax_loss = 6.16859 (* 1 = 6.16859 loss)
I0423 23:11:06.970629 21205 sgd_solver.cpp:112] Iteration 5100, lr = 0.1
I0423 23:11:38.720324 21205 solver.cpp:239] Iteration 5200 (3.14962 iter/s, 31.7499s/100 iters), loss = 5.19341
I0423 23:11:38.720393 21205 solver.cpp:258]     Train net output #0: accuracy = 0.203125
I0423 23:11:38.720404 21205 solver.cpp:258]     Train net output #1: softmax_loss = 5.19341 (* 1 = 5.19341 loss)
I0423 23:11:38.720414 21205 sgd_solver.cpp:112] Iteration 5200, lr = 0.1
I0423 23:11:53.983613 21209 data_layer.cpp:73] Restarting data prefetching from start.
I0423 23:12:10.473770 21205 solver.cpp:239] Iteration 5300 (3.14925 iter/s, 31.7535s/100 iters), loss = 5.48346
I0423 23:12:10.473881 21205 solver.cpp:258]     Train net output #0: accuracy = 0.179688
I0423 23:12:10.473893 21205 solver.cpp:258]     Train net output #1: softmax_loss = 5.48346 (* 1 = 5.48346 loss)
I0423 23:12:10.473906 21205 sgd_solver.cpp:112] Iteration 5300, lr = 0.1
I0423 23:12:42.230350 21205 solver.cpp:239] Iteration 5400 (3.14895 iter/s, 31.7566s/100 iters), loss = 5.78612
I0423 23:12:42.230444 21205 solver.cpp:258]     Train net output #0: accuracy = 0.164062
I0423 23:12:42.230455 21205 solver.cpp:258]     Train net output #1: softmax_loss = 5.78612 (* 1 = 5.78612 loss)
I0423 23:12:42.230466 21205 sgd_solver.cpp:112] Iteration 5400, lr = 0.1
I0423 23:13:13.988183 21205 solver.cpp:239] Iteration 5500 (3.14882 iter/s, 31.7579s/100 iters), loss = 5.07539
I0423 23:13:13.988262 21205 solver.cpp:258]     Train net output #0: accuracy = 0.226562
I0423 23:13:13.988273 21205 solver.cpp:258]     Train net output #1: softmax_loss = 5.07539 (* 1 = 5.07539 loss)
I0423 23:13:13.988284 21205 sgd_solver.cpp:112] Iteration 5500, lr = 0.1
I0423 23:13:45.748545 21205 solver.cpp:239] Iteration 5600 (3.14857 iter/s, 31.7604s/100 iters), loss = 5.28527
I0423 23:13:45.748617 21205 solver.cpp:258]     Train net output #0: accuracy = 0.195312
I0423 23:13:45.748630 21205 solver.cpp:258]     Train net output #1: softmax_loss = 5.28527 (* 1 = 5.28527 loss)
I0423 23:13:45.748641 21205 sgd_solver.cpp:112] Iteration 5600, lr = 0.1
I0423 23:14:17.503738 21205 solver.cpp:239] Iteration 5700 (3.14908 iter/s, 31.7553s/100 iters), loss = 5.19745
I0423 23:14:17.503818 21205 solver.cpp:258]     Train net output #0: accuracy = 0.234375
I0423 23:14:17.503829 21205 solver.cpp:258]     Train net output #1: softmax_loss = 5.19745 (* 1 = 5.19745 loss)
I0423 23:14:17.503840 21205 sgd_solver.cpp:112] Iteration 5700, lr = 0.1
I0423 23:14:49.262038 21205 solver.cpp:239] Iteration 5800 (3.14878 iter/s, 31.7584s/100 iters), loss = 5.31081
I0423 23:14:49.262116 21205 solver.cpp:258]     Train net output #0: accuracy = 0.21875
I0423 23:14:49.262128 21205 solver.cpp:258]     Train net output #1: softmax_loss = 5.31081 (* 1 = 5.31081 loss)
I0423 23:14:49.262140 21205 sgd_solver.cpp:112] Iteration 5800, lr = 0.1
I0423 23:15:21.024140 21205 solver.cpp:239] Iteration 5900 (3.1484 iter/s, 31.7622s/100 iters), loss = 5.47774
I0423 23:15:21.024212 21205 solver.cpp:258]     Train net output #0: accuracy = 0.195312
I0423 23:15:21.024224 21205 solver.cpp:258]     Train net output #1: softmax_loss = 5.47774 (* 1 = 5.47774 loss)
I0423 23:15:21.024235 21205 sgd_solver.cpp:112] Iteration 5900, lr = 0.1
I0423 23:15:52.183584 21209 data_layer.cpp:73] Restarting data prefetching from start.
I0423 23:15:52.790457 21205 solver.cpp:239] Iteration 6000 (3.14798 iter/s, 31.7664s/100 iters), loss = 5.3499
I0423 23:15:52.790491 21205 solver.cpp:258]     Train net output #0: accuracy = 0.179688
I0423 23:15:52.790503 21205 solver.cpp:258]     Train net output #1: softmax_loss = 5.3499 (* 1 = 5.3499 loss)
I0423 23:15:52.790511 21205 sgd_solver.cpp:112] Iteration 6000, lr = 0.1
I0423 23:16:24.560693 21205 solver.cpp:239] Iteration 6100 (3.14759 iter/s, 31.7703s/100 iters), loss = 5.28972
I0423 23:16:24.560751 21205 solver.cpp:258]     Train net output #0: accuracy = 0.21875
I0423 23:16:24.560762 21205 solver.cpp:258]     Train net output #1: softmax_loss = 5.28972 (* 1 = 5.28972 loss)
I0423 23:16:24.560772 21205 sgd_solver.cpp:112] Iteration 6100, lr = 0.1
I0423 23:16:56.323184 21205 solver.cpp:239] Iteration 6200 (3.14836 iter/s, 31.7626s/100 iters), loss = 5.5075
I0423 23:16:56.323282 21205 solver.cpp:258]     Train net output #0: accuracy = 0.195312
I0423 23:16:56.323295 21205 solver.cpp:258]     Train net output #1: softmax_loss = 5.5075 (* 1 = 5.5075 loss)
I0423 23:16:56.323305 21205 sgd_solver.cpp:112] Iteration 6200, lr = 0.1
I0423 23:17:28.078018 21205 solver.cpp:239] Iteration 6300 (3.14912 iter/s, 31.7549s/100 iters), loss = 5.44958
I0423 23:17:28.078099 21205 solver.cpp:258]     Train net output #0: accuracy = 0.210938
I0423 23:17:28.078112 21205 solver.cpp:258]     Train net output #1: softmax_loss = 5.44958 (* 1 = 5.44958 loss)
I0423 23:17:28.078122 21205 sgd_solver.cpp:112] Iteration 6300, lr = 0.1
I0423 23:17:59.842058 21205 solver.cpp:239] Iteration 6400 (3.14821 iter/s, 31.7641s/100 iters), loss = 6.02569
I0423 23:17:59.842169 21205 solver.cpp:258]     Train net output #0: accuracy = 0.179688
I0423 23:17:59.842181 21205 solver.cpp:258]     Train net output #1: softmax_loss = 6.02569 (* 1 = 6.02569 loss)
I0423 23:17:59.842193 21205 sgd_solver.cpp:112] Iteration 6400, lr = 0.1
I0423 23:18:31.599262 21205 solver.cpp:239] Iteration 6500 (3.14889 iter/s, 31.7572s/100 iters), loss = 4.76217
I0423 23:18:31.599335 21205 solver.cpp:258]     Train net output #0: accuracy = 0.320312
I0423 23:18:31.599347 21205 solver.cpp:258]     Train net output #1: softmax_loss = 4.76217 (* 1 = 4.76217 loss)
I0423 23:18:31.599357 21205 sgd_solver.cpp:112] Iteration 6500, lr = 0.1
I0423 23:19:03.368535 21205 solver.cpp:239] Iteration 6600 (3.14769 iter/s, 31.7693s/100 iters), loss = 4.98155
I0423 23:19:03.368618 21205 solver.cpp:258]     Train net output #0: accuracy = 0.257812
I0423 23:19:03.368630 21205 solver.cpp:258]     Train net output #1: softmax_loss = 4.98155 (* 1 = 4.98155 loss)
I0423 23:19:03.368641 21205 sgd_solver.cpp:112] Iteration 6600, lr = 0.1
I0423 23:19:35.134053 21205 solver.cpp:239] Iteration 6700 (3.14806 iter/s, 31.7656s/100 iters), loss = 5.14213
I0423 23:19:35.134114 21205 solver.cpp:258]     Train net output #0: accuracy = 0.210938
I0423 23:19:35.134124 21205 solver.cpp:258]     Train net output #1: softmax_loss = 5.14213 (* 1 = 5.14213 loss)
I0423 23:19:35.134135 21205 sgd_solver.cpp:112] Iteration 6700, lr = 0.1
I0423 23:19:50.416790 21209 data_layer.cpp:73] Restarting data prefetching from start.
I0423 23:20:06.900450 21205 solver.cpp:239] Iteration 6800 (3.14797 iter/s, 31.7665s/100 iters), loss = 4.89325
I0423 23:20:06.900532 21205 solver.cpp:258]     Train net output #0: accuracy = 0.234375
I0423 23:20:06.900544 21205 solver.cpp:258]     Train net output #1: softmax_loss = 4.89325 (* 1 = 4.89325 loss)
I0423 23:20:06.900554 21205 sgd_solver.cpp:112] Iteration 6800, lr = 0.1
I0423 23:20:38.667331 21205 solver.cpp:239] Iteration 6900 (3.14793 iter/s, 31.7669s/100 iters), loss = 4.74782
I0423 23:20:38.667402 21205 solver.cpp:258]     Train net output #0: accuracy = 0.234375
I0423 23:20:38.667414 21205 solver.cpp:258]     Train net output #1: softmax_loss = 4.74782 (* 1 = 4.74782 loss)
I0423 23:20:38.667424 21205 sgd_solver.cpp:112] Iteration 6900, lr = 0.1
I0423 23:21:10.428295 21205 solver.cpp:239] Iteration 7000 (3.14851 iter/s, 31.761s/100 iters), loss = 4.56177
I0423 23:21:10.428395 21205 solver.cpp:258]     Train net output #0: accuracy = 0.273438
I0423 23:21:10.428406 21205 solver.cpp:258]     Train net output #1: softmax_loss = 4.56177 (* 1 = 4.56177 loss)
I0423 23:21:10.428416 21205 sgd_solver.cpp:112] Iteration 7000, lr = 0.1
I0423 23:21:42.196656 21205 solver.cpp:239] Iteration 7100 (3.14778 iter/s, 31.7684s/100 iters), loss = 5.13321
I0423 23:21:42.196715 21205 solver.cpp:258]     Train net output #0: accuracy = 0.242188
I0423 23:21:42.196727 21205 solver.cpp:258]     Train net output #1: softmax_loss = 5.13321 (* 1 = 5.13321 loss)
I0423 23:21:42.196736 21205 sgd_solver.cpp:112] Iteration 7100, lr = 0.1
I0423 23:22:13.961196 21205 solver.cpp:239] Iteration 7200 (3.14816 iter/s, 31.7646s/100 iters), loss = 5.03267
I0423 23:22:13.961289 21205 solver.cpp:258]     Train net output #0: accuracy = 0.242188
I0423 23:22:13.961302 21205 solver.cpp:258]     Train net output #1: softmax_loss = 5.03267 (* 1 = 5.03267 loss)
I0423 23:22:13.961313 21205 sgd_solver.cpp:112] Iteration 7200, lr = 0.1
I0423 23:22:45.726478 21205 solver.cpp:239] Iteration 7300 (3.14809 iter/s, 31.7653s/100 iters), loss = 4.47344
I0423 23:22:45.726534 21205 solver.cpp:258]     Train net output #0: accuracy = 0.3125
I0423 23:22:45.726546 21205 solver.cpp:258]     Train net output #1: softmax_loss = 4.47344 (* 1 = 4.47344 loss)
I0423 23:22:45.726554 21205 sgd_solver.cpp:112] Iteration 7300, lr = 0.1
I0423 23:23:17.493839 21205 solver.cpp:239] Iteration 7400 (3.14788 iter/s, 31.7674s/100 iters), loss = 5.47005
I0423 23:23:17.493949 21205 solver.cpp:258]     Train net output #0: accuracy = 0.203125
I0423 23:23:17.493962 21205 solver.cpp:258]     Train net output #1: softmax_loss = 5.47005 (* 1 = 5.47005 loss)
I0423 23:23:17.493973 21205 sgd_solver.cpp:112] Iteration 7400, lr = 0.1
I0423 23:23:48.961444 21209 data_layer.cpp:73] Restarting data prefetching from start.
I0423 23:23:49.259413 21205 solver.cpp:239] Iteration 7500 (3.14806 iter/s, 31.7656s/100 iters), loss = 5.28916
I0423 23:23:49.259443 21205 solver.cpp:258]     Train net output #0: accuracy = 0.195312
I0423 23:23:49.259451 21205 solver.cpp:258]     Train net output #1: softmax_loss = 5.28916 (* 1 = 5.28916 loss)
I0423 23:23:49.259461 21205 sgd_solver.cpp:112] Iteration 7500, lr = 0.1
I0423 23:24:21.026350 21205 solver.cpp:239] Iteration 7600 (3.14792 iter/s, 31.767s/100 iters), loss = 4.50398
I0423 23:24:21.026440 21205 solver.cpp:258]     Train net output #0: accuracy = 0.328125
I0423 23:24:21.026453 21205 solver.cpp:258]     Train net output #1: softmax_loss = 4.50398 (* 1 = 4.50398 loss)
I0423 23:24:21.026463 21205 sgd_solver.cpp:112] Iteration 7600, lr = 0.1
I0423 23:24:52.793077 21205 solver.cpp:239] Iteration 7700 (3.14794 iter/s, 31.7668s/100 iters), loss = 4.95528
I0423 23:24:52.793164 21205 solver.cpp:258]     Train net output #0: accuracy = 0.265625
I0423 23:24:52.793175 21205 solver.cpp:258]     Train net output #1: softmax_loss = 4.95528 (* 1 = 4.95528 loss)
I0423 23:24:52.793185 21205 sgd_solver.cpp:112] Iteration 7700, lr = 0.1
I0423 23:25:24.569099 21205 solver.cpp:239] Iteration 7800 (3.14702 iter/s, 31.7761s/100 iters), loss = 4.54062
I0423 23:25:24.569169 21205 solver.cpp:258]     Train net output #0: accuracy = 0.28125
I0423 23:25:24.569180 21205 solver.cpp:258]     Train net output #1: softmax_loss = 4.54062 (* 1 = 4.54062 loss)
I0423 23:25:24.569190 21205 sgd_solver.cpp:112] Iteration 7800, lr = 0.1
I0423 23:25:56.334059 21205 solver.cpp:239] Iteration 7900 (3.14812 iter/s, 31.765s/100 iters), loss = 4.09348
I0423 23:25:56.334159 21205 solver.cpp:258]     Train net output #0: accuracy = 0.367188
I0423 23:25:56.334172 21205 solver.cpp:258]     Train net output #1: softmax_loss = 4.09348 (* 1 = 4.09348 loss)
I0423 23:25:56.334182 21205 sgd_solver.cpp:112] Iteration 7900, lr = 0.1
I0423 23:26:27.784065 21205 solver.cpp:468] Snapshotting to binary proto file result/model_iter_8000.caffemodel
I0423 23:26:27.823868 21205 sgd_solver.cpp:280] Snapshotting solver state to binary proto file result/model_iter_8000.solverstate
I0423 23:26:28.158521 21205 solver.cpp:239] Iteration 8000 (3.14224 iter/s, 31.8245s/100 iters), loss = 4.68119
I0423 23:26:28.158551 21205 solver.cpp:258]     Train net output #0: accuracy = 0.273438
I0423 23:26:28.158561 21205 solver.cpp:258]     Train net output #1: softmax_loss = 4.68119 (* 1 = 4.68119 loss)
I0423 23:26:28.158571 21205 sgd_solver.cpp:112] Iteration 8000, lr = 0.1
I0423 23:26:59.927664 21205 solver.cpp:239] Iteration 8100 (3.1477 iter/s, 31.7692s/100 iters), loss = 4.369
I0423 23:26:59.927743 21205 solver.cpp:258]     Train net output #0: accuracy = 0.304688
I0423 23:26:59.927755 21205 solver.cpp:258]     Train net output #1: softmax_loss = 4.369 (* 1 = 4.369 loss)
I0423 23:26:59.927765 21205 sgd_solver.cpp:112] Iteration 8100, lr = 0.1
I0423 23:27:31.692342 21205 solver.cpp:239] Iteration 8200 (3.14815 iter/s, 31.7647s/100 iters), loss = 5.11039
I0423 23:27:31.692410 21205 solver.cpp:258]     Train net output #0: accuracy = 0.226562
I0423 23:27:31.692423 21205 solver.cpp:258]     Train net output #1: softmax_loss = 5.11039 (* 1 = 5.11039 loss)
I0423 23:27:31.692433 21205 sgd_solver.cpp:112] Iteration 8200, lr = 0.1
I0423 23:27:47.283449 21209 data_layer.cpp:73] Restarting data prefetching from start.
I0423 23:28:03.458129 21205 solver.cpp:239] Iteration 8300 (3.14804 iter/s, 31.7658s/100 iters), loss = 4.61494
I0423 23:28:03.458220 21205 solver.cpp:258]     Train net output #0: accuracy = 0.289062
I0423 23:28:03.458231 21205 solver.cpp:258]     Train net output #1: softmax_loss = 4.61494 (* 1 = 4.61494 loss)
I0423 23:28:03.458241 21205 sgd_solver.cpp:112] Iteration 8300, lr = 0.1
I0423 23:28:35.226195 21205 solver.cpp:239] Iteration 8400 (3.14781 iter/s, 31.7681s/100 iters), loss = 4.2829
I0423 23:28:35.226294 21205 solver.cpp:258]     Train net output #0: accuracy = 0.335938
I0423 23:28:35.226307 21205 solver.cpp:258]     Train net output #1: softmax_loss = 4.2829 (* 1 = 4.2829 loss)
I0423 23:28:35.226317 21205 sgd_solver.cpp:112] Iteration 8400, lr = 0.1
I0423 23:29:06.994139 21205 solver.cpp:239] Iteration 8500 (3.14783 iter/s, 31.768s/100 iters), loss = 4.31352
I0423 23:29:06.994249 21205 solver.cpp:258]     Train net output #0: accuracy = 0.359375
I0423 23:29:06.994261 21205 solver.cpp:258]     Train net output #1: softmax_loss = 4.31352 (* 1 = 4.31352 loss)
I0423 23:29:06.994271 21205 sgd_solver.cpp:112] Iteration 8500, lr = 0.1
I0423 23:29:38.752233 21205 solver.cpp:239] Iteration 8600 (3.1488 iter/s, 31.7581s/100 iters), loss = 5.32954
I0423 23:29:38.752312 21205 solver.cpp:258]     Train net output #0: accuracy = 0.203125
I0423 23:29:38.752324 21205 solver.cpp:258]     Train net output #1: softmax_loss = 5.32954 (* 1 = 5.32954 loss)
I0423 23:29:38.752333 21205 sgd_solver.cpp:112] Iteration 8600, lr = 0.1
I0423 23:30:10.512472 21205 solver.cpp:239] Iteration 8700 (3.14859 iter/s, 31.7603s/100 iters), loss = 4.4883
I0423 23:30:10.512558 21205 solver.cpp:258]     Train net output #0: accuracy = 0.242188
I0423 23:30:10.512570 21205 solver.cpp:258]     Train net output #1: softmax_loss = 4.4883 (* 1 = 4.4883 loss)
I0423 23:30:10.512580 21205 sgd_solver.cpp:112] Iteration 8700, lr = 0.1
I0423 23:30:42.272646 21205 solver.cpp:239] Iteration 8800 (3.14859 iter/s, 31.7602s/100 iters), loss = 4.65918
I0423 23:30:42.272747 21205 solver.cpp:258]     Train net output #0: accuracy = 0.320312
I0423 23:30:42.272758 21205 solver.cpp:258]     Train net output #1: softmax_loss = 4.65918 (* 1 = 4.65918 loss)
I0423 23:30:42.272768 21205 sgd_solver.cpp:112] Iteration 8800, lr = 0.1
I0423 23:31:14.037940 21205 solver.cpp:239] Iteration 8900 (3.14809 iter/s, 31.7653s/100 iters), loss = 4.99733
I0423 23:31:14.038020 21205 solver.cpp:258]     Train net output #0: accuracy = 0.28125
I0423 23:31:14.038033 21205 solver.cpp:258]     Train net output #1: softmax_loss = 4.99733 (* 1 = 4.99733 loss)
I0423 23:31:14.038043 21205 sgd_solver.cpp:112] Iteration 8900, lr = 0.1
I0423 23:31:45.517344 21209 data_layer.cpp:73] Restarting data prefetching from start.
I0423 23:31:45.798666 21205 solver.cpp:239] Iteration 9000 (3.14854 iter/s, 31.7608s/100 iters), loss = 4.64608
I0423 23:31:45.798693 21205 solver.cpp:258]     Train net output #0: accuracy = 0.289062
I0423 23:31:45.798703 21205 solver.cpp:258]     Train net output #1: softmax_loss = 4.64608 (* 1 = 4.64608 loss)
I0423 23:31:45.798712 21205 sgd_solver.cpp:112] Iteration 9000, lr = 0.1
I0423 23:32:17.556286 21205 solver.cpp:239] Iteration 9100 (3.14884 iter/s, 31.7577s/100 iters), loss = 4.33991
I0423 23:32:17.556372 21205 solver.cpp:258]     Train net output #0: accuracy = 0.320312
I0423 23:32:17.556383 21205 solver.cpp:258]     Train net output #1: softmax_loss = 4.33991 (* 1 = 4.33991 loss)
I0423 23:32:17.556393 21205 sgd_solver.cpp:112] Iteration 9100, lr = 0.1
I0423 23:32:49.312352 21205 solver.cpp:239] Iteration 9200 (3.149 iter/s, 31.7561s/100 iters), loss = 4.51648
I0423 23:32:49.312409 21205 solver.cpp:258]     Train net output #0: accuracy = 0.304688
I0423 23:32:49.312419 21205 solver.cpp:258]     Train net output #1: softmax_loss = 4.51648 (* 1 = 4.51648 loss)
I0423 23:32:49.312429 21205 sgd_solver.cpp:112] Iteration 9200, lr = 0.1
I0423 23:33:21.070443 21205 solver.cpp:239] Iteration 9300 (3.1488 iter/s, 31.7581s/100 iters), loss = 4.31817
I0423 23:33:21.070528 21205 solver.cpp:258]     Train net output #0: accuracy = 0.28125
I0423 23:33:21.070539 21205 solver.cpp:258]     Train net output #1: softmax_loss = 4.31817 (* 1 = 4.31817 loss)
I0423 23:33:21.070549 21205 sgd_solver.cpp:112] Iteration 9300, lr = 0.1
I0423 23:33:52.833137 21205 solver.cpp:239] Iteration 9400 (3.14835 iter/s, 31.7627s/100 iters), loss = 4.60514
I0423 23:33:52.833258 21205 solver.cpp:258]     Train net output #0: accuracy = 0.320312
I0423 23:33:52.833271 21205 solver.cpp:258]     Train net output #1: softmax_loss = 4.60514 (* 1 = 4.60514 loss)
I0423 23:33:52.833281 21205 sgd_solver.cpp:112] Iteration 9400, lr = 0.1
I0423 23:34:24.589710 21205 solver.cpp:239] Iteration 9500 (3.14896 iter/s, 31.7566s/100 iters), loss = 4.19413
I0423 23:34:24.589807 21205 solver.cpp:258]     Train net output #0: accuracy = 0.328125
I0423 23:34:24.589818 21205 solver.cpp:258]     Train net output #1: softmax_loss = 4.19413 (* 1 = 4.19413 loss)
I0423 23:34:24.589828 21205 sgd_solver.cpp:112] Iteration 9500, lr = 0.1
I0423 23:34:56.347545 21205 solver.cpp:239] Iteration 9600 (3.14883 iter/s, 31.7578s/100 iters), loss = 4.2257
I0423 23:34:56.347646 21205 solver.cpp:258]     Train net output #0: accuracy = 0.304688
I0423 23:34:56.347658 21205 solver.cpp:258]     Train net output #1: softmax_loss = 4.2257 (* 1 = 4.2257 loss)
I0423 23:34:56.347667 21205 sgd_solver.cpp:112] Iteration 9600, lr = 0.1
I0423 23:35:28.110237 21205 solver.cpp:239] Iteration 9700 (3.14835 iter/s, 31.7627s/100 iters), loss = 4.68629
I0423 23:35:28.110306 21205 solver.cpp:258]     Train net output #0: accuracy = 0.304688
I0423 23:35:28.110317 21205 solver.cpp:258]     Train net output #1: softmax_loss = 4.68629 (* 1 = 4.68629 loss)
I0423 23:35:28.110327 21205 sgd_solver.cpp:112] Iteration 9700, lr = 0.1
I0423 23:35:44.010824 21209 data_layer.cpp:73] Restarting data prefetching from start.
I0423 23:35:59.871292 21205 solver.cpp:239] Iteration 9800 (3.14851 iter/s, 31.7611s/100 iters), loss = 4.75697
I0423 23:35:59.871369 21205 solver.cpp:258]     Train net output #0: accuracy = 0.3125
I0423 23:35:59.871381 21205 solver.cpp:258]     Train net output #1: softmax_loss = 4.75697 (* 1 = 4.75697 loss)
I0423 23:35:59.871392 21205 sgd_solver.cpp:112] Iteration 9800, lr = 0.1
I0423 23:36:31.630906 21205 solver.cpp:239] Iteration 9900 (3.14865 iter/s, 31.7596s/100 iters), loss = 4.66059
I0423 23:36:31.630965 21205 solver.cpp:258]     Train net output #0: accuracy = 0.34375
I0423 23:36:31.630976 21205 solver.cpp:258]     Train net output #1: softmax_loss = 4.66059 (* 1 = 4.66059 loss)
I0423 23:36:31.630986 21205 sgd_solver.cpp:112] Iteration 9900, lr = 0.1
I0423 23:37:03.389865 21205 solver.cpp:239] Iteration 10000 (3.14872 iter/s, 31.7589s/100 iters), loss = 4.89516
I0423 23:37:03.389952 21205 solver.cpp:258]     Train net output #0: accuracy = 0.328125
I0423 23:37:03.389963 21205 solver.cpp:258]     Train net output #1: softmax_loss = 4.89516 (* 1 = 4.89516 loss)
I0423 23:37:03.389973 21205 sgd_solver.cpp:112] Iteration 10000, lr = 0.1
I0423 23:37:35.156265 21205 solver.cpp:239] Iteration 10100 (3.148 iter/s, 31.7662s/100 iters), loss = 4.74295
I0423 23:37:35.156322 21205 solver.cpp:258]     Train net output #0: accuracy = 0.335938
I0423 23:37:35.156332 21205 solver.cpp:258]     Train net output #1: softmax_loss = 4.74295 (* 1 = 4.74295 loss)
I0423 23:37:35.156342 21205 sgd_solver.cpp:112] Iteration 10100, lr = 0.1
I0423 23:38:06.927477 21205 solver.cpp:239] Iteration 10200 (3.14752 iter/s, 31.7711s/100 iters), loss = 4.46821
I0423 23:38:06.927556 21205 solver.cpp:258]     Train net output #0: accuracy = 0.328125
I0423 23:38:06.927567 21205 solver.cpp:258]     Train net output #1: softmax_loss = 4.46821 (* 1 = 4.46821 loss)
I0423 23:38:06.927577 21205 sgd_solver.cpp:112] Iteration 10200, lr = 0.1
I0423 23:38:38.690800 21205 solver.cpp:239] Iteration 10300 (3.1483 iter/s, 31.7632s/100 iters), loss = 4.45151
I0423 23:38:38.690901 21205 solver.cpp:258]     Train net output #0: accuracy = 0.3125
I0423 23:38:38.690912 21205 solver.cpp:258]     Train net output #1: softmax_loss = 4.45151 (* 1 = 4.45151 loss)
I0423 23:38:38.690923 21205 sgd_solver.cpp:112] Iteration 10300, lr = 0.1
I0423 23:39:10.452818 21205 solver.cpp:239] Iteration 10400 (3.14843 iter/s, 31.7618s/100 iters), loss = 3.9135
I0423 23:39:10.452903 21205 solver.cpp:258]     Train net output #0: accuracy = 0.382812
I0423 23:39:10.452914 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.9135 (* 1 = 3.9135 loss)
I0423 23:39:10.452925 21205 sgd_solver.cpp:112] Iteration 10400, lr = 0.1
I0423 23:39:42.217499 21205 solver.cpp:239] Iteration 10500 (3.14817 iter/s, 31.7645s/100 iters), loss = 3.98437
I0423 23:39:42.217587 21205 solver.cpp:258]     Train net output #0: accuracy = 0.328125
I0423 23:39:42.217599 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.98437 (* 1 = 3.98437 loss)
I0423 23:39:42.217610 21205 sgd_solver.cpp:112] Iteration 10500, lr = 0.1
I0423 23:39:42.245817 21209 data_layer.cpp:73] Restarting data prefetching from start.
I0423 23:40:13.985961 21205 solver.cpp:239] Iteration 10600 (3.14779 iter/s, 31.7683s/100 iters), loss = 4.20256
I0423 23:40:13.986069 21205 solver.cpp:258]     Train net output #0: accuracy = 0.382812
I0423 23:40:13.986083 21205 solver.cpp:258]     Train net output #1: softmax_loss = 4.20256 (* 1 = 4.20256 loss)
I0423 23:40:13.986093 21205 sgd_solver.cpp:112] Iteration 10600, lr = 0.1
I0423 23:40:45.755412 21205 solver.cpp:239] Iteration 10700 (3.14769 iter/s, 31.7693s/100 iters), loss = 3.89765
I0423 23:40:45.755492 21205 solver.cpp:258]     Train net output #0: accuracy = 0.375
I0423 23:40:45.755504 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.89765 (* 1 = 3.89765 loss)
I0423 23:40:45.755513 21205 sgd_solver.cpp:112] Iteration 10700, lr = 0.1
I0423 23:41:17.515439 21205 solver.cpp:239] Iteration 10800 (3.14862 iter/s, 31.7599s/100 iters), loss = 4.52573
I0423 23:41:17.515522 21205 solver.cpp:258]     Train net output #0: accuracy = 0.3125
I0423 23:41:17.515535 21205 solver.cpp:258]     Train net output #1: softmax_loss = 4.52573 (* 1 = 4.52573 loss)
I0423 23:41:17.515544 21205 sgd_solver.cpp:112] Iteration 10800, lr = 0.1
I0423 23:41:49.282300 21205 solver.cpp:239] Iteration 10900 (3.14795 iter/s, 31.7667s/100 iters), loss = 4.49158
I0423 23:41:49.282371 21205 solver.cpp:258]     Train net output #0: accuracy = 0.289062
I0423 23:41:49.282382 21205 solver.cpp:258]     Train net output #1: softmax_loss = 4.49158 (* 1 = 4.49158 loss)
I0423 23:41:49.282392 21205 sgd_solver.cpp:112] Iteration 10900, lr = 0.1
I0423 23:42:21.043413 21205 solver.cpp:239] Iteration 11000 (3.14851 iter/s, 31.761s/100 iters), loss = 4.00164
I0423 23:42:21.043493 21205 solver.cpp:258]     Train net output #0: accuracy = 0.320312
I0423 23:42:21.043504 21205 solver.cpp:258]     Train net output #1: softmax_loss = 4.00164 (* 1 = 4.00164 loss)
I0423 23:42:21.043514 21205 sgd_solver.cpp:112] Iteration 11000, lr = 0.1
I0423 23:42:52.816817 21205 solver.cpp:239] Iteration 11100 (3.1473 iter/s, 31.7733s/100 iters), loss = 4.44298
I0423 23:42:52.816918 21205 solver.cpp:258]     Train net output #0: accuracy = 0.351562
I0423 23:42:52.816929 21205 solver.cpp:258]     Train net output #1: softmax_loss = 4.44298 (* 1 = 4.44298 loss)
I0423 23:42:52.816939 21205 sgd_solver.cpp:112] Iteration 11100, lr = 0.1
I0423 23:43:24.583041 21205 solver.cpp:239] Iteration 11200 (3.14801 iter/s, 31.7661s/100 iters), loss = 4.22554
I0423 23:43:24.583097 21205 solver.cpp:258]     Train net output #0: accuracy = 0.320312
I0423 23:43:24.583108 21205 solver.cpp:258]     Train net output #1: softmax_loss = 4.22554 (* 1 = 4.22554 loss)
I0423 23:43:24.583118 21205 sgd_solver.cpp:112] Iteration 11200, lr = 0.1
I0423 23:43:40.506520 21209 data_layer.cpp:73] Restarting data prefetching from start.
I0423 23:43:56.355785 21205 solver.cpp:239] Iteration 11300 (3.14736 iter/s, 31.7727s/100 iters), loss = 4.56219
I0423 23:43:56.355864 21205 solver.cpp:258]     Train net output #0: accuracy = 0.359375
I0423 23:43:56.355875 21205 solver.cpp:258]     Train net output #1: softmax_loss = 4.56219 (* 1 = 4.56219 loss)
I0423 23:43:56.355885 21205 sgd_solver.cpp:112] Iteration 11300, lr = 0.1
I0423 23:44:28.119472 21205 solver.cpp:239] Iteration 11400 (3.14826 iter/s, 31.7636s/100 iters), loss = 3.79046
I0423 23:44:28.119540 21205 solver.cpp:258]     Train net output #0: accuracy = 0.414062
I0423 23:44:28.119551 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.79046 (* 1 = 3.79046 loss)
I0423 23:44:28.119560 21205 sgd_solver.cpp:112] Iteration 11400, lr = 0.1
I0423 23:44:59.890578 21205 solver.cpp:239] Iteration 11500 (3.14752 iter/s, 31.771s/100 iters), loss = 3.83924
I0423 23:44:59.890684 21205 solver.cpp:258]     Train net output #0: accuracy = 0.367188
I0423 23:44:59.890697 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.83924 (* 1 = 3.83924 loss)
I0423 23:44:59.890707 21205 sgd_solver.cpp:112] Iteration 11500, lr = 0.1
I0423 23:45:31.659260 21205 solver.cpp:239] Iteration 11600 (3.14776 iter/s, 31.7686s/100 iters), loss = 4.57467
I0423 23:45:31.659343 21205 solver.cpp:258]     Train net output #0: accuracy = 0.304688
I0423 23:45:31.659353 21205 solver.cpp:258]     Train net output #1: softmax_loss = 4.57467 (* 1 = 4.57467 loss)
I0423 23:45:31.659363 21205 sgd_solver.cpp:112] Iteration 11600, lr = 0.1
I0423 23:46:03.431536 21205 solver.cpp:239] Iteration 11700 (3.1474 iter/s, 31.7722s/100 iters), loss = 3.82567
I0423 23:46:03.431623 21205 solver.cpp:258]     Train net output #0: accuracy = 0.40625
I0423 23:46:03.431634 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.82567 (* 1 = 3.82567 loss)
I0423 23:46:03.431644 21205 sgd_solver.cpp:112] Iteration 11700, lr = 0.1
I0423 23:46:35.199201 21205 solver.cpp:239] Iteration 11800 (3.14786 iter/s, 31.7676s/100 iters), loss = 4.52189
I0423 23:46:35.199260 21205 solver.cpp:258]     Train net output #0: accuracy = 0.351562
I0423 23:46:35.199271 21205 solver.cpp:258]     Train net output #1: softmax_loss = 4.52189 (* 1 = 4.52189 loss)
I0423 23:46:35.199280 21205 sgd_solver.cpp:112] Iteration 11800, lr = 0.1
I0423 23:47:06.968401 21205 solver.cpp:239] Iteration 11900 (3.14771 iter/s, 31.7692s/100 iters), loss = 4.18345
I0423 23:47:06.968508 21205 solver.cpp:258]     Train net output #0: accuracy = 0.34375
I0423 23:47:06.968518 21205 solver.cpp:258]     Train net output #1: softmax_loss = 4.18345 (* 1 = 4.18345 loss)
I0423 23:47:06.968528 21205 sgd_solver.cpp:112] Iteration 11900, lr = 0.1
I0423 23:47:38.426234 21205 solver.cpp:468] Snapshotting to binary proto file result/model_iter_12000.caffemodel
I0423 23:47:38.465678 21205 sgd_solver.cpp:280] Snapshotting solver state to binary proto file result/model_iter_12000.solverstate
I0423 23:47:38.799618 21205 solver.cpp:239] Iteration 12000 (3.14158 iter/s, 31.8311s/100 iters), loss = 4.49962
I0423 23:47:38.799645 21205 solver.cpp:258]     Train net output #0: accuracy = 0.3125
I0423 23:47:38.799654 21205 solver.cpp:258]     Train net output #1: softmax_loss = 4.49962 (* 1 = 4.49962 loss)
I0423 23:47:38.799664 21205 sgd_solver.cpp:112] Iteration 12000, lr = 0.1
I0423 23:47:39.137099 21209 data_layer.cpp:73] Restarting data prefetching from start.
I0423 23:48:10.573859 21205 solver.cpp:239] Iteration 12100 (3.1472 iter/s, 31.7742s/100 iters), loss = 4.0916
I0423 23:48:10.573942 21205 solver.cpp:258]     Train net output #0: accuracy = 0.359375
I0423 23:48:10.573954 21205 solver.cpp:258]     Train net output #1: softmax_loss = 4.0916 (* 1 = 4.0916 loss)
I0423 23:48:10.573963 21205 sgd_solver.cpp:112] Iteration 12100, lr = 0.1
I0423 23:48:42.343644 21205 solver.cpp:239] Iteration 12200 (3.14765 iter/s, 31.7697s/100 iters), loss = 4.27708
I0423 23:48:42.343699 21205 solver.cpp:258]     Train net output #0: accuracy = 0.359375
I0423 23:48:42.343710 21205 solver.cpp:258]     Train net output #1: softmax_loss = 4.27708 (* 1 = 4.27708 loss)
I0423 23:48:42.343719 21205 sgd_solver.cpp:112] Iteration 12200, lr = 0.1
I0423 23:49:14.110851 21205 solver.cpp:239] Iteration 12300 (3.1479 iter/s, 31.7672s/100 iters), loss = 3.89455
I0423 23:49:14.110931 21205 solver.cpp:258]     Train net output #0: accuracy = 0.40625
I0423 23:49:14.110944 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.89455 (* 1 = 3.89455 loss)
I0423 23:49:14.110954 21205 sgd_solver.cpp:112] Iteration 12300, lr = 0.1
I0423 23:49:45.881976 21205 solver.cpp:239] Iteration 12400 (3.14752 iter/s, 31.7711s/100 iters), loss = 3.97889
I0423 23:49:45.882061 21205 solver.cpp:258]     Train net output #0: accuracy = 0.390625
I0423 23:49:45.882072 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.97889 (* 1 = 3.97889 loss)
I0423 23:49:45.882082 21205 sgd_solver.cpp:112] Iteration 12400, lr = 0.1
I0423 23:50:17.655565 21205 solver.cpp:239] Iteration 12500 (3.14727 iter/s, 31.7735s/100 iters), loss = 3.8671
I0423 23:50:17.655673 21205 solver.cpp:258]     Train net output #0: accuracy = 0.367188
I0423 23:50:17.655684 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.8671 (* 1 = 3.8671 loss)
I0423 23:50:17.655694 21205 sgd_solver.cpp:112] Iteration 12500, lr = 0.1
I0423 23:50:49.426400 21205 solver.cpp:239] Iteration 12600 (3.14755 iter/s, 31.7708s/100 iters), loss = 4.33434
I0423 23:50:49.426476 21205 solver.cpp:258]     Train net output #0: accuracy = 0.359375
I0423 23:50:49.426488 21205 solver.cpp:258]     Train net output #1: softmax_loss = 4.33434 (* 1 = 4.33434 loss)
I0423 23:50:49.426498 21205 sgd_solver.cpp:112] Iteration 12600, lr = 0.1
I0423 23:51:21.202220 21205 solver.cpp:239] Iteration 12700 (3.14705 iter/s, 31.7758s/100 iters), loss = 3.84401
I0423 23:51:21.202317 21205 solver.cpp:258]     Train net output #0: accuracy = 0.40625
I0423 23:51:21.202329 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.84401 (* 1 = 3.84401 loss)
I0423 23:51:21.202339 21205 sgd_solver.cpp:112] Iteration 12700, lr = 0.1
I0423 23:51:37.435367 21209 data_layer.cpp:73] Restarting data prefetching from start.
I0423 23:51:52.979573 21205 solver.cpp:239] Iteration 12800 (3.1469 iter/s, 31.7773s/100 iters), loss = 4.05944
I0423 23:51:52.979655 21205 solver.cpp:258]     Train net output #0: accuracy = 0.3125
I0423 23:51:52.979666 21205 solver.cpp:258]     Train net output #1: softmax_loss = 4.05944 (* 1 = 4.05944 loss)
I0423 23:51:52.979676 21205 sgd_solver.cpp:112] Iteration 12800, lr = 0.1
I0423 23:52:24.750823 21205 solver.cpp:239] Iteration 12900 (3.1475 iter/s, 31.7712s/100 iters), loss = 3.75122
I0423 23:52:24.750882 21205 solver.cpp:258]     Train net output #0: accuracy = 0.351562
I0423 23:52:24.750893 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.75122 (* 1 = 3.75122 loss)
I0423 23:52:24.750902 21205 sgd_solver.cpp:112] Iteration 12900, lr = 0.1
I0423 23:52:56.524128 21205 solver.cpp:239] Iteration 13000 (3.1473 iter/s, 31.7733s/100 iters), loss = 4.02619
I0423 23:52:56.524210 21205 solver.cpp:258]     Train net output #0: accuracy = 0.359375
I0423 23:52:56.524222 21205 solver.cpp:258]     Train net output #1: softmax_loss = 4.02619 (* 1 = 4.02619 loss)
I0423 23:52:56.524232 21205 sgd_solver.cpp:112] Iteration 13000, lr = 0.1
I0423 23:53:28.295814 21205 solver.cpp:239] Iteration 13100 (3.14746 iter/s, 31.7717s/100 iters), loss = 3.68751
I0423 23:53:28.295881 21205 solver.cpp:258]     Train net output #0: accuracy = 0.421875
I0423 23:53:28.295892 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.68751 (* 1 = 3.68751 loss)
I0423 23:53:28.295902 21205 sgd_solver.cpp:112] Iteration 13100, lr = 0.1
I0423 23:54:00.067466 21205 solver.cpp:239] Iteration 13200 (3.14746 iter/s, 31.7716s/100 iters), loss = 4.38554
I0423 23:54:00.067544 21205 solver.cpp:258]     Train net output #0: accuracy = 0.320312
I0423 23:54:00.067555 21205 solver.cpp:258]     Train net output #1: softmax_loss = 4.38554 (* 1 = 4.38554 loss)
I0423 23:54:00.067565 21205 sgd_solver.cpp:112] Iteration 13200, lr = 0.1
I0423 23:54:31.841203 21205 solver.cpp:239] Iteration 13300 (3.14726 iter/s, 31.7737s/100 iters), loss = 4.21457
I0423 23:54:31.841267 21205 solver.cpp:258]     Train net output #0: accuracy = 0.289062
I0423 23:54:31.841279 21205 solver.cpp:258]     Train net output #1: softmax_loss = 4.21457 (* 1 = 4.21457 loss)
I0423 23:54:31.841287 21205 sgd_solver.cpp:112] Iteration 13300, lr = 0.1
I0423 23:55:03.614521 21205 solver.cpp:239] Iteration 13400 (3.1473 iter/s, 31.7733s/100 iters), loss = 4.01222
I0423 23:55:03.614600 21205 solver.cpp:258]     Train net output #0: accuracy = 0.40625
I0423 23:55:03.614611 21205 solver.cpp:258]     Train net output #1: softmax_loss = 4.01222 (* 1 = 4.01222 loss)
I0423 23:55:03.614621 21205 sgd_solver.cpp:112] Iteration 13400, lr = 0.1
I0423 23:55:35.386765 21205 solver.cpp:239] Iteration 13500 (3.1474 iter/s, 31.7722s/100 iters), loss = 3.81745
I0423 23:55:35.386860 21205 solver.cpp:258]     Train net output #0: accuracy = 0.414062
I0423 23:55:35.386873 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.81745 (* 1 = 3.81745 loss)
I0423 23:55:35.386883 21205 sgd_solver.cpp:112] Iteration 13500, lr = 0.1
I0423 23:55:35.739845 21209 data_layer.cpp:73] Restarting data prefetching from start.
I0423 23:56:07.155158 21205 solver.cpp:239] Iteration 13600 (3.14779 iter/s, 31.7684s/100 iters), loss = 3.63429
I0423 23:56:07.155262 21205 solver.cpp:258]     Train net output #0: accuracy = 0.398438
I0423 23:56:07.155273 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.63429 (* 1 = 3.63429 loss)
I0423 23:56:07.155283 21205 sgd_solver.cpp:112] Iteration 13600, lr = 0.1
I0423 23:56:38.926540 21205 solver.cpp:239] Iteration 13700 (3.14749 iter/s, 31.7713s/100 iters), loss = 4.11849
I0423 23:56:38.926594 21205 solver.cpp:258]     Train net output #0: accuracy = 0.390625
I0423 23:56:38.926604 21205 solver.cpp:258]     Train net output #1: softmax_loss = 4.11849 (* 1 = 4.11849 loss)
I0423 23:56:38.926614 21205 sgd_solver.cpp:112] Iteration 13700, lr = 0.1
I0423 23:57:10.696249 21205 solver.cpp:239] Iteration 13800 (3.14765 iter/s, 31.7697s/100 iters), loss = 3.85953
I0423 23:57:10.696327 21205 solver.cpp:258]     Train net output #0: accuracy = 0.398438
I0423 23:57:10.696338 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.85953 (* 1 = 3.85953 loss)
I0423 23:57:10.696348 21205 sgd_solver.cpp:112] Iteration 13800, lr = 0.1
I0423 23:57:42.470316 21205 solver.cpp:239] Iteration 13900 (3.14722 iter/s, 31.774s/100 iters), loss = 4.01844
I0423 23:57:42.470384 21205 solver.cpp:258]     Train net output #0: accuracy = 0.328125
I0423 23:57:42.470396 21205 solver.cpp:258]     Train net output #1: softmax_loss = 4.01844 (* 1 = 4.01844 loss)
I0423 23:57:42.470405 21205 sgd_solver.cpp:112] Iteration 13900, lr = 0.1
I0423 23:58:14.243481 21205 solver.cpp:239] Iteration 14000 (3.14731 iter/s, 31.7732s/100 iters), loss = 3.37595
I0423 23:58:14.243563 21205 solver.cpp:258]     Train net output #0: accuracy = 0.453125
I0423 23:58:14.243574 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.37595 (* 1 = 3.37595 loss)
I0423 23:58:14.243584 21205 sgd_solver.cpp:112] Iteration 14000, lr = 0.1
I0423 23:58:46.012714 21205 solver.cpp:239] Iteration 14100 (3.1477 iter/s, 31.7692s/100 iters), loss = 4.48093
I0423 23:58:46.012771 21205 solver.cpp:258]     Train net output #0: accuracy = 0.34375
I0423 23:58:46.012781 21205 solver.cpp:258]     Train net output #1: softmax_loss = 4.48093 (* 1 = 4.48093 loss)
I0423 23:58:46.012790 21205 sgd_solver.cpp:112] Iteration 14100, lr = 0.1
I0423 23:59:17.782742 21205 solver.cpp:239] Iteration 14200 (3.14762 iter/s, 31.77s/100 iters), loss = 3.54508
I0423 23:59:17.782819 21205 solver.cpp:258]     Train net output #0: accuracy = 0.445312
I0423 23:59:17.782830 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.54508 (* 1 = 3.54508 loss)
I0423 23:59:17.782840 21205 sgd_solver.cpp:112] Iteration 14200, lr = 0.1
I0423 23:59:34.324683 21209 data_layer.cpp:73] Restarting data prefetching from start.
I0423 23:59:49.554960 21205 solver.cpp:239] Iteration 14300 (3.14741 iter/s, 31.7722s/100 iters), loss = 3.93938
I0423 23:59:49.555052 21205 solver.cpp:258]     Train net output #0: accuracy = 0.390625
I0423 23:59:49.555063 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.93938 (* 1 = 3.93938 loss)
I0423 23:59:49.555074 21205 sgd_solver.cpp:112] Iteration 14300, lr = 0.1
I0424 00:00:21.325237 21205 solver.cpp:239] Iteration 14400 (3.1476 iter/s, 31.7702s/100 iters), loss = 4.00608
I0424 00:00:21.325309 21205 solver.cpp:258]     Train net output #0: accuracy = 0.382812
I0424 00:00:21.325320 21205 solver.cpp:258]     Train net output #1: softmax_loss = 4.00608 (* 1 = 4.00608 loss)
I0424 00:00:21.325331 21205 sgd_solver.cpp:112] Iteration 14400, lr = 0.1
I0424 00:00:53.101397 21205 solver.cpp:239] Iteration 14500 (3.14701 iter/s, 31.7761s/100 iters), loss = 3.84635
I0424 00:00:53.101496 21205 solver.cpp:258]     Train net output #0: accuracy = 0.382812
I0424 00:00:53.101508 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.84635 (* 1 = 3.84635 loss)
I0424 00:00:53.101519 21205 sgd_solver.cpp:112] Iteration 14500, lr = 0.1
I0424 00:01:24.876694 21205 solver.cpp:239] Iteration 14600 (3.1471 iter/s, 31.7753s/100 iters), loss = 3.56872
I0424 00:01:24.876770 21205 solver.cpp:258]     Train net output #0: accuracy = 0.429688
I0424 00:01:24.876781 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.56872 (* 1 = 3.56872 loss)
I0424 00:01:24.876791 21205 sgd_solver.cpp:112] Iteration 14600, lr = 0.1
I0424 00:01:56.649247 21205 solver.cpp:239] Iteration 14700 (3.14737 iter/s, 31.7725s/100 iters), loss = 3.97
I0424 00:01:56.649335 21205 solver.cpp:258]     Train net output #0: accuracy = 0.40625
I0424 00:01:56.649346 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.97 (* 1 = 3.97 loss)
I0424 00:01:56.649356 21205 sgd_solver.cpp:112] Iteration 14700, lr = 0.1
I0424 00:02:28.421445 21205 solver.cpp:239] Iteration 14800 (3.14741 iter/s, 31.7722s/100 iters), loss = 3.59835
I0424 00:02:28.421515 21205 solver.cpp:258]     Train net output #0: accuracy = 0.414062
I0424 00:02:28.421526 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.59835 (* 1 = 3.59835 loss)
I0424 00:02:28.421537 21205 sgd_solver.cpp:112] Iteration 14800, lr = 0.1
I0424 00:03:00.192250 21205 solver.cpp:239] Iteration 14900 (3.14754 iter/s, 31.7708s/100 iters), loss = 4.38393
I0424 00:03:00.192327 21205 solver.cpp:258]     Train net output #0: accuracy = 0.320312
I0424 00:03:00.192337 21205 solver.cpp:258]     Train net output #1: softmax_loss = 4.38393 (* 1 = 4.38393 loss)
I0424 00:03:00.192348 21205 sgd_solver.cpp:112] Iteration 14900, lr = 0.1
I0424 00:03:31.961959 21205 solver.cpp:239] Iteration 15000 (3.14765 iter/s, 31.7697s/100 iters), loss = 3.75107
I0424 00:03:31.962028 21205 solver.cpp:258]     Train net output #0: accuracy = 0.421875
I0424 00:03:31.962038 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.75107 (* 1 = 3.75107 loss)
I0424 00:03:31.962049 21205 sgd_solver.cpp:112] Iteration 15000, lr = 0.1
I0424 00:03:32.624809 21209 data_layer.cpp:73] Restarting data prefetching from start.
I0424 00:04:03.735026 21205 solver.cpp:239] Iteration 15100 (3.14732 iter/s, 31.7731s/100 iters), loss = 4.01127
I0424 00:04:03.735097 21205 solver.cpp:258]     Train net output #0: accuracy = 0.304688
I0424 00:04:03.735110 21205 solver.cpp:258]     Train net output #1: softmax_loss = 4.01127 (* 1 = 4.01127 loss)
I0424 00:04:03.735119 21205 sgd_solver.cpp:112] Iteration 15100, lr = 0.1
I0424 00:04:35.506932 21205 solver.cpp:239] Iteration 15200 (3.14744 iter/s, 31.7719s/100 iters), loss = 3.33153
I0424 00:04:35.507027 21205 solver.cpp:258]     Train net output #0: accuracy = 0.46875
I0424 00:04:35.507040 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.33153 (* 1 = 3.33153 loss)
I0424 00:04:35.507048 21205 sgd_solver.cpp:112] Iteration 15200, lr = 0.1
I0424 00:05:07.277458 21205 solver.cpp:239] Iteration 15300 (3.14757 iter/s, 31.7705s/100 iters), loss = 3.57505
I0424 00:05:07.277542 21205 solver.cpp:258]     Train net output #0: accuracy = 0.414062
I0424 00:05:07.277554 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.57505 (* 1 = 3.57505 loss)
I0424 00:05:07.277564 21205 sgd_solver.cpp:112] Iteration 15300, lr = 0.1
I0424 00:05:39.053946 21205 solver.cpp:239] Iteration 15400 (3.14698 iter/s, 31.7765s/100 iters), loss = 3.56064
I0424 00:05:39.054011 21205 solver.cpp:258]     Train net output #0: accuracy = 0.375
I0424 00:05:39.054023 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.56064 (* 1 = 3.56064 loss)
I0424 00:05:39.054033 21205 sgd_solver.cpp:112] Iteration 15400, lr = 0.1
I0424 00:06:10.825824 21205 solver.cpp:239] Iteration 15500 (3.14744 iter/s, 31.7719s/100 iters), loss = 4.07998
I0424 00:06:10.825920 21205 solver.cpp:258]     Train net output #0: accuracy = 0.351562
I0424 00:06:10.825933 21205 solver.cpp:258]     Train net output #1: softmax_loss = 4.07998 (* 1 = 4.07998 loss)
I0424 00:06:10.825943 21205 sgd_solver.cpp:112] Iteration 15500, lr = 0.1
I0424 00:06:42.594609 21205 solver.cpp:239] Iteration 15600 (3.14775 iter/s, 31.7687s/100 iters), loss = 3.78284
I0424 00:06:42.594703 21205 solver.cpp:258]     Train net output #0: accuracy = 0.40625
I0424 00:06:42.594715 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.78284 (* 1 = 3.78284 loss)
I0424 00:06:42.594725 21205 sgd_solver.cpp:112] Iteration 15600, lr = 0.1
I0424 00:07:14.369786 21205 solver.cpp:239] Iteration 15700 (3.14711 iter/s, 31.7751s/100 iters), loss = 3.90186
I0424 00:07:14.369868 21205 solver.cpp:258]     Train net output #0: accuracy = 0.359375
I0424 00:07:14.369879 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.90186 (* 1 = 3.90186 loss)
I0424 00:07:14.369889 21205 sgd_solver.cpp:112] Iteration 15700, lr = 0.1
I0424 00:07:30.927901 21209 data_layer.cpp:73] Restarting data prefetching from start.
I0424 00:07:46.144968 21205 solver.cpp:239] Iteration 15800 (3.14711 iter/s, 31.7752s/100 iters), loss = 3.85297
I0424 00:07:46.145036 21205 solver.cpp:258]     Train net output #0: accuracy = 0.390625
I0424 00:07:46.145047 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.85297 (* 1 = 3.85297 loss)
I0424 00:07:46.145057 21205 sgd_solver.cpp:112] Iteration 15800, lr = 0.1
I0424 00:08:17.918831 21205 solver.cpp:239] Iteration 15900 (3.14724 iter/s, 31.7739s/100 iters), loss = 4.42861
I0424 00:08:17.918910 21205 solver.cpp:258]     Train net output #0: accuracy = 0.34375
I0424 00:08:17.918921 21205 solver.cpp:258]     Train net output #1: softmax_loss = 4.42861 (* 1 = 4.42861 loss)
I0424 00:08:17.918931 21205 sgd_solver.cpp:112] Iteration 15900, lr = 0.1
I0424 00:08:49.375602 21205 solver.cpp:468] Snapshotting to binary proto file result/model_iter_16000.caffemodel
I0424 00:08:49.415004 21205 sgd_solver.cpp:280] Snapshotting solver state to binary proto file result/model_iter_16000.solverstate
I0424 00:08:49.750237 21205 solver.cpp:239] Iteration 16000 (3.14155 iter/s, 31.8314s/100 iters), loss = 4.04385
I0424 00:08:49.750264 21205 solver.cpp:258]     Train net output #0: accuracy = 0.367188
I0424 00:08:49.750273 21205 solver.cpp:258]     Train net output #1: softmax_loss = 4.04385 (* 1 = 4.04385 loss)
I0424 00:08:49.750275 21210 sgd_solver.cpp:50] MultiStep Status: Iteration 16000, step = 1
I0424 00:08:49.750275 21212 sgd_solver.cpp:50] MultiStep Status: Iteration 16000, step = 1
I0424 00:08:49.750275 21211 sgd_solver.cpp:50] MultiStep Status: Iteration 16000, step = 1
I0424 00:08:49.750283 21205 sgd_solver.cpp:50] MultiStep Status: Iteration 16000, step = 1
I0424 00:08:49.750308 21205 sgd_solver.cpp:112] Iteration 16000, lr = 0.01
I0424 00:09:21.522153 21205 solver.cpp:239] Iteration 16100 (3.14743 iter/s, 31.7719s/100 iters), loss = 3.30077
I0424 00:09:21.522238 21205 solver.cpp:258]     Train net output #0: accuracy = 0.4375
I0424 00:09:21.522248 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.30077 (* 1 = 3.30077 loss)
I0424 00:09:21.522259 21205 sgd_solver.cpp:112] Iteration 16100, lr = 0.01
I0424 00:09:53.296452 21205 solver.cpp:239] Iteration 16200 (3.1472 iter/s, 31.7743s/100 iters), loss = 3.71359
I0424 00:09:53.296528 21205 solver.cpp:258]     Train net output #0: accuracy = 0.421875
I0424 00:09:53.296540 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.71359 (* 1 = 3.71359 loss)
I0424 00:09:53.296550 21205 sgd_solver.cpp:112] Iteration 16200, lr = 0.01
I0424 00:10:25.076124 21205 solver.cpp:239] Iteration 16300 (3.14667 iter/s, 31.7797s/100 iters), loss = 3.41615
I0424 00:10:25.076181 21205 solver.cpp:258]     Train net output #0: accuracy = 0.445312
I0424 00:10:25.076191 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.41615 (* 1 = 3.41615 loss)
I0424 00:10:25.076201 21205 sgd_solver.cpp:112] Iteration 16300, lr = 0.01
I0424 00:10:56.852996 21205 solver.cpp:239] Iteration 16400 (3.14694 iter/s, 31.7769s/100 iters), loss = 3.73562
I0424 00:10:56.853106 21205 solver.cpp:258]     Train net output #0: accuracy = 0.445312
I0424 00:10:56.853118 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.73562 (* 1 = 3.73562 loss)
I0424 00:10:56.853129 21205 sgd_solver.cpp:112] Iteration 16400, lr = 0.01
I0424 00:11:28.635282 21205 solver.cpp:239] Iteration 16500 (3.14636 iter/s, 31.7828s/100 iters), loss = 2.73524
I0424 00:11:28.635375 21205 solver.cpp:258]     Train net output #0: accuracy = 0.539062
I0424 00:11:28.635386 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.73524 (* 1 = 2.73524 loss)
I0424 00:11:28.635397 21205 sgd_solver.cpp:112] Iteration 16500, lr = 0.01
I0424 00:11:29.608425 21209 data_layer.cpp:73] Restarting data prefetching from start.
I0424 00:12:00.422619 21205 solver.cpp:239] Iteration 16600 (3.14586 iter/s, 31.7879s/100 iters), loss = 2.61857
I0424 00:12:00.422701 21205 solver.cpp:258]     Train net output #0: accuracy = 0.554688
I0424 00:12:00.422713 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.61857 (* 1 = 2.61857 loss)
I0424 00:12:00.422724 21205 sgd_solver.cpp:112] Iteration 16600, lr = 0.01
I0424 00:12:32.206182 21205 solver.cpp:239] Iteration 16700 (3.14623 iter/s, 31.7841s/100 iters), loss = 3.04677
I0424 00:12:32.206249 21205 solver.cpp:258]     Train net output #0: accuracy = 0.539062
I0424 00:12:32.206261 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.04677 (* 1 = 3.04677 loss)
I0424 00:12:32.206270 21205 sgd_solver.cpp:112] Iteration 16700, lr = 0.01
I0424 00:13:03.991153 21205 solver.cpp:239] Iteration 16800 (3.14609 iter/s, 31.7855s/100 iters), loss = 3.35526
I0424 00:13:03.991247 21205 solver.cpp:258]     Train net output #0: accuracy = 0.5
I0424 00:13:03.991259 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.35526 (* 1 = 3.35526 loss)
I0424 00:13:03.991268 21205 sgd_solver.cpp:112] Iteration 16800, lr = 0.01
I0424 00:13:35.775060 21205 solver.cpp:239] Iteration 16900 (3.1462 iter/s, 31.7843s/100 iters), loss = 3.64251
I0424 00:13:35.775118 21205 solver.cpp:258]     Train net output #0: accuracy = 0.4375
I0424 00:13:35.775130 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.64251 (* 1 = 3.64251 loss)
I0424 00:13:35.775138 21205 sgd_solver.cpp:112] Iteration 16900, lr = 0.01
I0424 00:14:07.558022 21205 solver.cpp:239] Iteration 17000 (3.1463 iter/s, 31.7834s/100 iters), loss = 3.69345
I0424 00:14:07.558102 21205 solver.cpp:258]     Train net output #0: accuracy = 0.460938
I0424 00:14:07.558115 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.69345 (* 1 = 3.69345 loss)
I0424 00:14:07.558125 21205 sgd_solver.cpp:112] Iteration 17000, lr = 0.01
I0424 00:14:39.341806 21205 solver.cpp:239] Iteration 17100 (3.14622 iter/s, 31.7842s/100 iters), loss = 3.47162
I0424 00:14:39.341876 21205 solver.cpp:258]     Train net output #0: accuracy = 0.484375
I0424 00:14:39.341887 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.47162 (* 1 = 3.47162 loss)
I0424 00:14:39.341897 21205 sgd_solver.cpp:112] Iteration 17100, lr = 0.01
I0424 00:15:11.125900 21205 solver.cpp:239] Iteration 17200 (3.14619 iter/s, 31.7845s/100 iters), loss = 3.335
I0424 00:15:11.125979 21205 solver.cpp:258]     Train net output #0: accuracy = 0.5
I0424 00:15:11.125991 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.335 (* 1 = 3.335 loss)
I0424 00:15:11.126001 21205 sgd_solver.cpp:112] Iteration 17200, lr = 0.01
I0424 00:15:28.000434 21209 data_layer.cpp:73] Restarting data prefetching from start.
I0424 00:15:42.912469 21205 solver.cpp:239] Iteration 17300 (3.14595 iter/s, 31.7869s/100 iters), loss = 3.44551
I0424 00:15:42.912537 21205 solver.cpp:258]     Train net output #0: accuracy = 0.414062
I0424 00:15:42.912549 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.44551 (* 1 = 3.44551 loss)
I0424 00:15:42.912557 21205 sgd_solver.cpp:112] Iteration 17300, lr = 0.01
I0424 00:16:14.702064 21205 solver.cpp:239] Iteration 17400 (3.14565 iter/s, 31.79s/100 iters), loss = 3.38349
I0424 00:16:14.702172 21205 solver.cpp:258]     Train net output #0: accuracy = 0.523438
I0424 00:16:14.702184 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.38349 (* 1 = 3.38349 loss)
I0424 00:16:14.702195 21205 sgd_solver.cpp:112] Iteration 17400, lr = 0.01
I0424 00:16:46.488785 21205 solver.cpp:239] Iteration 17500 (3.14594 iter/s, 31.787s/100 iters), loss = 3.29247
I0424 00:16:46.488907 21205 solver.cpp:258]     Train net output #0: accuracy = 0.492188
I0424 00:16:46.488919 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.29247 (* 1 = 3.29247 loss)
I0424 00:16:46.488929 21205 sgd_solver.cpp:112] Iteration 17500, lr = 0.01
I0424 00:17:18.270956 21205 solver.cpp:239] Iteration 17600 (3.14639 iter/s, 31.7824s/100 iters), loss = 3.23548
I0424 00:17:18.271041 21205 solver.cpp:258]     Train net output #0: accuracy = 0.507812
I0424 00:17:18.271052 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.23548 (* 1 = 3.23548 loss)
I0424 00:17:18.271061 21205 sgd_solver.cpp:112] Iteration 17600, lr = 0.01
I0424 00:17:50.055009 21205 solver.cpp:239] Iteration 17700 (3.1462 iter/s, 31.7844s/100 iters), loss = 3.39711
I0424 00:17:50.055068 21205 solver.cpp:258]     Train net output #0: accuracy = 0.492188
I0424 00:17:50.055078 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.39711 (* 1 = 3.39711 loss)
I0424 00:17:50.055088 21205 sgd_solver.cpp:112] Iteration 17700, lr = 0.01
I0424 00:18:21.844533 21205 solver.cpp:239] Iteration 17800 (3.14566 iter/s, 31.7898s/100 iters), loss = 3.33683
I0424 00:18:21.844621 21205 solver.cpp:258]     Train net output #0: accuracy = 0.46875
I0424 00:18:21.844633 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.33683 (* 1 = 3.33683 loss)
I0424 00:18:21.844643 21205 sgd_solver.cpp:112] Iteration 17800, lr = 0.01
I0424 00:18:53.630323 21205 solver.cpp:239] Iteration 17900 (3.14603 iter/s, 31.7861s/100 iters), loss = 3.03789
I0424 00:18:53.630400 21205 solver.cpp:258]     Train net output #0: accuracy = 0.484375
I0424 00:18:53.630412 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.03789 (* 1 = 3.03789 loss)
I0424 00:18:53.630421 21205 sgd_solver.cpp:112] Iteration 17900, lr = 0.01
I0424 00:19:25.413475 21205 solver.cpp:239] Iteration 18000 (3.14629 iter/s, 31.7834s/100 iters), loss = 2.93051
I0424 00:19:25.413532 21205 solver.cpp:258]     Train net output #0: accuracy = 0.523438
I0424 00:19:25.413543 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.93051 (* 1 = 2.93051 loss)
I0424 00:19:25.413552 21205 sgd_solver.cpp:112] Iteration 18000, lr = 0.01
I0424 00:19:26.401829 21209 data_layer.cpp:73] Restarting data prefetching from start.
I0424 00:19:57.197508 21205 solver.cpp:239] Iteration 18100 (3.14621 iter/s, 31.7843s/100 iters), loss = 3.05225
I0424 00:19:57.197594 21205 solver.cpp:258]     Train net output #0: accuracy = 0.523438
I0424 00:19:57.197605 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.05225 (* 1 = 3.05225 loss)
I0424 00:19:57.197615 21205 sgd_solver.cpp:112] Iteration 18100, lr = 0.01
I0424 00:20:28.985311 21205 solver.cpp:239] Iteration 18200 (3.14584 iter/s, 31.788s/100 iters), loss = 2.56619
I0424 00:20:28.985378 21205 solver.cpp:258]     Train net output #0: accuracy = 0.570312
I0424 00:20:28.985388 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.56619 (* 1 = 2.56619 loss)
I0424 00:20:28.985399 21205 sgd_solver.cpp:112] Iteration 18200, lr = 0.01
I0424 00:21:00.771294 21205 solver.cpp:239] Iteration 18300 (3.14602 iter/s, 31.7862s/100 iters), loss = 3.81113
I0424 00:21:00.771396 21205 solver.cpp:258]     Train net output #0: accuracy = 0.421875
I0424 00:21:00.771407 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.81113 (* 1 = 3.81113 loss)
I0424 00:21:00.771417 21205 sgd_solver.cpp:112] Iteration 18300, lr = 0.01
I0424 00:21:32.554138 21205 solver.cpp:239] Iteration 18400 (3.14633 iter/s, 31.783s/100 iters), loss = 2.93616
I0424 00:21:32.554217 21205 solver.cpp:258]     Train net output #0: accuracy = 0.546875
I0424 00:21:32.554229 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.93616 (* 1 = 2.93616 loss)
I0424 00:21:32.554239 21205 sgd_solver.cpp:112] Iteration 18400, lr = 0.01
I0424 00:22:04.336042 21205 solver.cpp:239] Iteration 18500 (3.14642 iter/s, 31.7821s/100 iters), loss = 3.32855
I0424 00:22:04.336127 21205 solver.cpp:258]     Train net output #0: accuracy = 0.46875
I0424 00:22:04.336138 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.32855 (* 1 = 3.32855 loss)
I0424 00:22:04.336148 21205 sgd_solver.cpp:112] Iteration 18500, lr = 0.01
I0424 00:22:36.118803 21205 solver.cpp:239] Iteration 18600 (3.14634 iter/s, 31.783s/100 iters), loss = 3.16528
I0424 00:22:36.118871 21205 solver.cpp:258]     Train net output #0: accuracy = 0.5
I0424 00:22:36.118883 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.16528 (* 1 = 3.16528 loss)
I0424 00:22:36.118892 21205 sgd_solver.cpp:112] Iteration 18600, lr = 0.01
I0424 00:23:07.905689 21205 solver.cpp:239] Iteration 18700 (3.14593 iter/s, 31.7871s/100 iters), loss = 3.16201
I0424 00:23:07.905767 21205 solver.cpp:258]     Train net output #0: accuracy = 0.523438
I0424 00:23:07.905779 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.16201 (* 1 = 3.16201 loss)
I0424 00:23:07.905789 21205 sgd_solver.cpp:112] Iteration 18700, lr = 0.01
I0424 00:23:25.085578 21209 data_layer.cpp:73] Restarting data prefetching from start.
I0424 00:23:39.689916 21205 solver.cpp:239] Iteration 18800 (3.1462 iter/s, 31.7844s/100 iters), loss = 2.8745
I0424 00:23:39.689973 21205 solver.cpp:258]     Train net output #0: accuracy = 0.515625
I0424 00:23:39.689985 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.8745 (* 1 = 2.8745 loss)
I0424 00:23:39.689994 21205 sgd_solver.cpp:112] Iteration 18800, lr = 0.01
I0424 00:24:11.472236 21205 solver.cpp:239] Iteration 18900 (3.14638 iter/s, 31.7825s/100 iters), loss = 2.79481
I0424 00:24:11.472314 21205 solver.cpp:258]     Train net output #0: accuracy = 0.570312
I0424 00:24:11.472326 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.79481 (* 1 = 2.79481 loss)
I0424 00:24:11.472337 21205 sgd_solver.cpp:112] Iteration 18900, lr = 0.01
I0424 00:24:43.260732 21205 solver.cpp:239] Iteration 19000 (3.14577 iter/s, 31.7887s/100 iters), loss = 3.22368
I0424 00:24:43.260793 21205 solver.cpp:258]     Train net output #0: accuracy = 0.476562
I0424 00:24:43.260804 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.22368 (* 1 = 3.22368 loss)
I0424 00:24:43.260814 21205 sgd_solver.cpp:112] Iteration 19000, lr = 0.01
I0424 00:25:15.054860 21205 solver.cpp:239] Iteration 19100 (3.14522 iter/s, 31.7943s/100 iters), loss = 3.13712
I0424 00:25:15.054960 21205 solver.cpp:258]     Train net output #0: accuracy = 0.515625
I0424 00:25:15.054971 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.13712 (* 1 = 3.13712 loss)
I0424 00:25:15.054981 21205 sgd_solver.cpp:112] Iteration 19100, lr = 0.01
I0424 00:25:46.851977 21205 solver.cpp:239] Iteration 19200 (3.14492 iter/s, 31.7973s/100 iters), loss = 2.84921
I0424 00:25:46.852051 21205 solver.cpp:258]     Train net output #0: accuracy = 0.554688
I0424 00:25:46.852062 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.84921 (* 1 = 2.84921 loss)
I0424 00:25:46.852074 21205 sgd_solver.cpp:112] Iteration 19200, lr = 0.01
I0424 00:26:18.648013 21205 solver.cpp:239] Iteration 19300 (3.14503 iter/s, 31.7962s/100 iters), loss = 3.6075
I0424 00:26:18.648099 21205 solver.cpp:258]     Train net output #0: accuracy = 0.453125
I0424 00:26:18.648111 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.6075 (* 1 = 3.6075 loss)
I0424 00:26:18.648121 21205 sgd_solver.cpp:112] Iteration 19300, lr = 0.01
I0424 00:26:50.443055 21205 solver.cpp:239] Iteration 19400 (3.14513 iter/s, 31.7952s/100 iters), loss = 2.82379
I0424 00:26:50.443115 21205 solver.cpp:258]     Train net output #0: accuracy = 0.5
I0424 00:26:50.443126 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.82379 (* 1 = 2.82379 loss)
I0424 00:26:50.443136 21205 sgd_solver.cpp:112] Iteration 19400, lr = 0.01
I0424 00:27:22.237021 21205 solver.cpp:239] Iteration 19500 (3.14523 iter/s, 31.7941s/100 iters), loss = 2.60565
I0424 00:27:22.237130 21205 solver.cpp:258]     Train net output #0: accuracy = 0.601562
I0424 00:27:22.237143 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.60565 (* 1 = 2.60565 loss)
I0424 00:27:22.237154 21205 sgd_solver.cpp:112] Iteration 19500, lr = 0.01
I0424 00:27:23.536471 21209 data_layer.cpp:73] Restarting data prefetching from start.
I0424 00:27:54.029691 21205 solver.cpp:239] Iteration 19600 (3.14537 iter/s, 31.7928s/100 iters), loss = 3.35458
I0424 00:27:54.029811 21205 solver.cpp:258]     Train net output #0: accuracy = 0.390625
I0424 00:27:54.029824 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.35458 (* 1 = 3.35458 loss)
I0424 00:27:54.029834 21205 sgd_solver.cpp:112] Iteration 19600, lr = 0.01
I0424 00:28:25.825676 21205 solver.cpp:239] Iteration 19700 (3.14504 iter/s, 31.7961s/100 iters), loss = 2.87436
I0424 00:28:25.825749 21205 solver.cpp:258]     Train net output #0: accuracy = 0.507812
I0424 00:28:25.825762 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.87436 (* 1 = 2.87436 loss)
I0424 00:28:25.825773 21205 sgd_solver.cpp:112] Iteration 19700, lr = 0.01
I0424 00:28:57.620014 21205 solver.cpp:239] Iteration 19800 (3.1452 iter/s, 31.7945s/100 iters), loss = 3.14416
I0424 00:28:57.620098 21205 solver.cpp:258]     Train net output #0: accuracy = 0.492188
I0424 00:28:57.620110 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.14416 (* 1 = 3.14416 loss)
I0424 00:28:57.620121 21205 sgd_solver.cpp:112] Iteration 19800, lr = 0.01
I0424 00:29:29.423743 21205 solver.cpp:239] Iteration 19900 (3.14427 iter/s, 31.8039s/100 iters), loss = 3.26552
I0424 00:29:29.423842 21205 solver.cpp:258]     Train net output #0: accuracy = 0.515625
I0424 00:29:29.423856 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.26552 (* 1 = 3.26552 loss)
I0424 00:29:29.423866 21205 sgd_solver.cpp:112] Iteration 19900, lr = 0.01
I0424 00:30:00.894389 21205 solver.cpp:468] Snapshotting to binary proto file result/model_iter_20000.caffemodel
I0424 00:30:00.934201 21205 sgd_solver.cpp:280] Snapshotting solver state to binary proto file result/model_iter_20000.solverstate
I0424 00:30:01.268898 21205 solver.cpp:239] Iteration 20000 (3.14018 iter/s, 31.8453s/100 iters), loss = 3.27317
I0424 00:30:01.268925 21205 solver.cpp:258]     Train net output #0: accuracy = 0.515625
I0424 00:30:01.268934 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.27317 (* 1 = 3.27317 loss)
I0424 00:30:01.268944 21205 sgd_solver.cpp:112] Iteration 20000, lr = 0.01
I0424 00:30:33.052227 21205 solver.cpp:239] Iteration 20100 (3.14629 iter/s, 31.7835s/100 iters), loss = 2.82809
I0424 00:30:33.052300 21205 solver.cpp:258]     Train net output #0: accuracy = 0.554688
I0424 00:30:33.052312 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.82809 (* 1 = 2.82809 loss)
I0424 00:30:33.052322 21205 sgd_solver.cpp:112] Iteration 20100, lr = 0.01
I0424 00:31:04.833015 21205 solver.cpp:239] Iteration 20200 (3.14654 iter/s, 31.7809s/100 iters), loss = 3.47809
I0424 00:31:04.833093 21205 solver.cpp:258]     Train net output #0: accuracy = 0.484375
I0424 00:31:04.833106 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.47809 (* 1 = 3.47809 loss)
I0424 00:31:04.833115 21205 sgd_solver.cpp:112] Iteration 20200, lr = 0.01
I0424 00:31:22.032827 21209 data_layer.cpp:73] Restarting data prefetching from start.
I0424 00:31:36.617242 21205 solver.cpp:239] Iteration 20300 (3.1462 iter/s, 31.7843s/100 iters), loss = 3.26503
I0424 00:31:36.617311 21205 solver.cpp:258]     Train net output #0: accuracy = 0.492188
I0424 00:31:36.617323 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.26503 (* 1 = 3.26503 loss)
I0424 00:31:36.617333 21205 sgd_solver.cpp:112] Iteration 20300, lr = 0.01
I0424 00:32:08.398663 21205 solver.cpp:239] Iteration 20400 (3.14648 iter/s, 31.7816s/100 iters), loss = 3.06987
I0424 00:32:08.398772 21205 solver.cpp:258]     Train net output #0: accuracy = 0.5
I0424 00:32:08.398784 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.06987 (* 1 = 3.06987 loss)
I0424 00:32:08.398795 21205 sgd_solver.cpp:112] Iteration 20400, lr = 0.01
I0424 00:32:40.183269 21205 solver.cpp:239] Iteration 20500 (3.14617 iter/s, 31.7847s/100 iters), loss = 2.53636
I0424 00:32:40.183363 21205 solver.cpp:258]     Train net output #0: accuracy = 0.5625
I0424 00:32:40.183377 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.53636 (* 1 = 2.53636 loss)
I0424 00:32:40.183387 21205 sgd_solver.cpp:112] Iteration 20500, lr = 0.01
I0424 00:33:11.962497 21205 solver.cpp:239] Iteration 20600 (3.1467 iter/s, 31.7793s/100 iters), loss = 3.27463
I0424 00:33:11.962605 21205 solver.cpp:258]     Train net output #0: accuracy = 0.523438
I0424 00:33:11.962618 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.27463 (* 1 = 3.27463 loss)
I0424 00:33:11.962630 21205 sgd_solver.cpp:112] Iteration 20600, lr = 0.01
I0424 00:33:43.743342 21205 solver.cpp:239] Iteration 20700 (3.14654 iter/s, 31.7809s/100 iters), loss = 2.75804
I0424 00:33:43.743402 21205 solver.cpp:258]     Train net output #0: accuracy = 0.601562
I0424 00:33:43.743414 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.75804 (* 1 = 2.75804 loss)
I0424 00:33:43.743424 21205 sgd_solver.cpp:112] Iteration 20700, lr = 0.01
I0424 00:34:15.538085 21205 solver.cpp:239] Iteration 20800 (3.14516 iter/s, 31.7949s/100 iters), loss = 3.12494
I0424 00:34:15.538174 21205 solver.cpp:258]     Train net output #0: accuracy = 0.484375
I0424 00:34:15.538187 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.12494 (* 1 = 3.12494 loss)
I0424 00:34:15.538197 21205 sgd_solver.cpp:112] Iteration 20800, lr = 0.01
I0424 00:34:47.312245 21205 solver.cpp:239] Iteration 20900 (3.1472 iter/s, 31.7743s/100 iters), loss = 2.77641
I0424 00:34:47.312315 21205 solver.cpp:258]     Train net output #0: accuracy = 0.539062
I0424 00:34:47.312326 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.77641 (* 1 = 2.77641 loss)
I0424 00:34:47.312337 21205 sgd_solver.cpp:112] Iteration 20900, lr = 0.01
I0424 00:35:19.098199 21205 solver.cpp:239] Iteration 21000 (3.14603 iter/s, 31.7861s/100 iters), loss = 2.92245
I0424 00:35:19.098278 21205 solver.cpp:258]     Train net output #0: accuracy = 0.5625
I0424 00:35:19.098290 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.92245 (* 1 = 2.92245 loss)
I0424 00:35:19.098300 21205 sgd_solver.cpp:112] Iteration 21000, lr = 0.01
I0424 00:35:20.704380 21209 data_layer.cpp:73] Restarting data prefetching from start.
I0424 00:35:50.884243 21205 solver.cpp:239] Iteration 21100 (3.14602 iter/s, 31.7861s/100 iters), loss = 2.86516
I0424 00:35:50.884295 21205 solver.cpp:258]     Train net output #0: accuracy = 0.546875
I0424 00:35:50.884307 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.86516 (* 1 = 2.86516 loss)
I0424 00:35:50.884317 21205 sgd_solver.cpp:112] Iteration 21100, lr = 0.01
I0424 00:36:22.666437 21205 solver.cpp:239] Iteration 21200 (3.1464 iter/s, 31.7823s/100 iters), loss = 2.9919
I0424 00:36:22.666524 21205 solver.cpp:258]     Train net output #0: accuracy = 0.507812
I0424 00:36:22.666535 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.9919 (* 1 = 2.9919 loss)
I0424 00:36:22.666545 21205 sgd_solver.cpp:112] Iteration 21200, lr = 0.01
I0424 00:36:54.441928 21205 solver.cpp:239] Iteration 21300 (3.14707 iter/s, 31.7756s/100 iters), loss = 3.27793
I0424 00:36:54.442001 21205 solver.cpp:258]     Train net output #0: accuracy = 0.453125
I0424 00:36:54.442013 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.27793 (* 1 = 3.27793 loss)
I0424 00:36:54.442023 21205 sgd_solver.cpp:112] Iteration 21300, lr = 0.01
I0424 00:37:26.222545 21205 solver.cpp:239] Iteration 21400 (3.14656 iter/s, 31.7807s/100 iters), loss = 3.36927
I0424 00:37:26.222662 21205 solver.cpp:258]     Train net output #0: accuracy = 0.507812
I0424 00:37:26.222676 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.36927 (* 1 = 3.36927 loss)
I0424 00:37:26.222685 21205 sgd_solver.cpp:112] Iteration 21400, lr = 0.01
I0424 00:37:58.007072 21205 solver.cpp:239] Iteration 21500 (3.14618 iter/s, 31.7846s/100 iters), loss = 2.77294
I0424 00:37:58.007184 21205 solver.cpp:258]     Train net output #0: accuracy = 0.554688
I0424 00:37:58.007197 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.77294 (* 1 = 2.77294 loss)
I0424 00:37:58.007207 21205 sgd_solver.cpp:112] Iteration 21500, lr = 0.01
I0424 00:38:29.788238 21205 solver.cpp:239] Iteration 21600 (3.14651 iter/s, 31.7812s/100 iters), loss = 3.35546
I0424 00:38:29.788313 21205 solver.cpp:258]     Train net output #0: accuracy = 0.484375
I0424 00:38:29.788326 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.35546 (* 1 = 3.35546 loss)
I0424 00:38:29.788336 21205 sgd_solver.cpp:112] Iteration 21600, lr = 0.01
I0424 00:39:01.597002 21205 solver.cpp:239] Iteration 21700 (3.14378 iter/s, 31.8089s/100 iters), loss = 3.40012
I0424 00:39:01.597077 21205 solver.cpp:258]     Train net output #0: accuracy = 0.453125
I0424 00:39:01.597090 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.40012 (* 1 = 3.40012 loss)
I0424 00:39:01.597100 21205 sgd_solver.cpp:112] Iteration 21700, lr = 0.01
I0424 00:39:19.094514 21209 data_layer.cpp:73] Restarting data prefetching from start.
I0424 00:39:33.379513 21205 solver.cpp:239] Iteration 21800 (3.14637 iter/s, 31.7826s/100 iters), loss = 2.7056
I0424 00:39:33.379582 21205 solver.cpp:258]     Train net output #0: accuracy = 0.5625
I0424 00:39:33.379593 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.7056 (* 1 = 2.7056 loss)
I0424 00:39:33.379603 21205 sgd_solver.cpp:112] Iteration 21800, lr = 0.01
I0424 00:40:05.166540 21205 solver.cpp:239] Iteration 21900 (3.14593 iter/s, 31.7871s/100 iters), loss = 2.57791
I0424 00:40:05.166627 21205 solver.cpp:258]     Train net output #0: accuracy = 0.585938
I0424 00:40:05.166640 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.57791 (* 1 = 2.57791 loss)
I0424 00:40:05.166649 21205 sgd_solver.cpp:112] Iteration 21900, lr = 0.01
I0424 00:40:36.958428 21205 solver.cpp:239] Iteration 22000 (3.14545 iter/s, 31.792s/100 iters), loss = 2.08379
I0424 00:40:36.958495 21205 solver.cpp:258]     Train net output #0: accuracy = 0.625
I0424 00:40:36.958508 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.08379 (* 1 = 2.08379 loss)
I0424 00:40:36.958516 21205 sgd_solver.cpp:112] Iteration 22000, lr = 0.01
I0424 00:41:08.751488 21205 solver.cpp:239] Iteration 22100 (3.14533 iter/s, 31.7932s/100 iters), loss = 3.12268
I0424 00:41:08.751576 21205 solver.cpp:258]     Train net output #0: accuracy = 0.445312
I0424 00:41:08.751588 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.12268 (* 1 = 3.12268 loss)
I0424 00:41:08.751597 21205 sgd_solver.cpp:112] Iteration 22100, lr = 0.01
I0424 00:41:40.540395 21205 solver.cpp:239] Iteration 22200 (3.14574 iter/s, 31.789s/100 iters), loss = 3.12443
I0424 00:41:40.540495 21205 solver.cpp:258]     Train net output #0: accuracy = 0.492188
I0424 00:41:40.540508 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.12443 (* 1 = 3.12443 loss)
I0424 00:41:40.540518 21205 sgd_solver.cpp:112] Iteration 22200, lr = 0.01
I0424 00:42:12.334516 21205 solver.cpp:239] Iteration 22300 (3.14523 iter/s, 31.7942s/100 iters), loss = 3.0858
I0424 00:42:12.334595 21205 solver.cpp:258]     Train net output #0: accuracy = 0.570312
I0424 00:42:12.334606 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.0858 (* 1 = 3.0858 loss)
I0424 00:42:12.334616 21205 sgd_solver.cpp:112] Iteration 22300, lr = 0.01
I0424 00:42:44.131054 21205 solver.cpp:239] Iteration 22400 (3.14499 iter/s, 31.7966s/100 iters), loss = 2.95605
I0424 00:42:44.131125 21205 solver.cpp:258]     Train net output #0: accuracy = 0.484375
I0424 00:42:44.131136 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.95605 (* 1 = 2.95605 loss)
I0424 00:42:44.131146 21205 sgd_solver.cpp:112] Iteration 22400, lr = 0.01
I0424 00:43:15.925498 21205 solver.cpp:239] Iteration 22500 (3.14519 iter/s, 31.7945s/100 iters), loss = 3.10682
I0424 00:43:15.925604 21205 solver.cpp:258]     Train net output #0: accuracy = 0.484375
I0424 00:43:15.925616 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.10682 (* 1 = 3.10682 loss)
I0424 00:43:15.925626 21205 sgd_solver.cpp:112] Iteration 22500, lr = 0.01
I0424 00:43:17.549541 21209 data_layer.cpp:73] Restarting data prefetching from start.
I0424 00:43:47.720350 21205 solver.cpp:239] Iteration 22600 (3.14516 iter/s, 31.7949s/100 iters), loss = 2.42089
I0424 00:43:47.720433 21205 solver.cpp:258]     Train net output #0: accuracy = 0.570312
I0424 00:43:47.720446 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.42089 (* 1 = 2.42089 loss)
I0424 00:43:47.720456 21205 sgd_solver.cpp:112] Iteration 22600, lr = 0.01
I0424 00:44:19.516394 21205 solver.cpp:239] Iteration 22700 (3.14504 iter/s, 31.7961s/100 iters), loss = 3.15047
I0424 00:44:19.516485 21205 solver.cpp:258]     Train net output #0: accuracy = 0.546875
I0424 00:44:19.516497 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.15047 (* 1 = 3.15047 loss)
I0424 00:44:19.516507 21205 sgd_solver.cpp:112] Iteration 22700, lr = 0.01
I0424 00:44:51.309623 21205 solver.cpp:239] Iteration 22800 (3.14532 iter/s, 31.7933s/100 iters), loss = 3.16565
I0424 00:44:51.309695 21205 solver.cpp:258]     Train net output #0: accuracy = 0.515625
I0424 00:44:51.309706 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.16565 (* 1 = 3.16565 loss)
I0424 00:44:51.309716 21205 sgd_solver.cpp:112] Iteration 22800, lr = 0.01
I0424 00:45:23.099675 21205 solver.cpp:239] Iteration 22900 (3.14561 iter/s, 31.7903s/100 iters), loss = 3.59615
I0424 00:45:23.099753 21205 solver.cpp:258]     Train net output #0: accuracy = 0.523438
I0424 00:45:23.099766 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.59615 (* 1 = 3.59615 loss)
I0424 00:45:23.099776 21205 sgd_solver.cpp:112] Iteration 22900, lr = 0.01
I0424 00:45:54.895830 21205 solver.cpp:239] Iteration 23000 (3.145 iter/s, 31.7965s/100 iters), loss = 2.47361
I0424 00:45:54.895906 21205 solver.cpp:258]     Train net output #0: accuracy = 0.554688
I0424 00:45:54.895918 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.47361 (* 1 = 2.47361 loss)
I0424 00:45:54.895928 21205 sgd_solver.cpp:112] Iteration 23000, lr = 0.01
I0424 00:46:26.687361 21205 solver.cpp:239] Iteration 23100 (3.14545 iter/s, 31.7919s/100 iters), loss = 2.72044
I0424 00:46:26.687453 21205 solver.cpp:258]     Train net output #0: accuracy = 0.539062
I0424 00:46:26.687463 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.72044 (* 1 = 2.72044 loss)
I0424 00:46:26.687474 21205 sgd_solver.cpp:112] Iteration 23100, lr = 0.01
I0424 00:46:58.477540 21205 solver.cpp:239] Iteration 23200 (3.14559 iter/s, 31.7905s/100 iters), loss = 3.30569
I0424 00:46:58.477615 21205 solver.cpp:258]     Train net output #0: accuracy = 0.492188
I0424 00:46:58.477627 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.30569 (* 1 = 3.30569 loss)
I0424 00:46:58.477638 21205 sgd_solver.cpp:112] Iteration 23200, lr = 0.01
I0424 00:47:16.299672 21209 data_layer.cpp:73] Restarting data prefetching from start.
I0424 00:47:30.267490 21205 solver.cpp:239] Iteration 23300 (3.14561 iter/s, 31.7903s/100 iters), loss = 2.82559
I0424 00:47:30.267561 21205 solver.cpp:258]     Train net output #0: accuracy = 0.578125
I0424 00:47:30.267572 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.82559 (* 1 = 2.82559 loss)
I0424 00:47:30.267583 21205 sgd_solver.cpp:112] Iteration 23300, lr = 0.01
I0424 00:48:02.062722 21205 solver.cpp:239] Iteration 23400 (3.14509 iter/s, 31.7956s/100 iters), loss = 2.98905
I0424 00:48:02.062801 21205 solver.cpp:258]     Train net output #0: accuracy = 0.53125
I0424 00:48:02.062813 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.98905 (* 1 = 2.98905 loss)
I0424 00:48:02.062824 21205 sgd_solver.cpp:112] Iteration 23400, lr = 0.01
I0424 00:48:33.857656 21205 solver.cpp:239] Iteration 23500 (3.14512 iter/s, 31.7952s/100 iters), loss = 2.64075
I0424 00:48:33.857758 21205 solver.cpp:258]     Train net output #0: accuracy = 0.53125
I0424 00:48:33.857771 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.64075 (* 1 = 2.64075 loss)
I0424 00:48:33.857782 21205 sgd_solver.cpp:112] Iteration 23500, lr = 0.01
I0424 00:49:05.647467 21205 solver.cpp:239] Iteration 23600 (3.14563 iter/s, 31.7901s/100 iters), loss = 2.95038
I0424 00:49:05.647572 21205 solver.cpp:258]     Train net output #0: accuracy = 0.507812
I0424 00:49:05.647585 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.95038 (* 1 = 2.95038 loss)
I0424 00:49:05.647596 21205 sgd_solver.cpp:112] Iteration 23600, lr = 0.01
I0424 00:49:37.441330 21205 solver.cpp:239] Iteration 23700 (3.14524 iter/s, 31.7941s/100 iters), loss = 2.48517
I0424 00:49:37.441404 21205 solver.cpp:258]     Train net output #0: accuracy = 0.617188
I0424 00:49:37.441416 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.48517 (* 1 = 2.48517 loss)
I0424 00:49:37.441427 21205 sgd_solver.cpp:112] Iteration 23700, lr = 0.01
I0424 00:50:09.234993 21205 solver.cpp:239] Iteration 23800 (3.14525 iter/s, 31.7939s/100 iters), loss = 2.61649
I0424 00:50:09.235077 21205 solver.cpp:258]     Train net output #0: accuracy = 0.570312
I0424 00:50:09.235090 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.61649 (* 1 = 2.61649 loss)
I0424 00:50:09.235100 21205 sgd_solver.cpp:112] Iteration 23800, lr = 0.01
I0424 00:50:41.026926 21205 solver.cpp:239] Iteration 23900 (3.14543 iter/s, 31.7922s/100 iters), loss = 3.06686
I0424 00:50:41.026984 21205 solver.cpp:258]     Train net output #0: accuracy = 0.523438
I0424 00:50:41.026995 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.06686 (* 1 = 3.06686 loss)
I0424 00:50:41.027005 21205 sgd_solver.cpp:112] Iteration 23900, lr = 0.01
I0424 00:51:12.502122 21205 solver.cpp:468] Snapshotting to binary proto file result/model_iter_24000.caffemodel
I0424 00:51:12.541869 21205 sgd_solver.cpp:280] Snapshotting solver state to binary proto file result/model_iter_24000.solverstate
I0424 00:51:12.877329 21205 solver.cpp:239] Iteration 24000 (3.13965 iter/s, 31.8507s/100 iters), loss = 2.64215
I0424 00:51:12.877358 21205 solver.cpp:258]     Train net output #0: accuracy = 0.554688
I0424 00:51:12.877360 21210 sgd_solver.cpp:50] MultiStep Status: Iteration 24000, step = 2
I0424 00:51:12.877367 21212 sgd_solver.cpp:50] MultiStep Status: Iteration 24000, step = 2
I0424 00:51:12.877367 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.64215 (* 1 = 2.64215 loss)
I0424 00:51:12.877368 21211 sgd_solver.cpp:50] MultiStep Status: Iteration 24000, step = 2
I0424 00:51:12.877389 21205 sgd_solver.cpp:50] MultiStep Status: Iteration 24000, step = 2
I0424 00:51:12.877393 21205 sgd_solver.cpp:112] Iteration 24000, lr = 0.001
I0424 00:51:14.811683 21209 data_layer.cpp:73] Restarting data prefetching from start.
I0424 00:51:44.669461 21205 solver.cpp:239] Iteration 24100 (3.1454 iter/s, 31.7924s/100 iters), loss = 3.20257
I0424 00:51:44.669529 21205 solver.cpp:258]     Train net output #0: accuracy = 0.523438
I0424 00:51:44.669541 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.20257 (* 1 = 3.20257 loss)
I0424 00:51:44.669551 21205 sgd_solver.cpp:112] Iteration 24100, lr = 0.001
I0424 00:52:16.462656 21205 solver.cpp:239] Iteration 24200 (3.1453 iter/s, 31.7935s/100 iters), loss = 3.3338
I0424 00:52:16.462736 21205 solver.cpp:258]     Train net output #0: accuracy = 0.53125
I0424 00:52:16.462749 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.3338 (* 1 = 3.3338 loss)
I0424 00:52:16.462757 21205 sgd_solver.cpp:112] Iteration 24200, lr = 0.001
I0424 00:52:48.248517 21205 solver.cpp:239] Iteration 24300 (3.14603 iter/s, 31.7861s/100 iters), loss = 3.10492
I0424 00:52:48.248605 21205 solver.cpp:258]     Train net output #0: accuracy = 0.601562
I0424 00:52:48.248616 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.10492 (* 1 = 3.10492 loss)
I0424 00:52:48.248626 21205 sgd_solver.cpp:112] Iteration 24300, lr = 0.001
I0424 00:53:20.035529 21205 solver.cpp:239] Iteration 24400 (3.14592 iter/s, 31.7872s/100 iters), loss = 2.65811
I0424 00:53:20.035635 21205 solver.cpp:258]     Train net output #0: accuracy = 0.546875
I0424 00:53:20.035647 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.65811 (* 1 = 2.65811 loss)
I0424 00:53:20.035657 21205 sgd_solver.cpp:112] Iteration 24400, lr = 0.001
I0424 00:53:51.819124 21205 solver.cpp:239] Iteration 24500 (3.14626 iter/s, 31.7838s/100 iters), loss = 3.31554
I0424 00:53:51.819200 21205 solver.cpp:258]     Train net output #0: accuracy = 0.484375
I0424 00:53:51.819212 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.31554 (* 1 = 3.31554 loss)
I0424 00:53:51.819222 21205 sgd_solver.cpp:112] Iteration 24500, lr = 0.001
I0424 00:54:23.608552 21205 solver.cpp:239] Iteration 24600 (3.14568 iter/s, 31.7896s/100 iters), loss = 3.18413
I0424 00:54:23.608631 21205 solver.cpp:258]     Train net output #0: accuracy = 0.5
I0424 00:54:23.608644 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.18413 (* 1 = 3.18413 loss)
I0424 00:54:23.608654 21205 sgd_solver.cpp:112] Iteration 24600, lr = 0.001
I0424 00:54:55.395287 21205 solver.cpp:239] Iteration 24700 (3.14595 iter/s, 31.7869s/100 iters), loss = 2.79532
I0424 00:54:55.395364 21205 solver.cpp:258]     Train net output #0: accuracy = 0.539062
I0424 00:54:55.395375 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.79532 (* 1 = 2.79532 loss)
I0424 00:54:55.395385 21205 sgd_solver.cpp:112] Iteration 24700, lr = 0.001
I0424 00:55:13.233520 21209 data_layer.cpp:73] Restarting data prefetching from start.
I0424 00:55:27.186651 21205 solver.cpp:239] Iteration 24800 (3.14549 iter/s, 31.7916s/100 iters), loss = 3.21262
I0424 00:55:27.186722 21205 solver.cpp:258]     Train net output #0: accuracy = 0.515625
I0424 00:55:27.186733 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.21262 (* 1 = 3.21262 loss)
I0424 00:55:27.186745 21205 sgd_solver.cpp:112] Iteration 24800, lr = 0.001
I0424 00:55:58.975845 21205 solver.cpp:239] Iteration 24900 (3.1457 iter/s, 31.7894s/100 iters), loss = 2.44574
I0424 00:55:58.975949 21205 solver.cpp:258]     Train net output #0: accuracy = 0.578125
I0424 00:55:58.975960 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.44574 (* 1 = 2.44574 loss)
I0424 00:55:58.975971 21205 sgd_solver.cpp:112] Iteration 24900, lr = 0.001
I0424 00:56:30.762089 21205 solver.cpp:239] Iteration 25000 (3.146 iter/s, 31.7864s/100 iters), loss = 2.8675
I0424 00:56:30.762148 21205 solver.cpp:258]     Train net output #0: accuracy = 0.492188
I0424 00:56:30.762159 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.8675 (* 1 = 2.8675 loss)
I0424 00:56:30.762169 21205 sgd_solver.cpp:112] Iteration 25000, lr = 0.001
I0424 00:57:02.544775 21205 solver.cpp:239] Iteration 25100 (3.14635 iter/s, 31.7829s/100 iters), loss = 2.96269
I0424 00:57:02.544859 21205 solver.cpp:258]     Train net output #0: accuracy = 0.53125
I0424 00:57:02.544872 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.96269 (* 1 = 2.96269 loss)
I0424 00:57:02.544881 21205 sgd_solver.cpp:112] Iteration 25100, lr = 0.001
I0424 00:57:34.330669 21205 solver.cpp:239] Iteration 25200 (3.14603 iter/s, 31.7861s/100 iters), loss = 2.83891
I0424 00:57:34.330727 21205 solver.cpp:258]     Train net output #0: accuracy = 0.570312
I0424 00:57:34.330739 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.83891 (* 1 = 2.83891 loss)
I0424 00:57:34.330749 21205 sgd_solver.cpp:112] Iteration 25200, lr = 0.001
I0424 00:58:06.117885 21205 solver.cpp:239] Iteration 25300 (3.1459 iter/s, 31.7874s/100 iters), loss = 2.7066
I0424 00:58:06.117967 21205 solver.cpp:258]     Train net output #0: accuracy = 0.546875
I0424 00:58:06.117980 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.7066 (* 1 = 2.7066 loss)
I0424 00:58:06.117991 21205 sgd_solver.cpp:112] Iteration 25300, lr = 0.001
I0424 00:58:37.899163 21205 solver.cpp:239] Iteration 25400 (3.14649 iter/s, 31.7815s/100 iters), loss = 3.11979
I0424 00:58:37.899263 21205 solver.cpp:258]     Train net output #0: accuracy = 0.453125
I0424 00:58:37.899276 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.11979 (* 1 = 3.11979 loss)
I0424 00:58:37.899287 21205 sgd_solver.cpp:112] Iteration 25400, lr = 0.001
I0424 00:59:09.682615 21205 solver.cpp:239] Iteration 25500 (3.14628 iter/s, 31.7836s/100 iters), loss = 2.99117
I0424 00:59:09.682725 21205 solver.cpp:258]     Train net output #0: accuracy = 0.515625
I0424 00:59:09.682737 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.99117 (* 1 = 2.99117 loss)
I0424 00:59:09.682749 21205 sgd_solver.cpp:112] Iteration 25500, lr = 0.001
I0424 00:59:11.925695 21209 data_layer.cpp:73] Restarting data prefetching from start.
I0424 00:59:41.462764 21205 solver.cpp:239] Iteration 25600 (3.1466 iter/s, 31.7803s/100 iters), loss = 3.07775
I0424 00:59:41.462864 21205 solver.cpp:258]     Train net output #0: accuracy = 0.507812
I0424 00:59:41.462877 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.07775 (* 1 = 3.07775 loss)
I0424 00:59:41.462888 21205 sgd_solver.cpp:112] Iteration 25600, lr = 0.001
I0424 01:00:13.242591 21205 solver.cpp:239] Iteration 25700 (3.14664 iter/s, 31.78s/100 iters), loss = 2.85138
I0424 01:00:13.242672 21205 solver.cpp:258]     Train net output #0: accuracy = 0.492188
I0424 01:00:13.242686 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.85138 (* 1 = 2.85138 loss)
I0424 01:00:13.242696 21205 sgd_solver.cpp:112] Iteration 25700, lr = 0.001
I0424 01:00:45.022801 21205 solver.cpp:239] Iteration 25800 (3.1466 iter/s, 31.7804s/100 iters), loss = 2.97619
I0424 01:00:45.022860 21205 solver.cpp:258]     Train net output #0: accuracy = 0.53125
I0424 01:00:45.022871 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.97619 (* 1 = 2.97619 loss)
I0424 01:00:45.022881 21205 sgd_solver.cpp:112] Iteration 25800, lr = 0.001
I0424 01:01:16.804847 21205 solver.cpp:239] Iteration 25900 (3.14641 iter/s, 31.7822s/100 iters), loss = 2.78471
I0424 01:01:16.804926 21205 solver.cpp:258]     Train net output #0: accuracy = 0.539062
I0424 01:01:16.804939 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.78471 (* 1 = 2.78471 loss)
I0424 01:01:16.804949 21205 sgd_solver.cpp:112] Iteration 25900, lr = 0.001
I0424 01:01:48.601749 21205 solver.cpp:239] Iteration 26000 (3.14494 iter/s, 31.7971s/100 iters), loss = 2.8193
I0424 01:01:48.601810 21205 solver.cpp:258]     Train net output #0: accuracy = 0.539062
I0424 01:01:48.601821 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.8193 (* 1 = 2.8193 loss)
I0424 01:01:48.601831 21205 sgd_solver.cpp:112] Iteration 26000, lr = 0.001
I0424 01:02:20.397009 21205 solver.cpp:239] Iteration 26100 (3.14511 iter/s, 31.7954s/100 iters), loss = 3.15185
I0424 01:02:20.397094 21205 solver.cpp:258]     Train net output #0: accuracy = 0.546875
I0424 01:02:20.397106 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.15185 (* 1 = 3.15185 loss)
I0424 01:02:20.397116 21205 sgd_solver.cpp:112] Iteration 26100, lr = 0.001
I0424 01:02:52.195255 21205 solver.cpp:239] Iteration 26200 (3.14481 iter/s, 31.7984s/100 iters), loss = 3.112
I0424 01:02:52.195312 21205 solver.cpp:258]     Train net output #0: accuracy = 0.539062
I0424 01:02:52.195323 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.112 (* 1 = 3.112 loss)
I0424 01:02:52.195333 21205 sgd_solver.cpp:112] Iteration 26200, lr = 0.001
I0424 01:03:10.347630 21209 data_layer.cpp:73] Restarting data prefetching from start.
I0424 01:03:23.991947 21205 solver.cpp:239] Iteration 26300 (3.14496 iter/s, 31.7969s/100 iters), loss = 2.81072
I0424 01:03:23.992035 21205 solver.cpp:258]     Train net output #0: accuracy = 0.5
I0424 01:03:23.992046 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.81072 (* 1 = 2.81072 loss)
I0424 01:03:23.992056 21205 sgd_solver.cpp:112] Iteration 26300, lr = 0.001
I0424 01:03:55.788034 21205 solver.cpp:239] Iteration 26400 (3.14503 iter/s, 31.7962s/100 iters), loss = 2.79669
I0424 01:03:55.788169 21205 solver.cpp:258]     Train net output #0: accuracy = 0.53125
I0424 01:03:55.788182 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.79669 (* 1 = 2.79669 loss)
I0424 01:03:55.788192 21205 sgd_solver.cpp:112] Iteration 26400, lr = 0.001
I0424 01:04:27.584031 21205 solver.cpp:239] Iteration 26500 (3.14504 iter/s, 31.7961s/100 iters), loss = 2.95623
I0424 01:04:27.584115 21205 solver.cpp:258]     Train net output #0: accuracy = 0.515625
I0424 01:04:27.584126 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.95623 (* 1 = 2.95623 loss)
I0424 01:04:27.584136 21205 sgd_solver.cpp:112] Iteration 26500, lr = 0.001
I0424 01:04:59.363819 21205 solver.cpp:239] Iteration 26600 (3.14664 iter/s, 31.7799s/100 iters), loss = 2.57223
I0424 01:04:59.363910 21205 solver.cpp:258]     Train net output #0: accuracy = 0.554688
I0424 01:04:59.363922 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.57223 (* 1 = 2.57223 loss)
I0424 01:04:59.363931 21205 sgd_solver.cpp:112] Iteration 26600, lr = 0.001
I0424 01:05:31.145488 21205 solver.cpp:239] Iteration 26700 (3.14646 iter/s, 31.7818s/100 iters), loss = 3.08549
I0424 01:05:31.145560 21205 solver.cpp:258]     Train net output #0: accuracy = 0.492188
I0424 01:05:31.145572 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.08549 (* 1 = 3.08549 loss)
I0424 01:05:31.145582 21205 sgd_solver.cpp:112] Iteration 26700, lr = 0.001
I0424 01:06:02.929061 21205 solver.cpp:239] Iteration 26800 (3.14626 iter/s, 31.7837s/100 iters), loss = 2.89177
I0424 01:06:02.929145 21205 solver.cpp:258]     Train net output #0: accuracy = 0.523438
I0424 01:06:02.929157 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.89177 (* 1 = 2.89177 loss)
I0424 01:06:02.929168 21205 sgd_solver.cpp:112] Iteration 26800, lr = 0.001
I0424 01:06:34.710759 21205 solver.cpp:239] Iteration 26900 (3.14645 iter/s, 31.7818s/100 iters), loss = 2.93185
I0424 01:06:34.710821 21205 solver.cpp:258]     Train net output #0: accuracy = 0.5625
I0424 01:06:34.710832 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.93185 (* 1 = 2.93185 loss)
I0424 01:06:34.710842 21205 sgd_solver.cpp:112] Iteration 26900, lr = 0.001
I0424 01:07:06.492741 21205 solver.cpp:239] Iteration 27000 (3.14642 iter/s, 31.7821s/100 iters), loss = 3.07757
I0424 01:07:06.492822 21205 solver.cpp:258]     Train net output #0: accuracy = 0.5625
I0424 01:07:06.492835 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.07757 (* 1 = 3.07757 loss)
I0424 01:07:06.492844 21205 sgd_solver.cpp:112] Iteration 27000, lr = 0.001
I0424 01:07:08.752068 21209 data_layer.cpp:73] Restarting data prefetching from start.
I0424 01:07:38.279821 21205 solver.cpp:239] Iteration 27100 (3.14592 iter/s, 31.7872s/100 iters), loss = 3.00723
I0424 01:07:38.279892 21205 solver.cpp:258]     Train net output #0: accuracy = 0.515625
I0424 01:07:38.279903 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.00723 (* 1 = 3.00723 loss)
I0424 01:07:38.279913 21205 sgd_solver.cpp:112] Iteration 27100, lr = 0.001
I0424 01:08:10.067065 21205 solver.cpp:239] Iteration 27200 (3.1459 iter/s, 31.7874s/100 iters), loss = 2.99239
I0424 01:08:10.067157 21205 solver.cpp:258]     Train net output #0: accuracy = 0.53125
I0424 01:08:10.067169 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.99239 (* 1 = 2.99239 loss)
I0424 01:08:10.067179 21205 sgd_solver.cpp:112] Iteration 27200, lr = 0.001
I0424 01:08:41.854902 21205 solver.cpp:239] Iteration 27300 (3.14585 iter/s, 31.788s/100 iters), loss = 3.51819
I0424 01:08:41.854959 21205 solver.cpp:258]     Train net output #0: accuracy = 0.476562
I0424 01:08:41.854970 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.51819 (* 1 = 3.51819 loss)
I0424 01:08:41.854981 21205 sgd_solver.cpp:112] Iteration 27300, lr = 0.001
I0424 01:09:13.637080 21205 solver.cpp:239] Iteration 27400 (3.1464 iter/s, 31.7823s/100 iters), loss = 3.10366
I0424 01:09:13.637199 21205 solver.cpp:258]     Train net output #0: accuracy = 0.53125
I0424 01:09:13.637212 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.10366 (* 1 = 3.10366 loss)
I0424 01:09:13.637231 21205 sgd_solver.cpp:112] Iteration 27400, lr = 0.001
I0424 01:09:45.420105 21205 solver.cpp:239] Iteration 27500 (3.14632 iter/s, 31.7831s/100 iters), loss = 3.1094
I0424 01:09:45.420182 21205 solver.cpp:258]     Train net output #0: accuracy = 0.492188
I0424 01:09:45.420194 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.1094 (* 1 = 3.1094 loss)
I0424 01:09:45.420204 21205 sgd_solver.cpp:112] Iteration 27500, lr = 0.001
I0424 01:10:17.199118 21205 solver.cpp:239] Iteration 27600 (3.14672 iter/s, 31.7791s/100 iters), loss = 3.48893
I0424 01:10:17.199206 21205 solver.cpp:258]     Train net output #0: accuracy = 0.421875
I0424 01:10:17.199218 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.48893 (* 1 = 3.48893 loss)
I0424 01:10:17.199229 21205 sgd_solver.cpp:112] Iteration 27600, lr = 0.001
I0424 01:10:48.983158 21205 solver.cpp:239] Iteration 27700 (3.14622 iter/s, 31.7842s/100 iters), loss = 2.97094
I0424 01:10:48.983216 21205 solver.cpp:258]     Train net output #0: accuracy = 0.546875
I0424 01:10:48.983227 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.97094 (* 1 = 2.97094 loss)
I0424 01:10:48.983237 21205 sgd_solver.cpp:112] Iteration 27700, lr = 0.001
I0424 01:11:07.436374 21209 data_layer.cpp:73] Restarting data prefetching from start.
I0424 01:11:20.765962 21205 solver.cpp:239] Iteration 27800 (3.14634 iter/s, 31.783s/100 iters), loss = 2.91386
I0424 01:11:20.766047 21205 solver.cpp:258]     Train net output #0: accuracy = 0.507812
I0424 01:11:20.766060 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.91386 (* 1 = 2.91386 loss)
I0424 01:11:20.766070 21205 sgd_solver.cpp:112] Iteration 27800, lr = 0.001
I0424 01:11:52.550448 21205 solver.cpp:239] Iteration 27900 (3.14618 iter/s, 31.7846s/100 iters), loss = 2.82376
I0424 01:11:52.550505 21205 solver.cpp:258]     Train net output #0: accuracy = 0.5625
I0424 01:11:52.550515 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.82376 (* 1 = 2.82376 loss)
I0424 01:11:52.550526 21205 sgd_solver.cpp:112] Iteration 27900, lr = 0.001
I0424 01:12:24.018641 21205 solver.cpp:468] Snapshotting to binary proto file result/model_iter_28000.caffemodel
I0424 01:12:24.058408 21205 sgd_solver.cpp:280] Snapshotting solver state to binary proto file result/model_iter_28000.solverstate
I0424 01:12:24.393221 21205 solver.cpp:239] Iteration 28000 (3.14042 iter/s, 31.8429s/100 iters), loss = 2.93536
I0424 01:12:24.393239 21212 sgd_solver.cpp:50] MultiStep Status: Iteration 28000, step = 3
I0424 01:12:24.393239 21211 sgd_solver.cpp:50] MultiStep Status: Iteration 28000, step = 3
I0424 01:12:24.393252 21205 solver.cpp:258]     Train net output #0: accuracy = 0.546875
I0424 01:12:24.393239 21210 sgd_solver.cpp:50] MultiStep Status: Iteration 28000, step = 3
I0424 01:12:24.393265 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.93536 (* 1 = 2.93536 loss)
I0424 01:12:24.393281 21205 sgd_solver.cpp:50] MultiStep Status: Iteration 28000, step = 3
I0424 01:12:24.393285 21205 sgd_solver.cpp:112] Iteration 28000, lr = 0.0001
I0424 01:12:56.164067 21205 solver.cpp:239] Iteration 28100 (3.14752 iter/s, 31.771s/100 iters), loss = 3.66072
I0424 01:12:56.164149 21205 solver.cpp:258]     Train net output #0: accuracy = 0.507812
I0424 01:12:56.164160 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.66072 (* 1 = 3.66072 loss)
I0424 01:12:56.164170 21205 sgd_solver.cpp:112] Iteration 28100, lr = 0.0001
I0424 01:13:27.938107 21205 solver.cpp:239] Iteration 28200 (3.14721 iter/s, 31.7742s/100 iters), loss = 3.08487
I0424 01:13:27.938180 21205 solver.cpp:258]     Train net output #0: accuracy = 0.546875
I0424 01:13:27.938191 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.08487 (* 1 = 3.08487 loss)
I0424 01:13:27.938201 21205 sgd_solver.cpp:112] Iteration 28200, lr = 0.0001
I0424 01:13:59.712150 21205 solver.cpp:239] Iteration 28300 (3.14721 iter/s, 31.7742s/100 iters), loss = 3.26441
I0424 01:13:59.712261 21205 solver.cpp:258]     Train net output #0: accuracy = 0.507812
I0424 01:13:59.712273 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.26441 (* 1 = 3.26441 loss)
I0424 01:13:59.712285 21205 sgd_solver.cpp:112] Iteration 28300, lr = 0.0001
I0424 01:14:31.483482 21205 solver.cpp:239] Iteration 28400 (3.14748 iter/s, 31.7714s/100 iters), loss = 2.95595
I0424 01:14:31.483587 21205 solver.cpp:258]     Train net output #0: accuracy = 0.546875
I0424 01:14:31.483598 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.95595 (* 1 = 2.95595 loss)
I0424 01:14:31.483609 21205 sgd_solver.cpp:112] Iteration 28400, lr = 0.0001
I0424 01:15:03.260368 21205 solver.cpp:239] Iteration 28500 (3.14693 iter/s, 31.777s/100 iters), loss = 2.96828
I0424 01:15:03.260450 21205 solver.cpp:258]     Train net output #0: accuracy = 0.554688
I0424 01:15:03.260462 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.96828 (* 1 = 2.96828 loss)
I0424 01:15:03.260473 21205 sgd_solver.cpp:112] Iteration 28500, lr = 0.0001
I0424 01:15:05.827070 21209 data_layer.cpp:73] Restarting data prefetching from start.
I0424 01:15:35.031759 21205 solver.cpp:239] Iteration 28600 (3.14747 iter/s, 31.7715s/100 iters), loss = 3.33863
I0424 01:15:35.031834 21205 solver.cpp:258]     Train net output #0: accuracy = 0.484375
I0424 01:15:35.031847 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.33863 (* 1 = 3.33863 loss)
I0424 01:15:35.031857 21205 sgd_solver.cpp:112] Iteration 28600, lr = 0.0001
I0424 01:16:06.804759 21205 solver.cpp:239] Iteration 28700 (3.14731 iter/s, 31.7731s/100 iters), loss = 3.2182
I0424 01:16:06.804862 21205 solver.cpp:258]     Train net output #0: accuracy = 0.484375
I0424 01:16:06.804873 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.2182 (* 1 = 3.2182 loss)
I0424 01:16:06.804883 21205 sgd_solver.cpp:112] Iteration 28700, lr = 0.0001
I0424 01:16:38.574463 21205 solver.cpp:239] Iteration 28800 (3.14764 iter/s, 31.7698s/100 iters), loss = 3.02683
I0424 01:16:38.574520 21205 solver.cpp:258]     Train net output #0: accuracy = 0.53125
I0424 01:16:38.574530 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.02683 (* 1 = 3.02683 loss)
I0424 01:16:38.574540 21205 sgd_solver.cpp:112] Iteration 28800, lr = 0.0001
I0424 01:17:10.345932 21205 solver.cpp:239] Iteration 28900 (3.14746 iter/s, 31.7716s/100 iters), loss = 3.03142
I0424 01:17:10.346012 21205 solver.cpp:258]     Train net output #0: accuracy = 0.546875
I0424 01:17:10.346024 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.03142 (* 1 = 3.03142 loss)
I0424 01:17:10.346035 21205 sgd_solver.cpp:112] Iteration 28900, lr = 0.0001
I0424 01:17:42.119735 21205 solver.cpp:239] Iteration 29000 (3.14723 iter/s, 31.7739s/100 iters), loss = 2.42355
I0424 01:17:42.119793 21205 solver.cpp:258]     Train net output #0: accuracy = 0.578125
I0424 01:17:42.119804 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.42355 (* 1 = 2.42355 loss)
I0424 01:17:42.119814 21205 sgd_solver.cpp:112] Iteration 29000, lr = 0.0001
I0424 01:18:13.899893 21205 solver.cpp:239] Iteration 29100 (3.1466 iter/s, 31.7803s/100 iters), loss = 2.44894
I0424 01:18:13.899973 21205 solver.cpp:258]     Train net output #0: accuracy = 0.609375
I0424 01:18:13.899984 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.44894 (* 1 = 2.44894 loss)
I0424 01:18:13.899996 21205 sgd_solver.cpp:112] Iteration 29100, lr = 0.0001
I0424 01:18:45.678501 21205 solver.cpp:239] Iteration 29200 (3.14676 iter/s, 31.7787s/100 iters), loss = 3.07177
I0424 01:18:45.678572 21205 solver.cpp:258]     Train net output #0: accuracy = 0.507812
I0424 01:18:45.678583 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.07177 (* 1 = 3.07177 loss)
I0424 01:18:45.678593 21205 sgd_solver.cpp:112] Iteration 29200, lr = 0.0001
I0424 01:19:04.145020 21209 data_layer.cpp:73] Restarting data prefetching from start.
I0424 01:19:17.458441 21205 solver.cpp:239] Iteration 29300 (3.14663 iter/s, 31.78s/100 iters), loss = 2.74614
I0424 01:19:17.458546 21205 solver.cpp:258]     Train net output #0: accuracy = 0.5625
I0424 01:19:17.458559 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.74614 (* 1 = 2.74614 loss)
I0424 01:19:17.458570 21205 sgd_solver.cpp:112] Iteration 29300, lr = 0.0001
I0424 01:19:49.236459 21205 solver.cpp:239] Iteration 29400 (3.1469 iter/s, 31.7773s/100 iters), loss = 2.79438
I0424 01:19:49.236536 21205 solver.cpp:258]     Train net output #0: accuracy = 0.515625
I0424 01:19:49.236546 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.79438 (* 1 = 2.79438 loss)
I0424 01:19:49.236557 21205 sgd_solver.cpp:112] Iteration 29400, lr = 0.0001
I0424 01:20:21.015137 21205 solver.cpp:239] Iteration 29500 (3.14683 iter/s, 31.778s/100 iters), loss = 2.66872
I0424 01:20:21.015236 21205 solver.cpp:258]     Train net output #0: accuracy = 0.59375
I0424 01:20:21.015249 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.66872 (* 1 = 2.66872 loss)
I0424 01:20:21.015259 21205 sgd_solver.cpp:112] Iteration 29500, lr = 0.0001
I0424 01:20:52.796756 21205 solver.cpp:239] Iteration 29600 (3.14654 iter/s, 31.7809s/100 iters), loss = 2.86676
I0424 01:20:52.796826 21205 solver.cpp:258]     Train net output #0: accuracy = 0.539062
I0424 01:20:52.796838 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.86676 (* 1 = 2.86676 loss)
I0424 01:20:52.796849 21205 sgd_solver.cpp:112] Iteration 29600, lr = 0.0001
I0424 01:21:24.585077 21205 solver.cpp:239] Iteration 29700 (3.14587 iter/s, 31.7877s/100 iters), loss = 3.09433
I0424 01:21:24.585160 21205 solver.cpp:258]     Train net output #0: accuracy = 0.5
I0424 01:21:24.585172 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.09433 (* 1 = 3.09433 loss)
I0424 01:21:24.585183 21205 sgd_solver.cpp:112] Iteration 29700, lr = 0.0001
I0424 01:21:56.367943 21205 solver.cpp:239] Iteration 29800 (3.14641 iter/s, 31.7823s/100 iters), loss = 2.84671
I0424 01:21:56.368021 21205 solver.cpp:258]     Train net output #0: accuracy = 0.609375
I0424 01:21:56.368032 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.84671 (* 1 = 2.84671 loss)
I0424 01:21:56.368043 21205 sgd_solver.cpp:112] Iteration 29800, lr = 0.0001
I0424 01:22:28.156710 21205 solver.cpp:239] Iteration 29900 (3.14582 iter/s, 31.7882s/100 iters), loss = 2.84827
I0424 01:22:28.156781 21205 solver.cpp:258]     Train net output #0: accuracy = 0.570312
I0424 01:22:28.156793 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.84827 (* 1 = 2.84827 loss)
I0424 01:22:28.156805 21205 sgd_solver.cpp:112] Iteration 29900, lr = 0.0001
I0424 01:22:59.942226 21205 solver.cpp:239] Iteration 30000 (3.14614 iter/s, 31.785s/100 iters), loss = 2.9717
I0424 01:22:59.942309 21205 solver.cpp:258]     Train net output #0: accuracy = 0.53125
I0424 01:22:59.942320 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.9717 (* 1 = 2.9717 loss)
I0424 01:22:59.942332 21205 sgd_solver.cpp:112] Iteration 30000, lr = 0.0001
I0424 01:23:02.820107 21209 data_layer.cpp:73] Restarting data prefetching from start.
I0424 01:23:31.724081 21205 solver.cpp:239] Iteration 30100 (3.1465 iter/s, 31.7814s/100 iters), loss = 3.49926
I0424 01:23:31.724156 21205 solver.cpp:258]     Train net output #0: accuracy = 0.507812
I0424 01:23:31.724169 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.49926 (* 1 = 3.49926 loss)
I0424 01:23:31.724179 21205 sgd_solver.cpp:112] Iteration 30100, lr = 0.0001
I0424 01:24:03.507747 21205 solver.cpp:239] Iteration 30200 (3.14631 iter/s, 31.7832s/100 iters), loss = 2.95654
I0424 01:24:03.507829 21205 solver.cpp:258]     Train net output #0: accuracy = 0.507812
I0424 01:24:03.507841 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.95654 (* 1 = 2.95654 loss)
I0424 01:24:03.507851 21205 sgd_solver.cpp:112] Iteration 30200, lr = 0.0001
I0424 01:24:35.290657 21205 solver.cpp:239] Iteration 30300 (3.14639 iter/s, 31.7825s/100 iters), loss = 3.17512
I0424 01:24:35.290786 21205 solver.cpp:258]     Train net output #0: accuracy = 0.476562
I0424 01:24:35.290798 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.17512 (* 1 = 3.17512 loss)
I0424 01:24:35.290808 21205 sgd_solver.cpp:112] Iteration 30300, lr = 0.0001
I0424 01:25:07.072307 21205 solver.cpp:239] Iteration 30400 (3.14651 iter/s, 31.7812s/100 iters), loss = 2.89446
I0424 01:25:07.072420 21205 solver.cpp:258]     Train net output #0: accuracy = 0.53125
I0424 01:25:07.072433 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.89446 (* 1 = 2.89446 loss)
I0424 01:25:07.072444 21205 sgd_solver.cpp:112] Iteration 30400, lr = 0.0001
I0424 01:25:38.857494 21205 solver.cpp:239] Iteration 30500 (3.14616 iter/s, 31.7848s/100 iters), loss = 2.84041
I0424 01:25:38.857558 21205 solver.cpp:258]     Train net output #0: accuracy = 0.578125
I0424 01:25:38.857569 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.84041 (* 1 = 2.84041 loss)
I0424 01:25:38.857579 21205 sgd_solver.cpp:112] Iteration 30500, lr = 0.0001
I0424 01:26:10.634560 21205 solver.cpp:239] Iteration 30600 (3.14696 iter/s, 31.7767s/100 iters), loss = 3.3983
I0424 01:26:10.634642 21205 solver.cpp:258]     Train net output #0: accuracy = 0.5
I0424 01:26:10.634654 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.3983 (* 1 = 3.3983 loss)
I0424 01:26:10.634665 21205 sgd_solver.cpp:112] Iteration 30600, lr = 0.0001
I0424 01:26:42.408380 21205 solver.cpp:239] Iteration 30700 (3.14728 iter/s, 31.7735s/100 iters), loss = 2.42828
I0424 01:26:42.408448 21205 solver.cpp:258]     Train net output #0: accuracy = 0.601562
I0424 01:26:42.408462 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.42828 (* 1 = 2.42828 loss)
I0424 01:26:42.408470 21205 sgd_solver.cpp:112] Iteration 30700, lr = 0.0001
I0424 01:27:01.178335 21209 data_layer.cpp:73] Restarting data prefetching from start.
I0424 01:27:14.178197 21205 solver.cpp:239] Iteration 30800 (3.14767 iter/s, 31.7695s/100 iters), loss = 2.75547
I0424 01:27:14.178275 21205 solver.cpp:258]     Train net output #0: accuracy = 0.515625
I0424 01:27:14.178287 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.75547 (* 1 = 2.75547 loss)
I0424 01:27:14.178297 21205 sgd_solver.cpp:112] Iteration 30800, lr = 0.0001
I0424 01:27:45.961002 21205 solver.cpp:239] Iteration 30900 (3.14639 iter/s, 31.7825s/100 iters), loss = 2.66671
I0424 01:27:45.961061 21205 solver.cpp:258]     Train net output #0: accuracy = 0.546875
I0424 01:27:45.961072 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.66671 (* 1 = 2.66671 loss)
I0424 01:27:45.961082 21205 sgd_solver.cpp:112] Iteration 30900, lr = 0.0001
I0424 01:28:17.739751 21205 solver.cpp:239] Iteration 31000 (3.14678 iter/s, 31.7785s/100 iters), loss = 3.24199
I0424 01:28:17.739835 21205 solver.cpp:258]     Train net output #0: accuracy = 0.53125
I0424 01:28:17.739847 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.24199 (* 1 = 3.24199 loss)
I0424 01:28:17.739858 21205 sgd_solver.cpp:112] Iteration 31000, lr = 0.0001
I0424 01:28:49.516624 21205 solver.cpp:239] Iteration 31100 (3.14697 iter/s, 31.7766s/100 iters), loss = 3.63806
I0424 01:28:49.516695 21205 solver.cpp:258]     Train net output #0: accuracy = 0.476562
I0424 01:28:49.516706 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.63806 (* 1 = 3.63806 loss)
I0424 01:28:49.516716 21205 sgd_solver.cpp:112] Iteration 31100, lr = 0.0001
I0424 01:29:21.293975 21205 solver.cpp:239] Iteration 31200 (3.14692 iter/s, 31.7771s/100 iters), loss = 3.13691
I0424 01:29:21.294073 21205 solver.cpp:258]     Train net output #0: accuracy = 0.484375
I0424 01:29:21.294085 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.13691 (* 1 = 3.13691 loss)
I0424 01:29:21.294095 21205 sgd_solver.cpp:112] Iteration 31200, lr = 0.0001
I0424 01:29:53.069242 21205 solver.cpp:239] Iteration 31300 (3.14713 iter/s, 31.775s/100 iters), loss = 3.02599
I0424 01:29:53.069326 21205 solver.cpp:258]     Train net output #0: accuracy = 0.578125
I0424 01:29:53.069339 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.02599 (* 1 = 3.02599 loss)
I0424 01:29:53.069350 21205 sgd_solver.cpp:112] Iteration 31300, lr = 0.0001
I0424 01:30:24.844254 21205 solver.cpp:239] Iteration 31400 (3.14715 iter/s, 31.7748s/100 iters), loss = 2.9555
I0424 01:30:24.844363 21205 solver.cpp:258]     Train net output #0: accuracy = 0.539062
I0424 01:30:24.844377 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.9555 (* 1 = 2.9555 loss)
I0424 01:30:24.844388 21205 sgd_solver.cpp:112] Iteration 31400, lr = 0.0001
I0424 01:30:56.620996 21205 solver.cpp:239] Iteration 31500 (3.14698 iter/s, 31.7765s/100 iters), loss = 3.1885
I0424 01:30:56.621081 21205 solver.cpp:258]     Train net output #0: accuracy = 0.546875
I0424 01:30:56.621094 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.1885 (* 1 = 3.1885 loss)
I0424 01:30:56.621104 21205 sgd_solver.cpp:112] Iteration 31500, lr = 0.0001
I0424 01:30:59.520293 21209 data_layer.cpp:73] Restarting data prefetching from start.
I0424 01:31:28.415733 21205 solver.cpp:239] Iteration 31600 (3.1452 iter/s, 31.7945s/100 iters), loss = 3.23292
I0424 01:31:28.415801 21205 solver.cpp:258]     Train net output #0: accuracy = 0.476562
I0424 01:31:28.415812 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.23292 (* 1 = 3.23292 loss)
I0424 01:31:28.415822 21205 sgd_solver.cpp:112] Iteration 31600, lr = 0.0001
I0424 01:32:00.207825 21205 solver.cpp:239] Iteration 31700 (3.14545 iter/s, 31.7919s/100 iters), loss = 2.62705
I0424 01:32:00.207907 21205 solver.cpp:258]     Train net output #0: accuracy = 0.59375
I0424 01:32:00.207918 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.62705 (* 1 = 2.62705 loss)
I0424 01:32:00.207928 21205 sgd_solver.cpp:112] Iteration 31700, lr = 0.0001
I0424 01:32:31.998911 21205 solver.cpp:239] Iteration 31800 (3.14555 iter/s, 31.7909s/100 iters), loss = 3.24084
I0424 01:32:31.998968 21205 solver.cpp:258]     Train net output #0: accuracy = 0.484375
I0424 01:32:31.998980 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.24084 (* 1 = 3.24084 loss)
I0424 01:32:31.998989 21205 sgd_solver.cpp:112] Iteration 31800, lr = 0.0001
I0424 01:33:03.786170 21205 solver.cpp:239] Iteration 31900 (3.14593 iter/s, 31.7871s/100 iters), loss = 3.02183
I0424 01:33:03.786254 21205 solver.cpp:258]     Train net output #0: accuracy = 0.515625
I0424 01:33:03.786265 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.02183 (* 1 = 3.02183 loss)
I0424 01:33:03.786276 21205 sgd_solver.cpp:112] Iteration 31900, lr = 0.0001
I0424 01:33:35.263258 21205 solver.cpp:468] Snapshotting to binary proto file result/model_iter_32000.caffemodel
I0424 01:33:35.302978 21205 sgd_solver.cpp:280] Snapshotting solver state to binary proto file result/model_iter_32000.solverstate
I0424 01:33:35.638130 21205 solver.cpp:239] Iteration 32000 (3.13954 iter/s, 31.8518s/100 iters), loss = 3.25681
I0424 01:33:35.638145 21212 sgd_solver.cpp:50] MultiStep Status: Iteration 32000, step = 4
I0424 01:33:35.638159 21205 solver.cpp:258]     Train net output #0: accuracy = 0.484375
I0424 01:33:35.638161 21210 sgd_solver.cpp:50] MultiStep Status: Iteration 32000, step = 4
I0424 01:33:35.638161 21211 sgd_solver.cpp:50] MultiStep Status: Iteration 32000, step = 4
I0424 01:33:35.638169 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.25681 (* 1 = 3.25681 loss)
I0424 01:33:35.638191 21205 sgd_solver.cpp:50] MultiStep Status: Iteration 32000, step = 4
I0424 01:33:35.638196 21205 sgd_solver.cpp:112] Iteration 32000, lr = 1e-05
I0424 01:34:07.424060 21205 solver.cpp:239] Iteration 32100 (3.14606 iter/s, 31.7858s/100 iters), loss = 3.05013
I0424 01:34:07.424165 21205 solver.cpp:258]     Train net output #0: accuracy = 0.515625
I0424 01:34:07.424177 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.05013 (* 1 = 3.05013 loss)
I0424 01:34:07.424187 21205 sgd_solver.cpp:112] Iteration 32100, lr = 1e-05
I0424 01:34:39.217090 21205 solver.cpp:239] Iteration 32200 (3.14536 iter/s, 31.7929s/100 iters), loss = 2.965
I0424 01:34:39.217190 21205 solver.cpp:258]     Train net output #0: accuracy = 0.59375
I0424 01:34:39.217202 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.965 (* 1 = 2.965 loss)
I0424 01:34:39.217212 21205 sgd_solver.cpp:112] Iteration 32200, lr = 1e-05
I0424 01:34:58.309408 21209 data_layer.cpp:73] Restarting data prefetching from start.
I0424 01:35:11.010377 21205 solver.cpp:239] Iteration 32300 (3.14533 iter/s, 31.7931s/100 iters), loss = 2.95622
I0424 01:35:11.010493 21205 solver.cpp:258]     Train net output #0: accuracy = 0.507812
I0424 01:35:11.010504 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.95622 (* 1 = 2.95622 loss)
I0424 01:35:11.010515 21205 sgd_solver.cpp:112] Iteration 32300, lr = 1e-05
I0424 01:35:42.802090 21205 solver.cpp:239] Iteration 32400 (3.14549 iter/s, 31.7915s/100 iters), loss = 3.28707
I0424 01:35:42.802170 21205 solver.cpp:258]     Train net output #0: accuracy = 0.476562
I0424 01:35:42.802181 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.28707 (* 1 = 3.28707 loss)
I0424 01:35:42.802191 21205 sgd_solver.cpp:112] Iteration 32400, lr = 1e-05
I0424 01:36:14.593798 21205 solver.cpp:239] Iteration 32500 (3.14549 iter/s, 31.7916s/100 iters), loss = 2.95891
I0424 01:36:14.593879 21205 solver.cpp:258]     Train net output #0: accuracy = 0.476562
I0424 01:36:14.593890 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.95891 (* 1 = 2.95891 loss)
I0424 01:36:14.593900 21205 sgd_solver.cpp:112] Iteration 32500, lr = 1e-05
I0424 01:36:46.382803 21205 solver.cpp:239] Iteration 32600 (3.14575 iter/s, 31.7889s/100 iters), loss = 2.68751
I0424 01:36:46.382874 21205 solver.cpp:258]     Train net output #0: accuracy = 0.578125
I0424 01:36:46.382885 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.68751 (* 1 = 2.68751 loss)
I0424 01:36:46.382896 21205 sgd_solver.cpp:112] Iteration 32600, lr = 1e-05
I0424 01:37:18.176553 21205 solver.cpp:239] Iteration 32700 (3.14528 iter/s, 31.7936s/100 iters), loss = 3.26497
I0424 01:37:18.176641 21205 solver.cpp:258]     Train net output #0: accuracy = 0.5
I0424 01:37:18.176653 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.26497 (* 1 = 3.26497 loss)
I0424 01:37:18.176663 21205 sgd_solver.cpp:112] Iteration 32700, lr = 1e-05
I0424 01:37:49.966233 21205 solver.cpp:239] Iteration 32800 (3.14569 iter/s, 31.7896s/100 iters), loss = 3.07529
I0424 01:37:49.966291 21205 solver.cpp:258]     Train net output #0: accuracy = 0.515625
I0424 01:37:49.966302 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.07529 (* 1 = 3.07529 loss)
I0424 01:37:49.966312 21205 sgd_solver.cpp:112] Iteration 32800, lr = 1e-05
I0424 01:38:21.754611 21205 solver.cpp:239] Iteration 32900 (3.14581 iter/s, 31.7883s/100 iters), loss = 3.23958
I0424 01:38:21.754709 21205 solver.cpp:258]     Train net output #0: accuracy = 0.484375
I0424 01:38:21.754721 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.23958 (* 1 = 3.23958 loss)
I0424 01:38:21.754731 21205 sgd_solver.cpp:112] Iteration 32900, lr = 1e-05
I0424 01:38:53.546353 21205 solver.cpp:239] Iteration 33000 (3.14548 iter/s, 31.7916s/100 iters), loss = 2.6003
I0424 01:38:53.546412 21205 solver.cpp:258]     Train net output #0: accuracy = 0.625
I0424 01:38:53.546423 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.6003 (* 1 = 2.6003 loss)
I0424 01:38:53.546433 21205 sgd_solver.cpp:112] Iteration 33000, lr = 1e-05
I0424 01:38:56.751135 21209 data_layer.cpp:73] Restarting data prefetching from start.
I0424 01:39:25.334105 21205 solver.cpp:239] Iteration 33100 (3.14587 iter/s, 31.7877s/100 iters), loss = 2.49619
I0424 01:39:25.334182 21205 solver.cpp:258]     Train net output #0: accuracy = 0.59375
I0424 01:39:25.334194 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.49619 (* 1 = 2.49619 loss)
I0424 01:39:25.334205 21205 sgd_solver.cpp:112] Iteration 33100, lr = 1e-05
I0424 01:39:57.125000 21205 solver.cpp:239] Iteration 33200 (3.14556 iter/s, 31.7908s/100 iters), loss = 2.74748
I0424 01:39:57.125105 21205 solver.cpp:258]     Train net output #0: accuracy = 0.59375
I0424 01:39:57.125118 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.74748 (* 1 = 2.74748 loss)
I0424 01:39:57.125128 21205 sgd_solver.cpp:112] Iteration 33200, lr = 1e-05
I0424 01:40:28.911474 21205 solver.cpp:239] Iteration 33300 (3.146 iter/s, 31.7864s/100 iters), loss = 3.47436
I0424 01:40:28.911573 21205 solver.cpp:258]     Train net output #0: accuracy = 0.484375
I0424 01:40:28.911586 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.47436 (* 1 = 3.47436 loss)
I0424 01:40:28.911597 21205 sgd_solver.cpp:112] Iteration 33300, lr = 1e-05
I0424 01:41:00.698082 21205 solver.cpp:239] Iteration 33400 (3.14599 iter/s, 31.7865s/100 iters), loss = 2.8875
I0424 01:41:00.698168 21205 solver.cpp:258]     Train net output #0: accuracy = 0.492188
I0424 01:41:00.698179 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.8875 (* 1 = 2.8875 loss)
I0424 01:41:00.698189 21205 sgd_solver.cpp:112] Iteration 33400, lr = 1e-05
I0424 01:41:32.486899 21205 solver.cpp:239] Iteration 33500 (3.14577 iter/s, 31.7887s/100 iters), loss = 3.10763
I0424 01:41:32.486956 21205 solver.cpp:258]     Train net output #0: accuracy = 0.554688
I0424 01:41:32.486968 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.10763 (* 1 = 3.10763 loss)
I0424 01:41:32.486977 21205 sgd_solver.cpp:112] Iteration 33500, lr = 1e-05
I0424 01:42:04.268573 21205 solver.cpp:239] Iteration 33600 (3.14647 iter/s, 31.7816s/100 iters), loss = 3.17915
I0424 01:42:04.268673 21205 solver.cpp:258]     Train net output #0: accuracy = 0.539062
I0424 01:42:04.268685 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.17915 (* 1 = 3.17915 loss)
I0424 01:42:04.268697 21205 sgd_solver.cpp:112] Iteration 33600, lr = 1e-05
I0424 01:42:36.055814 21205 solver.cpp:239] Iteration 33700 (3.14593 iter/s, 31.7871s/100 iters), loss = 3.37688
I0424 01:42:36.055887 21205 solver.cpp:258]     Train net output #0: accuracy = 0.484375
I0424 01:42:36.055898 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.37688 (* 1 = 3.37688 loss)
I0424 01:42:36.055908 21205 sgd_solver.cpp:112] Iteration 33700, lr = 1e-05
I0424 01:42:55.160344 21209 data_layer.cpp:73] Restarting data prefetching from start.
I0424 01:43:07.841625 21205 solver.cpp:239] Iteration 33800 (3.14606 iter/s, 31.7857s/100 iters), loss = 2.73284
I0424 01:43:07.841706 21205 solver.cpp:258]     Train net output #0: accuracy = 0.515625
I0424 01:43:07.841717 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.73284 (* 1 = 2.73284 loss)
I0424 01:43:07.841728 21205 sgd_solver.cpp:112] Iteration 33800, lr = 1e-05
I0424 01:43:39.626621 21205 solver.cpp:239] Iteration 33900 (3.14615 iter/s, 31.7849s/100 iters), loss = 3.26528
I0424 01:43:39.626679 21205 solver.cpp:258]     Train net output #0: accuracy = 0.476562
I0424 01:43:39.626689 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.26528 (* 1 = 3.26528 loss)
I0424 01:43:39.626700 21205 sgd_solver.cpp:112] Iteration 33900, lr = 1e-05
I0424 01:44:11.409134 21205 solver.cpp:239] Iteration 34000 (3.14639 iter/s, 31.7825s/100 iters), loss = 2.82361
I0424 01:44:11.409216 21205 solver.cpp:258]     Train net output #0: accuracy = 0.585938
I0424 01:44:11.409234 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.82361 (* 1 = 2.82361 loss)
I0424 01:44:11.409245 21205 sgd_solver.cpp:112] Iteration 34000, lr = 1e-05
I0424 01:44:43.195087 21205 solver.cpp:239] Iteration 34100 (3.14605 iter/s, 31.7859s/100 iters), loss = 3.55943
I0424 01:44:43.195158 21205 solver.cpp:258]     Train net output #0: accuracy = 0.484375
I0424 01:44:43.195169 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.55943 (* 1 = 3.55943 loss)
I0424 01:44:43.195180 21205 sgd_solver.cpp:112] Iteration 34100, lr = 1e-05
I0424 01:45:14.988101 21205 solver.cpp:239] Iteration 34200 (3.14535 iter/s, 31.793s/100 iters), loss = 3.24665
I0424 01:45:14.988214 21205 solver.cpp:258]     Train net output #0: accuracy = 0.5
I0424 01:45:14.988225 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.24665 (* 1 = 3.24665 loss)
I0424 01:45:14.988236 21205 sgd_solver.cpp:112] Iteration 34200, lr = 1e-05
I0424 01:45:46.782243 21205 solver.cpp:239] Iteration 34300 (3.14524 iter/s, 31.7941s/100 iters), loss = 2.83703
I0424 01:45:46.782373 21205 solver.cpp:258]     Train net output #0: accuracy = 0.53125
I0424 01:45:46.782385 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.83703 (* 1 = 2.83703 loss)
I0424 01:45:46.782397 21205 sgd_solver.cpp:112] Iteration 34300, lr = 1e-05
I0424 01:46:18.571068 21205 solver.cpp:239] Iteration 34400 (3.14577 iter/s, 31.7887s/100 iters), loss = 2.85329
I0424 01:46:18.571159 21205 solver.cpp:258]     Train net output #0: accuracy = 0.546875
I0424 01:46:18.571171 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.85329 (* 1 = 2.85329 loss)
I0424 01:46:18.571182 21205 sgd_solver.cpp:112] Iteration 34400, lr = 1e-05
I0424 01:46:50.361799 21205 solver.cpp:239] Iteration 34500 (3.14558 iter/s, 31.7907s/100 iters), loss = 3.20169
I0424 01:46:50.361853 21205 solver.cpp:258]     Train net output #0: accuracy = 0.5
I0424 01:46:50.361865 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.20169 (* 1 = 3.20169 loss)
I0424 01:46:50.361874 21205 sgd_solver.cpp:112] Iteration 34500, lr = 1e-05
I0424 01:46:53.875113 21209 data_layer.cpp:73] Restarting data prefetching from start.
I0424 01:47:22.157107 21205 solver.cpp:239] Iteration 34600 (3.14512 iter/s, 31.7953s/100 iters), loss = 3.39287
I0424 01:47:22.157188 21205 solver.cpp:258]     Train net output #0: accuracy = 0.476562
I0424 01:47:22.157202 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.39287 (* 1 = 3.39287 loss)
I0424 01:47:22.157212 21205 sgd_solver.cpp:112] Iteration 34600, lr = 1e-05
I0424 01:47:53.948900 21205 solver.cpp:239] Iteration 34700 (3.14547 iter/s, 31.7917s/100 iters), loss = 3.36173
I0424 01:47:53.948969 21205 solver.cpp:258]     Train net output #0: accuracy = 0.523438
I0424 01:47:53.948982 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.36173 (* 1 = 3.36173 loss)
I0424 01:47:53.948992 21205 sgd_solver.cpp:112] Iteration 34700, lr = 1e-05
I0424 01:48:25.736387 21205 solver.cpp:239] Iteration 34800 (3.1459 iter/s, 31.7875s/100 iters), loss = 2.94882
I0424 01:48:25.736465 21205 solver.cpp:258]     Train net output #0: accuracy = 0.476562
I0424 01:48:25.736477 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.94882 (* 1 = 2.94882 loss)
I0424 01:48:25.736487 21205 sgd_solver.cpp:112] Iteration 34800, lr = 1e-05
I0424 01:48:57.517678 21205 solver.cpp:239] Iteration 34900 (3.14651 iter/s, 31.7812s/100 iters), loss = 3.32551
I0424 01:48:57.517758 21205 solver.cpp:258]     Train net output #0: accuracy = 0.46875
I0424 01:48:57.517769 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.32551 (* 1 = 3.32551 loss)
I0424 01:48:57.517781 21205 sgd_solver.cpp:112] Iteration 34900, lr = 1e-05
I0424 01:49:29.303756 21205 solver.cpp:239] Iteration 35000 (3.14604 iter/s, 31.786s/100 iters), loss = 2.82568
I0424 01:49:29.303824 21205 solver.cpp:258]     Train net output #0: accuracy = 0.539062
I0424 01:49:29.303835 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.82568 (* 1 = 2.82568 loss)
I0424 01:49:29.303845 21205 sgd_solver.cpp:112] Iteration 35000, lr = 1e-05
I0424 01:50:01.091502 21205 solver.cpp:239] Iteration 35100 (3.14587 iter/s, 31.7877s/100 iters), loss = 2.95194
I0424 01:50:01.091583 21205 solver.cpp:258]     Train net output #0: accuracy = 0.53125
I0424 01:50:01.091594 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.95194 (* 1 = 2.95194 loss)
I0424 01:50:01.091603 21205 sgd_solver.cpp:112] Iteration 35100, lr = 1e-05
I0424 01:50:32.879153 21205 solver.cpp:239] Iteration 35200 (3.14588 iter/s, 31.7876s/100 iters), loss = 3.57058
I0424 01:50:32.879238 21205 solver.cpp:258]     Train net output #0: accuracy = 0.445312
I0424 01:50:32.879251 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.57058 (* 1 = 3.57058 loss)
I0424 01:50:32.879261 21205 sgd_solver.cpp:112] Iteration 35200, lr = 1e-05
I0424 01:50:52.291255 21209 data_layer.cpp:73] Restarting data prefetching from start.
I0424 01:51:04.661810 21205 solver.cpp:239] Iteration 35300 (3.14637 iter/s, 31.7826s/100 iters), loss = 2.82533
I0424 01:51:04.661916 21205 solver.cpp:258]     Train net output #0: accuracy = 0.53125
I0424 01:51:04.661928 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.82533 (* 1 = 2.82533 loss)
I0424 01:51:04.661938 21205 sgd_solver.cpp:112] Iteration 35300, lr = 1e-05
I0424 01:51:36.445614 21205 solver.cpp:239] Iteration 35400 (3.14626 iter/s, 31.7837s/100 iters), loss = 2.76286
I0424 01:51:36.445686 21205 solver.cpp:258]     Train net output #0: accuracy = 0.507812
I0424 01:51:36.445698 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.76286 (* 1 = 2.76286 loss)
I0424 01:51:36.445708 21205 sgd_solver.cpp:112] Iteration 35400, lr = 1e-05
I0424 01:52:08.227094 21205 solver.cpp:239] Iteration 35500 (3.14649 iter/s, 31.7814s/100 iters), loss = 2.71039
I0424 01:52:08.227182 21205 solver.cpp:258]     Train net output #0: accuracy = 0.554688
I0424 01:52:08.227193 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.71039 (* 1 = 2.71039 loss)
I0424 01:52:08.227202 21205 sgd_solver.cpp:112] Iteration 35500, lr = 1e-05
I0424 01:52:40.013250 21205 solver.cpp:239] Iteration 35600 (3.14603 iter/s, 31.7861s/100 iters), loss = 2.91667
I0424 01:52:40.013319 21205 solver.cpp:258]     Train net output #0: accuracy = 0.546875
I0424 01:52:40.013331 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.91667 (* 1 = 2.91667 loss)
I0424 01:52:40.013340 21205 sgd_solver.cpp:112] Iteration 35600, lr = 1e-05
I0424 01:53:11.798743 21205 solver.cpp:239] Iteration 35700 (3.14609 iter/s, 31.7855s/100 iters), loss = 2.52769
I0424 01:53:11.798823 21205 solver.cpp:258]     Train net output #0: accuracy = 0.632812
I0424 01:53:11.798835 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.52769 (* 1 = 2.52769 loss)
I0424 01:53:11.798844 21205 sgd_solver.cpp:112] Iteration 35700, lr = 1e-05
I0424 01:53:43.580008 21205 solver.cpp:239] Iteration 35800 (3.14649 iter/s, 31.7815s/100 iters), loss = 3.15449
I0424 01:53:43.580080 21205 solver.cpp:258]     Train net output #0: accuracy = 0.492188
I0424 01:53:43.580090 21205 solver.cpp:258]     Train net output #1: softmax_loss = 3.15449 (* 1 = 3.15449 loss)
I0424 01:53:43.580101 21205 sgd_solver.cpp:112] Iteration 35800, lr = 1e-05
I0424 01:54:15.364521 21205 solver.cpp:239] Iteration 35900 (3.14615 iter/s, 31.7848s/100 iters), loss = 2.61538
I0424 01:54:15.364608 21205 solver.cpp:258]     Train net output #0: accuracy = 0.570312
I0424 01:54:15.364619 21205 solver.cpp:258]     Train net output #1: softmax_loss = 2.61538 (* 1 = 2.61538 loss)
I0424 01:54:15.364629 21205 sgd_solver.cpp:112] Iteration 35900, lr = 1e-05
I0424 01:54:46.836674 21205 solver.cpp:468] Snapshotting to binary proto file result/model_iter_36000.caffemodel
I0424 01:54:46.874847 21205 sgd_solver.cpp:280] Snapshotting solver state to binary proto file result/model_iter_36000.solverstate
I0424 01:54:46.967473 21205 solver.cpp:331] Iteration 36000, loss = 3.02328
I0424 01:54:46.967494 21205 solver.cpp:336] Optimization Done.
I0424 01:54:50.273675 21205 caffe.cpp:250] Optimization Done.
